---
title: "计算机动画02：二维图像变形技术(2D Image Morphing)"
description: ""
pubDate: "2025-08-21"
heroImage: ""
---

# 计算机动画02：二维图像变形技术(2D Image Morphing)

### **第一部分：Morphing 的概念与直觉**

#### **1.1 什么是图像 Morphing？**

大家可能都在电影、广告中见过这样的特效：一个人的脸平滑地变成了另一个人的脸，或者一只猫无缝地变成了一只老虎。这个过程，我们称之为 **Morphing**，即“变形”。

从技术上讲，**图像自然渐变 (Image Morphing)** 是指将一幅源数字图像（Source Image）以一种自然流畅、富有戏剧性的方式，变换到另一幅目标数字图像（Destination Image）的过程。这个过程会生成一系列中间帧图像，当它们连续播放时，就形成了平滑过渡的动画效果。

最著名的例子莫过于迈克尔·杰克逊在其1991年的音乐录影带《Black or White》结尾处使用的面部变形特效，在当时引起了巨大的轰动，也让这项技术走进了公众视野。

#### **1.2 Morphing 的核心思想：分解与合成**

一个成功的 Morphing 效果，实际上是两种基本操作的完美结合：

1.  **图像扭曲 (Image Warping)**：这是一种几何变换，它改变图像中像素的位置，但不改变它们的颜色。它负责将源图像的形状逐渐“捏”成目标图像的形状，同时也将目标图像的形状“反向捏”成源图像的形状。
2.  **交叉溶解 (Cross-dissolving)**：这是一种颜色变换，它通过对两幅图像的颜色值进行加权平均，实现一幅图像逐渐淡出，另一幅图像逐渐淡入的效果。

我们可以用一个简单的公式来描述在时间点 `t` (其中 `t` 从 0 到 1) 的中间帧图像 `I_t`：

`I_t = (1 - t) * Warped_Source + t * Warped_Destination`

这里的 `Warped_Source` 是源图像经过扭曲后的结果，`Warped_Destination` 是目标图像经过扭曲后的结果。当 `t=0` 时，图像完全是源图像；当 `t=1` 时，图像完全是目标图像。

#### **1.3 二维 Morphing vs. 三维 Morphing**

在我们深入二维技术之前，有必要区分它与三维 Morphing 的不同：

*   **三维 Morphing**：
    
    *   在三维模型上操作。需要先为源对象和目标对象分别建模。
    *   对模型的拓扑结构有严格要求（例如，顶点数、面数和连接关系需要一致）。
    *   插值的是三维顶点的坐标、法线、纹理坐标等几何与非几何属性。
    *   优点：物理上更准确，可以任意改变视角和光照。
    *   缺点：建模复杂，建立模型间的对应关系极其困难。
*   **二维 Morphing**：
    
    *   在二维图像空间上操作，本质上是像素处理技术。
    *   不依赖三维信息，更加灵活和简单。
    *   优点：**可以避免复杂的三维造型过程**。当虚拟摄像机位置固定时，效果非常出色，足以产生神奇的“三维形状改变”的错觉。
    *   缺点：缺乏真实的三维几何信息，无法处理视角和光照的变化，可能产生不符合物理规律的畸变。

我们今天将聚焦于二维 Morphing，因为它在很多应用场景下，以较低的成本实现了惊人的视觉效果。

* * *

### **第二部分：经典 Morphing 算法**

现在，我们来探讨实现 Morphing 的两种主流经典方法。

#### **2.1 方法一：基于网格的 Morphing (Grid-Based Morphing)**

这是最早期的 Morphing 方法之一，其思想非常直观：在源图像和目标图像上覆盖一个控制网格，通过操纵网格来驱动整个图像的变形。

**2.1.1 算法流程**

1.  **定义控制网格**：在源图像 `I_S` 上定义一个控制网格 `M_S`，在目标图像 `I_D` 上定义一个对应的控制网格 `M_D`。`M_S` 和 `M_D` 具有相同的拓扑结构（即，相同的行列数），但控制顶点的位置不同，以匹配两幅图像的特征。
2.  **插值中间网格**：对于任意时间 `t` (0 ≤ t ≤ 1)，通过对 `M_S` 和 `M_D` 的控制顶点坐标进行线性插值，得到一个中间控制网格 `M_t`。 `M_t(i, j) = (1 - t) * M_S(i, j) + t * M_D(i, j)`
3.  **执行图像扭曲 (Warping)**：这是最关键的一步。我们需要生成两幅扭曲后的图像：
    *   `I_S'`：将源图像 `I_S` 从其原始网格 `M_S` 扭曲到中间网格 `M_t`。
    *   `I_D'`：将目标图像 `I_D` 从其原始网格 `M_D` 扭曲到中间网格 `M_t`。
4.  **交叉溶解**：将两幅扭曲后的图像 `I_S'` 和 `I_D'` 进行交叉溶解，得到最终的中间帧 `I_t`。 `I_t(p) = (1 - t) * I_S'(p) + t * I_D'(p)`

**2.1.2 扭曲的数学实现：逆向映射与双线性/双三次插值**

直接从源网格计算像素到目标网格的位置（正向映射）可能会导致目标图像中出现空洞（多个源像素映射到同一位置）或重叠（某些目标像素没有源像素映射过来）的问题。因此，我们通常采用**逆向映射 (Inverse Mapping)**：

对于中间帧 `I_t` 中的每一个像素 `p`，我们问：它在源图像 `I_S` 和目标图像 `I_D` 中对应的原始位置 `p_s` 和 `p_d` 是哪里？

*   **步骤**：
    1.  确定像素 `p` 位于中间网格 `M_t` 的哪个四边形单元格内。
    2.  根据 `p` 在该单元格内的相对位置（通常用 `(u,v)` 坐标表示，0 ≤ u,v ≤ 1），计算出它在源网格 `M_S` 和目标网格 `M_D` 对应单元格内的位置 `p_s` 和 `p_d`。这个计算过程就是**双线性插值**或更平滑的**双三次样条插值**。
    3.  由于 `p_s` 和 `p_d` 的坐标通常不是整数，我们需要在 `I_S` 和 `I_D` 中，使用其周围像素的颜色再次进行双线性插值，来得到精确的颜色值。

**双三次样条曲面 (Bicubic Spline Surface)**

为了获得更平滑的变形，网格通常被看作是双三次样条曲面的控制点。一个由 `(n+1)x(n+1)` 控制点 `P_ij` 定义的样条曲面可以表示为： `p(u,v) = Σ_{i=0 to n} Σ_{j=0 to n} B_{i,n}(u) B_{j,n}(v) P_{ij}` 其中 `B_{i,n}` 是基函数（例如Bernstein基函数用于Bezier曲面），`(u,v)` 是参数化坐标 `(u,v) ∈ [0,1]x[0,1]`。

逆向映射的核心挑战在于求解方程 `p = p(u,v)` 来反向得到 `(u,v)`。这是一个非线性方程组，通常没有解析解。在实践中，可以使用数值方法，如**梯度下降法**来求解。

*   **目标函数**: `F(u,v) = || p(u,v) - p_{target} ||^2`
*   **迭代更新**: `(u_{k+1}, v_{k+1}) = (u_k, v_k) - η * ∇F(u_k, v_k)` 其中 `η` 是学习率，`∇F` 是梯度。

**2.1.3 网格法的优缺点**

*   **优点**：概念简单，变形平滑。
*   **缺点**：控制不直观。在图像特征复杂区域，需要非常密集的网格，手动放置和调整这些网格点是一项枯燥且繁重的工作。

* * *

#### **2.2 方法二：基于特征的 Morphing (Feature-Based Morphing)**

为了解决网格法控制不直观的问题，Thaddeus Beier 和 Shawn Neely 在1992年提出了一种革命性的方法，它允许动画师通过指定**线对 (Line Pairs)** 来控制变形。这项技术成为了行业的标准，并在无数电影特效中被使用。

**2.2.1 核心思想**

动画师在源图像和目标图像上画出一系列对应的特征线段。例如，在人脸 Morphing 中，可以在眉毛、眼睛、鼻子、嘴巴和脸的轮廓上画线。这些线对定义了图像空间中点与点之间的映射关系。

**2.2.2 单个线对定义的变换**

让我们首先考虑一个从目标图像 `I_D` 到源图像 `I_S` 的逆向映射，这个映射由一对线段 `P'Q'` (在 `I_D` 中) 和 `PQ` (在 `I_S` 中) 定义。

对于 `I_D` 中的任意像素点 `X'`，我们如何找到它在 `I_S` 中对应的点 `X`？

1.  **计算 `X'` 相对于线段 `P'Q'` 的坐标 `(u, v)`**：
    
    *   `u`：`X'` 在线段 `P'Q'` 上的投影点，沿线段方向的归一化距离。`u=0` 在 `P'`，`u=1` 在 `Q'`。 `u = ((X' - P') · (Q' - P')) / ||Q' - P'||^2`
    *   `v`：`X'` 到线段 `P'Q'` 的带符号垂直距离。距离以像素为单位。 `v = ((X' - P') · Perpendicular(Q' - P')) / ||Q' - P'||` 其中 `Perpendicular((dx, dy))` 返回 `(-dy, dx)`。
2.  **根据 `(u, v)` 在源图像中重建 `X`**： 使用相同的 `(u, v)` 坐标，我们可以计算出 `X` 相对于线段 `PQ` 的位置： `X = P + u * (Q - P) + v * Perpendicular(Q - P) / ||Q - P||`
    

这个变换本质上是一个由旋转、平移和缩放构成的复合变换。

**2.2.3 多个线对定义的变换**

当存在多对特征线时，一个像素会受到所有线对的影响。Beier 和 Neely 的方法是，对每个线对 `i` 计算一个从 `X'` 映射到的源位置 `X_i`，然后对这些 `X_i` 进行加权平均，得到最终的源位置 `X`。

*   **位移**：对于每个线对 `i`，它产生一个从目标点 `X'` 到源点 `X_i` 的位移向量 `D_i = X_i - X'`。
*   **加权平均**：最终的源位置 `X_{source}` 是由目标位置 `X'_{dest}` 加上所有位移的加权平均值决定的。 `X_{source} = X'_{dest} + (Σ_i D_i * w_i) / (Σ_i w_i)`
*   **权重函数 (Weight Function)**：权重 `w_i` 的计算至关重要，它决定了每条线的影响范围和强度。 `w_i = (length^p / (a + dist))^b`
    *   `length`：线段 `P'Q'` 的长度。`p` 参数控制长度的影响力 (`p=0` 则长度无关，`p=1` 则长线影响更大)。
    *   `dist`：像素 `X'` 到线段 `P'Q'` 的最短距离。这是影响力的主要来源，距离越近，影响越大。
    *   `a`：一个很小的常数，防止 `dist` 为0时除零。它也控制了影响力的衰减。
    *   `b`：控制影响力随距离衰减的强度。`b` 越大，影响力衰减越快，变形更“局部”。`b` 通常在 `[0.5, 2]` 之间。

**2.2.4 完整的 Beier-Neely Morphing 算法流程**

1.  **输入**：源图像 `I_S`，目标图像 `I_D`，源特征线集 `{S_i}`，目标特征线集 `{D_i}`。
2.  **动画循环**：对于时间 `t` 从 0 到 1 的每一帧： a. 创建一个空的中间帧图像 `I_t`。 b. **插值特征线**：计算当前帧的特征线集 `{L_i}`。 `L_i = (1 - t) * S_i + t * D_i` c. **逆向映射像素**：对于 `I_t` 中的每一个像素 `p_{dest}`： i. **计算源位置**：使用 `{L_i}` 作为目标线，`{S_i}` 作为源线，根据上述多线对变换算法，计算出 `p_{dest}` 在 `I_S` 中对应的源像素位置 `p_{source_S}`。 ii. **计算目标位置**：使用 `{L_i}` 作为目标线，`{D_i}` 作为源线，计算出 `p_{dest}` 在 `I_D` 中对应的源像素位置 `p_{source_D}`。 iii. **采样颜色**：在 `I_S` 和 `I_D` 中分别对 `p_{source_S}` 和 `p_{source_D}` 位置进行双线性插值，得到颜色 `Color_S` 和 `Color_D`。 iv. **交叉溶解**：计算最终颜色 `Color_t = (1 - t) * Color_S + t * Color_D`，并赋给 `I_t(p_{dest})`。
3.  **输出**：生成的所有中间帧 `I_t` 序列。

* * *

### **第三部分：代码实现 (Python/NumPy)**

下面我们给出一个基于特征线对的 Morphing 算法的简化 Python 实现，以帮助大家理解核心逻辑。

```python
import numpy as np
from PIL import Image
from scipy.interpolate import interp2d

# 定义一个线段的数据结构
class Line:
    def __init__(self, p1, p2):
        self.P = np.array(p1, dtype=float)
        self.Q = np.array(p2, dtype=float)

def warp_image(image, lines_src, lines_dst):
    """
    Warps an image based on source and destination lines.
    Inverse mapping: for each pixel in the destination grid, find its source.
    """
    height, width, _ = image.shape
    warped_img = np.zeros_like(image, dtype=np.uint8)

    # 创建一个坐标网格
    y_coords, x_coords = np.mgrid[0:height, 0:width]
    dest_pixels = np.stack([x_coords.ravel(), y_coords.ravel()], axis=1)

    # 参数
    a = 0.001
    b = 2.0
    p = 0.5
    
    displacements = np.zeros_like(dest_pixels, dtype=float)
    total_weights = np.zeros(len(dest_pixels), dtype=float)

    for line_src, line_dst in zip(lines_src, lines_dst):
        # 计算相对于目标线的 u, v
        vec_PQ_dst = line_dst.Q - line_dst.P
        vec_Perp_PQ_dst = np.array([-vec_PQ_dst[1], vec_PQ_dst[0]])
        len_sq_PQ_dst = np.dot(vec_PQ_dst, vec_PQ_dst)

        # 避免除以零
        if len_sq_PQ_dst == 0:
            len_sq_PQ_dst = 1e-6

        vec_XP_dst = dest_pixels - line_dst.P

        u = np.dot(vec_XP_dst, vec_PQ_dst) / len_sq_PQ_dst
        v = np.dot(vec_XP_dst, vec_Perp_PQ_dst) / np.sqrt(len_sq_PQ_dst)

        # 计算源像素位置
        vec_PQ_src = line_src.Q - line_src.P
        vec_Perp_PQ_src = np.array([-vec_PQ_src[1], vec_PQ_src[0]])
        len_PQ_src = np.sqrt(np.dot(vec_PQ_src, vec_PQ_src))
        
        # 避免除以零
        if len_PQ_src == 0:
            len_PQ_src = 1e-6
        
        # u 和 v 是向量化的，所以 X_src 也是
        X_src = line_src.P + u[:, np.newaxis] * vec_PQ_src + (v[:, np.newaxis] / len_PQ_src) * vec_Perp_PQ_src
        
        # 计算位移和权重
        D = X_src - dest_pixels
        
        # 计算 dist
        dist = np.zeros_like(u)
        # u < 0
        dist[u < 0] = np.linalg.norm(dest_pixels[u < 0] - line_dst.P, axis=1)
        # u > 1
        dist[u > 1] = np.linalg.norm(dest_pixels[u > 1] - line_dst.Q, axis=1)
        # 0 <= u <= 1
        mask = (u >= 0) & (u <= 1)
        dist[mask] = np.abs(v[mask])
        
        weight = (len(vec_PQ_dst)**p / (a + dist))**b
        
        displacements += D * weight[:, np.newaxis]
        total_weights += weight

    # 避免除以零
    total_weights[total_weights == 0] = 1e-6
    
    final_displacements = displacements / total_weights[:, np.newaxis]
    source_pixels = dest_pixels + final_displacements
    
    # 双线性插值采样颜色
    x_src = source_pixels[:, 0]
    y_src = source_pixels[:, 1]
    
    # 边界检查
    x_src = np.clip(x_src, 0, width - 1)
    y_src = np.clip(y_src, 0, height - 1)
    
    # 使用 floor 和 ceil 进行双线性插值
    x_floor, y_floor = np.floor(x_src).astype(int), np.floor(y_src).astype(int)
    x_ceil, y_ceil = np.ceil(x_src).astype(int), np.ceil(y_src).astype(int)
    
    x_ceil = np.clip(x_ceil, 0, width - 1)
    y_ceil = np.clip(y_ceil, 0, height - 1)

    # 计算插值权重
    dx = x_src - x_floor
    dy = y_src - y_floor

    # 采样四个点的颜色
    c00 = image[y_floor, x_floor]
    c01 = image[y_floor, x_ceil]
    c10 = image[y_ceil, x_floor]
    c11 = image[y_ceil, x_ceil]

    # 双线性插值
    c0 = c00 * (1 - dx)[:, np.newaxis] + c01 * dx[:, np.newaxis]
    c1 = c10 * (1 - dx)[:, np.newaxis] + c11 * dx[:, np.newaxis]
    color = c0 * (1 - dy)[:, np.newaxis] + c1 * dy[:, np.newaxis]

    warped_img[y_coords.ravel(), x_coords.ravel()] = color.astype(np.uint8)
    
    return warped_img


def morph(img_src, img_dst, lines_src, lines_dst, t):
    """
    Performs morphing between two images at time t.
    """
    # 1. 插值线段
    lines_t = []
    for ls, ld in zip(lines_src, lines_dst):
        p1_t = (1 - t) * ls.P + t * ld.P
        p2_t = (1 - t) * ls.Q + t * ld.Q
        lines_t.append(Line(p1_t, p2_t))
    
    # 2. 扭曲源图像和目标图像到中间形态
    warped_src = warp_image(img_src, lines_src, lines_t)
    warped_dst = warp_image(img_dst, lines_dst, lines_t)
    
    # 3. 交叉溶解
    morphed_img = ((1 - t) * warped_src.astype(float) + t * warped_dst.astype(float)).astype(np.uint8)
    
    return morphed_img

# --- 使用示例 ---
# 1. 加载图像 (确保尺寸相同)
# img1 = np.array(Image.open('source.jpg'))
# img2 = np.array(Image.open('destination.jpg'))

# 2. 定义特征线 (手动或用UI工具)
# lines1 = [Line((100, 120), (150, 125)), Line((200, 130), (250, 128))] # 示例源线
# lines2 = [Line((110, 115), (160, 118)), Line((210, 125), (260, 122))] # 示例目标线

# 3. 生成 Morphing 序列
# num_frames = 30
# for i in range(num_frames):
#     t = i / (num_frames - 1)
#     morphed_frame = morph(img1, img2, lines1, lines2, t)
#     Image.fromarray(morphed_frame).save(f'frame_{i:03d}.png')
```

**代码解读**：

*   我们使用 NumPy 进行向量化计算，这极大地提高了效率。代码一次性计算所有像素的 `u, v`、位移和权重。
*   `warp_image` 函数实现了核心的逆向映射和扭曲过程。
*   `morph` 函数封装了整个流程：插值线段、分别扭曲源和目标图像，最后进行交叉溶解。
*   代码中包含了详细的双线性插值实现，这是保证图像质量的关键。

* * *

### **第四部分：高级主题与拓展**

#### **4.1 过渡控制 (Transition Control)**

在我们的算法中，参数 `t` 是线性变化的。这意味着变形和颜色溶解的速度是恒定的。我们可以引入一个**非均匀过渡函数** `f(t)` 来控制节奏，创造更具戏剧性的效果。

例如，使用一个 "ease-in-ease-out" 函数，可以让变形在开始和结束时较慢，在中间阶段加速。 `t_effective = f(t) = t*t*(3 - 2*t)` 只需将算法中所有的 `t` 替换为 `t_effective` 即可。

#### **4.2 其他变形方法**

*   **径向基函数 (Radial Basis Functions, RBF)**：这种方法基于点对（而不是线对）的对应关系。每个点对定义一个径向基函数（如高斯函数或薄板样条函数），整个空间的变形是所有这些函数的线性组合。它非常适合处理分散的、非结构化的特征。
*   **移动最小二乘法 (Moving Least Squares, MLS)**：这是一种更强大、更灵活的变形技术。对于图像中的每个点，MLS 会计算一个局部的最佳仿射变换（或相似变换、刚性变换），而不是像 Beier-Neely 那样计算一个全局的加权位移。这使得 MLS 在保持图像局部结构方面表现得更好，产生的畸变更少。

#### **4.3 视域 Morphing (View Morphing)**

传统2D Morphing 的一个致命弱点是它不考虑三维空间和透视。当两张图像的拍摄视点不同时，直接进行2D Morphing 会产生严重的几何畸变。例如，三维空间中的一条直线，在 Morphing 过程中可能会弯曲。

**Seitz 和 Dyer 在1996年提出的视域 Morphing** 解决了这个问题。它旨在生成物理上正确的中间视点图像。

**核心思想**：将复杂的透视变换问题，通过重投影（reprojection）转化为简单的平行视图插值问题。

**三步算法**：

1.  **预扭曲 (Pre-warp)**：利用两幅图像的相机投影矩阵（或通过特征点计算出的基本矩阵），将源图像 `I_S` 和目标图像 `I_D` 分别进行透视变换，重投影到一个与相机基线平行的公共平面上，得到 `I_S'` 和 `I_D'`。在这些“校正”后的图像中，对应的点位于同一水平扫描线上。
2.  **Morphing**：对校正后的图像 `I_S'` 和 `I_D'` 进行简单的线性插值或2D Morphing。由于几何已经对齐，这个过程不会产生畸变，只是简单的像素混合和位移。
3.  **后扭曲 (Post-warp)**：将生成的中间帧 `I_t'` 从公共平面上，通过插值得到的中间相机矩阵，重投影回最终的中间视点，得到最终结果 `I_t`。

视域 Morphing 能够产生逼真的三维旋转效果，但它需要关于相机几何的额外信息。

**伪影处理**：

*   **折叠 (Folds)**：当一个在源视图中可见的表面在目标视图中被遮挡时发生。
*   **空洞 (Holes)**：当一个在源视图中被遮挡的表面在目标视图中变得可见时发生。 这些问题可以通过深度信息（或其近似值——**视差(disparity)**）来解决。通过 Z-Buffering 的思想，可以判断哪个表面应该在前面，从而正确处理遮挡关系。

* * *

### **第五讲：总结与展望**

#### **5.1 总结**

*   **核心原理**：图像扭曲 + 交叉溶解。
*   **主要算法**：
    *   **基于网格**：直观但控制繁琐。
    *   **基于特征线对 (Beier-Neely)**：控制直观，效果出色，是行业标准。我们深入了其数学推导和代码实现。
*   **高级拓展**：
    *   **过渡控制**：实现非线性动画节奏。
    *   **视域 Morphing**：通过结合相机几何，生成物理上更准确的中间视图，解决了传统2D Morphing 的透视畸变问题。

#### **5.2 局限性**

尽管二维 Morphing 功能强大，但它有其固有的局限性：

*   **缺乏三维信息**：无法处理光照、阴影和材质的变化。
*   **依赖人工标注**：无论是网格还是特征线，都需要大量的人工交互来指定对应关系。
*   **对大尺度变换敏感**：当源和目标差异巨大时，容易产生不自然的“幽灵”或撕裂效果。

#### **5.3 展望：深度学习的时代**

近年来，随着深度学习，特别是生成对抗网络（GANs）的发展，图像到图像的转换进入了一个新的纪元。像 StyleGAN、CycleGAN 等模型，可以学习到数据集中的高维特征分布，实现惊人的图像转换效果，例如人脸老化、性别转换、风格迁移等。

这些深度学习方法与我们今天学习的经典 Morphing 相比：

*   **优点**：通常不需要手动指定特征，可以生成更真实、细节更丰富的纹理，甚至能“想象”出被遮挡的部分。
*   **缺点**：可控性较差（“黑箱”操作），需要大量的训练数据，并且可能会产生与输入无关的、不可预测的结果。

经典 Morphing 技术以其**精确的可控性、对几何的直观操纵和不依赖大规模训练数据**的特点，在许多专业领域（如电影特效、医疗影像、科学可视化）中，至今仍然是不可或TAINI的工具。

掌握这些经典算法，不仅能让你理解计算机图形学的基石，更能为你将来理解和开发更先进的生成模型打下坚实的数学和工程基础。