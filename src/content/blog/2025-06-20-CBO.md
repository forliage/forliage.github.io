---
title: "技术拓展:基于代价的优化器（Cost-Based Optimizer, CBO）"
description: ""
pubDate: "2025-06-20"
heroImage: ""
---

## 技术拓展:基于代价的优化器（Cost-Based Optimizer, CBO）

 **在正文开始之前,说一说为什么会想到CBO**.在我们学习<数据库系统与设计>这门课程的时候,我们的大程作业是minisql,也即实现一个自己的迷你数据库,一个不得不考虑的问题就是对我们的数据库进行优化.我在完成了基本基本框架之后发现操作对select,insert等的速度影响是极大的(其实有很多的原因),为了提升数据库的质量,查询资料学习了CBO.(在课程作业中直接加入CBO且可以看到完整效果的代码是不公开的,若有需要请私信我,我的email在**关于**板块中).

 接下来我们进入正题,我们的目的就是理解"为什么我的SQL有时候快如闪电，有时候慢如蜗牛".

### 第一章：问题的提出 —— 为何需要“优化”？

想象一下，你是一位图书馆的管理员，有人向你借两本书：一本是《计算机科学导论》，另一本是雨果的《悲惨世界》。这两本书都在图书馆里，但你有两种寻找方式：

1.  **方案A：** 你先去“计算机”区域，找到《计算机科学导论》，然后走到“外国文学”区域，找到《悲惨世界》。
    
2.  **方案B：** 你先去“外国文学”区域，找到《悲惨世界》，然后走到“计算机”区域，找到《计算机科学导论》。
    

对于你来说，这两个方案最终都能完成任务，但所花费的时间和行走的距离可能差不多。

现在，我们把场景切换到数据库。假设你执行了这样一条SQL查询：

```sql

SELECT *

FROM students s

JOIN scores sc ON s.student_id = sc.student_id

WHERE s.major = '计算机科学'  AND sc.course_name = '数据库系统';

```

这条SQL的目的是找出所有“计算机科学”专业学生中，选修了“数据库系统”这门课的成绩。数据库为了得到结果，至少有两种执行路径（我们称之为**执行计划 (Execution Plan)**）：

1.  **计划A：**

*   第一步：扫描`students`表，筛选出所有`major = '计算机科学'`的学生。
    
*   第二步：对于每一个找到的学生，拿着他/她的`student_id`去`scores`表里查找`course_name = '数据库系统'`的记录。
    

2.  **计划B：**

*   第一步：扫描`scores`表，筛选出所有`course_name = '数据库系统'`的选课记录。
    
*   第二步：对于每一条找到的记录，拿着它的`student_id`去`students`表里查找`major = '计算机科学'`的学生。
    

这两个计划哪个更好呢？

直觉告诉我们，这取决于“计算机科学”专业的学生数量和“数据库系统”这门课的选课人数。

*   如果全校有10000名学生，但只有100人是计算机科学专业的。而“数据库系统”是一门有5000人选修的大热门课。
    
*   **计划A**：先从10000人里筛出100人，然后用这100个`student_id`去查询。
    
*   **计划B**：先从海量的选课记录中筛出5000条，然后用这5000个`student_id`去查询。
    
*   显然，**计划A**的计算量要小得多。
    
*   反之，如果全校只有20人选修了“数据库系统”，但“计算机科学”是一个有3000人的大学院。
    
*   此时，**计划B**就变得更优了。
    

**问题的核心来了：** 数据库本身并不知道哪个条件更“稀有”，哪个计划的“代价”更低。它如何能像我们一样做出明智的判断，选择那个最高效的执行计划呢？

这就是**查询优化器 (Query Optimizer)** 的使命。而CBO，就是那个能够进行智能判断的“大脑”。

* * *

### 第二章：CBO的核心思想 —— 万物皆有“代价”

在CBO出现之前，流行的是**基于规则的优化器（Rule-Based Optimizer, RBO）**。RBO非常“死板”，它有一系列的内置规则（比如：有索引就一定要用索引），然后按照规则的优先级来决定执行计划，它不关心表里有多少数据，数据是如何分布的。这就像一个只会按固定路线巡逻的机器人，不懂得变通。

而CBO则是一个“经济学家”，它的核心思想是：**为每一个可能的执行计划计算一个量化的“代价”（Cost），然后选择那个代价最小的计划去执行。**

这个“代价”是什么呢？它是一个估算值，主要由以下几部分组成：

*   **I/O代价：** 从磁盘读取数据页到内存的代价。这是最主要的代价，因为磁盘I/O比CPU计算慢几个数量级。
    
*   **CPU代价：** 处理内存中数据的代价，例如排序、哈希计算、比较等。
    
*   **网络代价：** 在分布式数据库中，节点间传输数据的代价。
    

为了简化模型，我们通常可以认为：

Total Cost≈I/O Cost+w⋅CPU Cost\\text{Total Cost} \\approx \\text{I/O Cost} + w \\cdot \\text{CPU Cost}Total Cost≈I/O Cost+w⋅CPU Cost

其中 www 是一个权重因子。在很多经典的模型里，为了教学和理解方便，甚至会直接将 **Cost等价于需要读取的磁盘页（Page/Block）的数量**。这个假设虽然粗糙，但抓住了主要矛盾。

**所以，CBO的工作流程可以概括为三步：**

1.  **生成候选计划：** 根据一条SQL，列出所有逻辑上等价的执行计划。
    
2.  **估算计划代价：** 为每一个候选计划计算一个总代价。
    
3.  **选择最优计划：** 选出代价最小的那个计划。
    

现在，最关键的问题来了：CBO是如何“未卜先知”，在不真正执行的情况下，估算出代价的呢？

* * *

### 第三章：CBO的基石 —— 统计信息

CBO不是神，它进行估算需要依据，这个依据就是数据库提前收集好的**统计信息（Statistics）**。这些信息描绘了数据的“长相”和“分布”，存储在系统表中。

常见的统计信息包括：

*   **表级别统计信息：**
    
*   `NumRows`: 表的总行数。
    
*   `NumPages` / `Blocks`: 表占用的数据块（页）数量。
    
*   **列级别统计信息：**
    
*   `Ndv` (Number of Distinct Values): 列中不重复值的数量。
    
*   `NullFreq`: NULL值的比例。
    
*   `Min/Max Value`: 列的最大值和最小值。
    
*   **直方图 (Histogram):** 这是非常重要的信息！它描述了列中数据的分布情况。例如，一个年龄列，大部分人可能集中在20-30岁，而不是均匀分布在0-100岁。直方图就能捕捉到这种不均匀性。
    
*   **索引级别统计信息：**
    
*   `Levels`: B+树索引的高度。
    
*   `LeafBlocks`: 索引的叶子节点占用的块数。
    
*   `Clustering Factor`: **聚簇因子**。一个至关重要的指标，表示索引键值的顺序与表中数据行物理存储顺序的匹配程度。聚簇因子越低，说明索引顺序和物理顺序越一致，通过索引范围扫描的效率越高。
    

数据库通过`ANALYZE TABLE`或自动任务来收集和更新这些统计信息。**如果统计信息是陈旧的、不准确的，CBO就会被误导，做出错误的判断（Garbage In, Garbage Out），这是导致SQL性能问题的常见原因。**

* * *

### 第四章：代价估算详解 —— 公式与推导

#### 4.1 核心概念：选择率（Selectivity）

**选择率（Selectivity）** 是一个过滤条件（如 `WHERE col = value`）能筛选出数据行数的比例，是代价估算中最基础、最重要的概念。它的值在0到1之间。

Selectivity (S)\=满足条件的行数总行数\\text{Selectivity (S)} = \\frac{\\text{满足条件的行数}}{\\text{总行数}}Selectivity (S)\=总行数满足条件的行数​

估算出的返回行数（我们称之为**基数 (Cardinality)**）就等于：

Cardinality\=NumRows×Selectivity \\text{Cardinality} = \\text{NumRows} \\times \\text{Selectivity} Cardinality\=NumRows×Selectivity

CBO如何估算不同条件的选择率呢？

**1\. 等值查询 (`column = value`)**

在没有详细数据分布信息（如直方图）时，CBO会假设数据是**均匀分布**的。

Scol\=val\=1Ndv(col)S\_{\\text{col}=\\text{val}} = \\frac{1}{\\text{Ndv}(\\text{col})}Scol\=val​\=Ndv(col)1​

*   **推导：** 假设列 `col` 有 `Ndv` 个不同的值，并且每个值出现的概率相等。那么任何一个特定值出现的概率就是 1/Ndv1/\\text{Ndv}1/Ndv。
    
*   **例子：** `students`表有10000行，`major`列有50个不同的专业（`Ndv('major') = 50`）。那么 `WHERE major = '计算机科学'` 的选择率估算为 1/50\=0.021/50 = 0.021/50\=0.02。估算的返回行数（基数）为 10000×0.02\=20010000 \\times 0.02 = 20010000×0.02\=200行。
    

**2\. 范围查询 (`column > value`)**

同样，在没有直方图的情况下，假设数据在 `min` 和 `max` 之间线性均匀分布。

Scol\>val\=MaxValue(col)−valMaxValue(col)−MinValue(col)S\_{\\text{col}>\\text{val}} = \\frac{\\text{MaxValue}(\\text{col}) - \\text{val}}{\\text{MaxValue}(\\text{col}) - \\text{MinValue}(\\text{col})}Scol\>val​\=MaxValue(col)−MinValue(col)MaxValue(col)−val​

*   **推导：** 这就是计算 `val` 在整个值域范围内的相对位置。
    
*   **例子：** `age`列的`min=18`, `max=60`。`WHERE age > 39` 的选择率估算为 (60−39)/(60−18)\=21/42\=0.5(60 - 39) / (60 - 18) = 21 / 42 = 0.5(60−39)/(60−18)\=21/42\=0.5。
    

**注意：** 如果有了直方图，CBO的估算会精确得多。它会查看直方图，计算出大于`val`的值具体落在了哪些“桶”里，然后根据桶的信息进行累加计算，而不是简单地假设线性分布。

**3\. 多个条件的组合**

*   **AND (`P1 AND P2`)**: 假设两个条件是相互独立的。

SP1 AND P2\=SP1×SP2S\_{P1 \\text{ AND } P2} = S\_{P1} \\times S\_{P2}SP1 AND P2​\=SP1​×SP2​

*   **OR (`P1 OR P2`)**: 根据集合的容斥原理，并假设独立性。

SP1 OR P2\=SP1+SP2−(SP1×SP2)S\_{P1 \\text{ OR } P2} = S\_{P1} + S\_{P2} - (S\_{P1} \\times S\_{P2})SP1 OR P2​\=SP1​+SP2​−(SP1​×SP2​)

**重要提示：** “条件独立”是一个非常强的假设，在现实世界中常常不成立（例如 `state = 'California'` 和 `city = 'Los Angeles'` 强相关）。这是CBO估算不准的另一个主要原因。现代数据库会通过多列统计信息等手段来缓解这个问题。

#### 4.2 访问路径的代价估算

有了基数估算，CBO就可以开始估算不同**访问路径 (Access Path)** 的代价了。

**1\. 全表扫描 (Full Table Scan, FTS)**

这是最简单的访问方式：读取表中的所有数据块。

Cost(FTS)\=NumPages\\text{Cost}(\\text{FTS}) = \\text{NumPages}Cost(FTS)\=NumPages

*   **例子：** `students` 表占用 500 个数据页，那么全表扫描的I/O代价就是 500。

**2\. 索引扫描 (Index Scan)**

这里情况复杂一些，取决于索引类型和需要扫描的数据量。

*   **唯一索引扫描 (Index Unique Scan):** 通过唯一索引查找单条记录，例如 `WHERE student_id = 123`。

Cost(Unique Scan)\=B-Tree Height+1\\text{Cost}(\\text{Unique Scan}) = \\text{B-Tree Height} + 1Cost(Unique Scan)\=B-Tree Height+1

*   **推导：** 代价约等于B+树的高度（通常是2-4，代表从根节点到叶子节点的I/O次数）+ 1次读取数据块的I/O。这是一个非常低的常数代价。
    
*   **索引范围扫描 (Index Range Scan):** 通过非唯一索引或范围条件查找一批数据，例如 `WHERE age > 39`。
    

Cost(Range Scan)≈(B-Tree Height)+(Selectivity×LeafBlocks)+(Cardinality×ClusteringFactor\_Adjusted)\\text{Cost}(\\text{Range Scan}) \\approx (\\text{B-Tree Height}) + (\\text{Selectivity} \\times \\text{LeafBlocks}) + (\\text{Cardinality} \\times \\text{ClusteringFactor\\\_Adjusted})Cost(Range Scan)≈(B-Tree Height)+(Selectivity×LeafBlocks)+(Cardinality×ClusteringFactor\_Adjusted)

*   **推导：**

1.  `B-Tree Height`: 定位到范围起点的索引叶子节点的I/O。
    
2.  `Selectivity × LeafBlocks`: 需要扫描的索引叶子块的数量。
    
3.  `Cardinality`: 估算出的返回行数。
    
4.  `ClusteringFactor_Adjusted`: 这是对**聚簇因子**的运用。它估算为了获取`Cardinality`这么多行数据，需要访问多少个**数据块**。
    

*   如果聚簇因子很低（数据物理有序），可能`Cardinality`行数据都集中在少数几个数据块里，这部分的I/O代价就很小。
    
*   如果聚簇因子很高（数据物理无序），极端情况下，每一行数据都来自不同的数据块，那么这部分I/O代价就是 `Cardinality`，这将是灾难性的。
    

CBO会比较 `Cost(FTS)` 和 `Cost(Index Scan)`。如果`WHERE`条件的选择率很低（筛选出的数据很少），那么索引扫描的代价通常会远低于全表扫描。反之，如果选择率很高（比如要查出表中50%的数据），CBO可能会发现全表扫描的顺序I/O反而比索引扫描的大量随机I/O更划算，从而放弃使用索引。**这就是为什么有时候加了索引SQL也不用索引的原因！**

#### 4.3 连接操作的代价估算

连接（Join）是CBO优化的重中之重，因为不同的连接算法和连接顺序，性能差异极大。

假设我们连接表 R (Outer Table) 和 S (Inner Table)。

**1\. 嵌套循环连接 (Nested Loop Join, NLJ)**

*   **算法：** 对外表R的每一行，都去内表S中查找匹配的行。
    
*   **代价公式：**
    

Cost(NLJ)\=Cost(Outer)+Cardinality(Outer)×Cost(Inner Access)\\text{Cost}(\\text{NLJ}) = \\text{Cost}(\\text{Outer}) + \\text{Cardinality}(\\text{Outer}) \\times \\text{Cost}(\\text{Inner Access})Cost(NLJ)\=Cost(Outer)+Cardinality(Outer)×Cost(Inner Access)

*   **推导：**

1.  `Cost(Outer)`: 访问外表的代价。
    
2.  `Cardinality(Outer)`: 外表经过过滤后返回的行数。
    
3.  `Cost(Inner Access)`: 对于外表的每一行，访问内表的代价。如果内表的连接键上有索引，这个代价会很低（类似于索引扫描）；如果没有，可能就是一次全表扫描，代价会非常高。
    

*   **适用场景：** 外表结果集很小，且内表的连接键上有高效索引。

**2\. 哈希连接 (Hash Join, HJ)**

*   **算法：**

1.  **Build Phase:** 选择小表（通常是R）作为构建表，在内存中基于连接键创建一个哈希表。
    
2.  **Probe Phase:** 扫描大表（S），用S的每一行的连接键去探测（Probe）哈希表，查找匹配项。
    

*   **代价公式（简化版）：**

Cost(HJ)≈Cost(Scan R)+Cost(Scan S)\\text{Cost}(\\text{HJ}) \\approx \\text{Cost}(\\text{Scan R}) + \\text{Cost}(\\text{Scan S})Cost(HJ)≈Cost(Scan R)+Cost(Scan S)

在I/O模型下，就是读取两个表的代价：

Cost(HJ)≈NumPages(R)+NumPages(S)\\text{Cost}(\\text{HJ}) \\approx \\text{NumPages}(R) + \\text{NumPages}(S)Cost(HJ)≈NumPages(R)+NumPages(S)

*   **推导：** 主要是对两个表进行一次全盘扫描的代价。CPU代价在于构建和探测哈希表。如果哈希表大到内存放不下，就需要写入临时磁盘文件，代价会急剧增加。
    
*   **适用场景：** 大数据量连接，特别是当连接键上没有索引时。它对等值连接（`ON R.key = S.key`）非常高效。
    

**3\. 排序归并连接 (Sort-Merge Join, SMJ)**

*   **算法：**

1.  **Sort Phase:** 分别对表R和表S按照连接键进行排序。
    
2.  **Merge Phase:** 像拉链一样，同步地扫描两个已排序的表，合并匹配的行。
    

*   **代价公式：**

Cost(SMJ)\=Cost(Sort R)+Cost(Sort S)+Cost(Merge)\\text{Cost}(\\text{SMJ}) = \\text{Cost}(\\text{Sort R}) + \\text{Cost}(\\text{Sort S}) + \\text{Cost}(\\text{Merge})Cost(SMJ)\=Cost(Sort R)+Cost(Sort S)+Cost(Merge)

排序的代价通常很高，如果数据量大，需要外部排序（使用磁盘）。`Cost(Sort)` 大致正比于 Nlog⁡NN \\log NNlogN。归并的代价则接近于一次线性扫描。

Cost(Merge)≈NumPages(R)+NumPages(S)\\text{Cost}(\\text{Merge}) \\approx \\text{NumPages}(R) + \\text{NumPages}(S)Cost(Merge)≈NumPages(R)+NumPages(S)

*   **适用场景：** 如果数据源本身已经是有序的，或者查询要求最终结果按连接键排序，SMJ就很有优势。也适用于非等值连接（如 `ON R.key > S.key`）。

* * *

### 第五章：实战演练 —— CBO如何决策

回到我们最初的例子：

```sql

SELECT *

FROM students s

JOIN scores sc ON s.student_id = sc.student_id

WHERE s.major = '计算机科学'  AND sc.course_name = '数据库系统';

```

假设有以下统计信息：

*   `students`: 10,000行 (`NumRows`), 500页 (`NumPages`)
    
*   `major`: 50个不同值 (`Ndv`)
    
*   `student_id` 是主键（有唯一索引）
    
*   `scores`: 200,000行, 4000页
    
*   `course_name`: 200个不同值
    
*   `student_id` 上有非唯一索引
    

CBO会评估多个可能的计划，我们来分析其中两个：

**计划A: `students`驱动`scores` (NLJ)**

1.  **访问`students`表:**

*   条件: `s.major = '计算机科学'`
    
*   选择率: Ss\=1/Ndv(major)\=1/50\=0.02S\_s = 1 / \\text{Ndv(major)} = 1/50 = 0.02Ss​\=1/Ndv(major)\=1/50\=0.02
    
*   基数: Cards\=10000×0.02\=200\\text{Card}\_s = 10000 \\times 0.02 = 200Cards​\=10000×0.02\=200 行
    
*   访问方式: `major`上若无索引，则全表扫描。Cost ≈ `NumPages(s)` = 500。
    

2.  **访问`scores`表 (for each of 200 students):**

*   连接条件: `sc.student_id = ?` (来自`students`表)
    
*   过滤条件: `sc.course_name = '数据库系统'`
    
*   访问方式: 使用`scores`表上`student_id`的索引。每次访问代价很低，假设为 `Cost(idx_access)` ≈ 3 (B-Tree Height + 1)。
    

3.  **总代价 (估算):**

Cost(Plan A)\=Cost(Access students)+Cards×Cost(Access scores per student)≈500+200×3\=1100\\begin{align\*} \\text{Cost}(\\text{Plan A}) &= \\text{Cost}(\\text{Access students}) + \\text{Card}\_s \\times \\text{Cost}(\\text{Access scores per student}) \\\\ &\\approx 500 + 200 \\times 3 \\\\ &= 1100 \\end{align\*}Cost(Plan A)​\=Cost(Access students)+Cards​×Cost(Access scores per student)≈500+200×3\=1100​

(这里忽略了对`course_name`的过滤，因为在索引查找`student_id`后，这个过滤是在内存中完成的，CPU代价，I/O代价小)

**计划B: `scores`驱动`students` (NLJ)**

1.  **访问`scores`表:**

*   条件: `sc.course_name = '数据库系统'`
    
*   选择率: Ssc\=1/Ndv(course\_name)\=1/200\=0.005S\_{sc} = 1 / \\text{Ndv(course\\\_name)} = 1/200 = 0.005Ssc​\=1/Ndv(course\_name)\=1/200\=0.005
    
*   基数: Cardsc\=200000×0.005\=1000\\text{Card}\_{sc} = 200000 \\times 0.005 = 1000Cardsc​\=200000×0.005\=1000 行
    
*   访问方式: `course_name`上若无索引，则全表扫描。Cost ≈ `NumPages(sc)` = 4000。
    

2.  **访问`students`表 (for each of 1000 scores):**

*   连接条件: `s.student_id = ?`
    
*   访问方式: 使用`students`表上`student_id`的主键索引。每次访问代价极低，`Cost(pk_access)` ≈ 2。
    

3.  **总代价 (估算):**

Cost(Plan B)\=Cost(Access scores)+Cardsc×Cost(Access students per score)≈4000+1000×2\=6000\\begin{align\*} \\text{Cost}(\\text{Plan B}) &= \\text{Cost}(\\text{Access scores}) + \\text{Card}\_{sc} \\times \\text{Cost}(\\text{Access students per score}) \\\\ &\\approx 4000 + 1000 \\times 2 \\\\ &= 6000 \\end{align\*} Cost(Plan B)​\=Cost(Access scores)+Cardsc​×Cost(Access students per score)≈4000+1000×2\=6000​

**决策:** `Cost(Plan A)` = 1100 << `Cost(Plan B)` = 6000。因此，CBO会明智地选择**计划A**。

CBO还会考虑**Hash Join**。其代价约为 `NumPages(s) + NumPages(sc) = 500 + 4000 = 4500`。这个代价介于A和B之间，所以CBO依然会选择计划A。

**思考：** 如果我们在`students.major`和`scores.course_name`上都建立了索引，CBO的计算会如何变化？它会重新计算索引扫描的代价，然后可能会发现一个全新的、更优的计划！