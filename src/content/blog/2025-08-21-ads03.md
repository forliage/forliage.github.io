---
title: "ads03:倒排文件索引（Inverted File Index）"
description: ""
pubDate: "2025-08-21"
heroImage: ""
---

# ads03:倒排文件索引（Inverted File Index）

### Part 1: 问题的提出 —— 信息的汪洋中如何航行？

我们每天都在使用搜索引擎。想象一下，当你在搜索框里输入“Computer Science”时，搜索引擎如何在不到一秒的时间内，从数千亿的网页中，精确地找出包含这个词组的页面，并呈现给你？

这就是我们今天课程要解决的核心问题：**如何快速地找到在哪些文档中包含了我们想要查询的关键词？**

面对这个问题，我们最直观的想法是什么？

#### 解决方案 1: 暴力扫描法 (Scan each page)

最简单粗暴的方法就是：把所有网页（文档）都看作一个长长的字符串，然后一篇一篇地去扫描，看看里面有没有“Computer Science”这个子串。

这个方法可行吗？理论上可行。但现实呢？Google索引了超过10亿的网页。假设每篇网页平均100KB，扫描一篇需要1毫秒，那么扫描完所有网页需要：

1,000,000,000 (网页) \* 0.001 (秒/网页) = 1,000,000 秒 ≈ 11.5 天

当你得到结果时，可能已经是很久的事情了。所以，这个方案在现实世界中是完全不可接受的。我们需要更聪明的办法。

#### 解决方案 2: 词项-文档关联矩阵 (Term-Document Incidence Matrix)

既然逐篇扫描太慢，我们能不能预先处理好所有文档，建立一张“速查表”呢？一个自然的想法就是**词项-文档关联矩阵**。

我们把所有文档中出现过的词提取出来，作为矩阵的行；把所有文档的编号作为矩阵的列。如果一个词在某篇文档中出现，就在对应的单元格记为`1`，否则记为`0`。

**【示例】** 假设我们有以下4个文档（Document sets）：

*   **Doc 1:** Gold silver truck
*   **Doc 2:** Shipment of gold damaged in a fire
*   **Doc 3:** Delivery of silver arrived in a silver truck
*   **Doc 4:** Shipment of gold arrived in a truck

我们可以构建出如下的矩阵：

Term

Doc 1

Doc 2

Doc 3

Doc 4

a

0

1

1

1

arrived

0

0

1

1

damaged

0

1

0

0

delivery

0

0

1

0

fire

0

1

0

0

gold

1

1

0

1

of

0

1

1

1

in

0

1

1

1

shipment

0

1

0

1

silver

1

0

1

0

truck

1

0

1

1

现在，如果我们想查询包含 `silver` **并且** `truck` 的文档，该怎么做？

1.  找到 `silver` 对应的行向量： `[1, 0, 1, 0]`
2.  找到 `truck` 对应的行向量： `[1, 0, 1, 1]`
3.  对这两个向量进行\*\*按位与(AND)\*\*操作： `[1, 0, 1, 0] & [1, 0, 1, 1] = [1, 0, 1, 0]`

结果向量中为`1`的位置，就是同时包含这两个词的文档，即 Doc 1 和 Doc 3。这个方法在逻辑上非常清晰，查询也很快。

**但它的致命缺陷是什么？**

1.  **极度稀疏 (Sparsity)**：想象一下，英语词汇量可能有几十万，而网页数量是千亿级别。这个矩阵的绝大多数单元格都会是 `0`。这造成了巨大的存储空间浪费。
2.  **难以扩展 (Scalability)**：每增加一个新词或一篇新文档，就需要给这个巨大的矩阵增加一行或一列。维护成本极高。

**数学分析：** 该矩阵的空间复杂度为 **O(|V| × |D|)**，其中 |V| 是词典中词项的总数，|D| 是文档的总数。对于Web规模的数据，|V| 在百万级，|D| 在千亿级，这个矩阵的大小是天文数字，任何现代计算机都无法存储。

所以，词项-文档矩阵虽然在思路上进了一步，但依然不实用。我们需要一种只存储“有效信息”（也就是那些 `1` 的位置）的数据结构。

* * *

### Part 2: 核心利器 —— 倒排索引 (Inverted File Index)

#### 解决方案 3: 倒排索引

倒排索引正是为了解决矩阵稀疏性问题而生的。它的核心思想非常简单：**我们不记录词在哪个文档中“没有出现”，只记录它“在哪里出现了”**。

**【定义】**

*   **索引 (Index)**: 是一种用于快速定位文本中给定词项的机制。
*   **倒排文件/倒排索引 (Inverted File)**: 它包含了一个从**词项(Term)**到其出现位置的**指针列表**的映射。这个“位置”通常是指向文档的ID。

之所以称为“倒排”，是因为它颠倒了“文档 -> 词项”的自然关系，变成了“**词项 -> 文档**”。

一个倒排索引主要由两部分组成：

1.  **词典 (Dictionary/Vocabulary)**: 包含了系统中所有的词项。
2.  **倒排列表 (Postings List)**: 对于词典中的每个词项，都有一个与之对应的列表，记录了包含该词项的所有文档的ID。

**【示例】** 还是用上面的4个文档作为例子，我们可以构建出这样的倒排索引：

graph TD subgraph "词典 (Dictionary)" direction LR A\[fire\] B\[gold\] C\[of\] D\[in\] E\[shipment\] F\[silver\] G\[truck\] end subgraph "倒排列表 (Postings Lists)" direction LR P1\["\[2\]"\] P2\["\[1, 2, 4\]"\] P3\["\[2, 3, 4\]"\] P4\["\[2, 3, 4\]"\] P5\["\[2, 4\]"\] P6\["\[1, 3\]"\] P7\["\[1, 3, 4\]"\] end A --> P1 B --> P2 C --> P3 D --> P4 E --> P5 F --> P6 G --> P7

这个结构清晰地展示了：词`gold`出现在文档1, 2, 4中；词`silver`出现在文档1, 3中。

现在，再来处理查询 `silver & truck`：

1.  从词典中找到 `silver`，获取其倒排列表: `[1, 3]`
2.  从词典中找到 `truck`，获取其倒排列表: `[1, 3, 4]`
3.  **求两个列表的交集**: `intersect([1, 3], [1, 3, 4]) = [1, 3]`

我们得到了结果 Doc 1 和 Doc 3，与矩阵法一致，但存储效率天差地别！我们只存储了有用的信息。

#### 扩展倒排索引：不仅仅是出现

一个基础的倒排索引只能回答“是否出现”的问题，但现代搜索引擎需要更多信息，比如：

*   这个词在一个文档里出现了多少次？（**词频 Frequency**）
*   它具体出现在文档的哪个位置？（**位置信息 Position**）
*   如何根据相关性对结果排序？
*   如何高亮显示搜索结果中的关键词？

为了支持这些功能，我们需要一个更完备的倒排索引结构。

No.

Term

Times; Doc ID, Word Position(s)

...

...

...

5

fire

<1; (2;7)>

6

gold

< 3; (1;1), (2;3), (4;3)>

...

...

...

10

silver

<2; (1;2), (3;3)>

11

truck

< 3; (1;3), (3;8), (4;7)>

这里的 `<3; (1;1), (2;3), (4;3)>` 表示：词 `gold`

*   总共出现了 **3** 次 (Times/Frequency)
*   出现在文档 **1** 的第 **1** 个位置。
*   出现在文档 **2** 的第 **3** 个位置。
*   出现在文档 **4** 的第 **3** 个位置。

现在我们可以回答之前提出的两个问题了：

1.  **如何高亮显示关键词？** 有了位置信息，当我们要展示文档3给用户时，我们知道 `silver` 出现在第3个词的位置，`truck` 出现在第8个词的位置。我们可以在渲染页面时，轻松地给这些位置的词加上高亮标签（如HTML的`<strong>`）。
    
2.  **为什么我们要保留"times" (词频)？** 词频是**相关性排序 (Relevance Ranking)** 的基石。直觉上，一篇文档中出现“搜索引擎”10次，比只出现1次的文档，更可能与“搜索引擎”这个主题相关。词频是计算著名的 **TF-IDF** 等排序算法的核心要素之一。我们稍后会详细讲解。
    

* * *

### Part 3: 倒排索引的构建 (Index Generation)

了解了倒排索引的结构，我们来看看如何从原始文档集合构建它。这个过程通常是一个流水线作业。

#### 构建流程伪代码

```
// 初始化一个空的倒排索引
InvertedIndex index = new InvertedIndex();

while (还有未处理的文档 D) {
    // 读取一篇文档
    document D = read_a_document();
    
    // 对文档进行分词
    tokens = tokenize(D.content);
    
    while (tokens 中还有词项 T) {
        // 读取一个词项
        term T = read_a_term(tokens);
        
        // 查找词典中是否已有该词
        if ( !index.dictionary.contains(T) ) {
            // 如果没有，添加到词典，并创建一个新的倒排列表
            index.dictionary.add(T);
            index.postings.add(new PostingList());
        }
        
        // 获取该词项的倒排列表
        PostingList posting_list = index.get_posting_list(T);
        
        // 将当前文档信息（ID, 频率, 位置）添加到倒排列表中
        posting_list.add_node(D.ID, ...);
    }
}

// 将构建好的索引写入磁盘
write_index_to_disk(index);
```

这个流程中，`tokenize(D.content)` 并不是简单的按空格切分，它包含了一系列重要的预处理步骤。

#### 文本预处理

**1\. 词干提取 (Word Stemming) 与 词形还原 (Lemmatization)** 在搜索时，用户输入 `running`，他可能也想看到包含 `run` 或 `ran` 的结果。为了实现这一点，我们需要将这些词的不同形态统一为它们的原型或词干。

*   **词干提取 (Stemming)**: 一种比较粗暴的、基于规则的方法，直接砍掉词的后缀。例如，`processing`, `processes`, `processed` 可能都会被处理成 `process`。
*   **词形还原 (Lemmatization)**: 一种更精细的、基于词典和形态学分析的方法，将词还原为它的基本形态（lemma）。例如，`said` 会被还原为 `say`，`better` 会被还原为 `good`。

```
     says
     said     ──>  process  ──>   say
     saying
```

**2\. 停用词 (Stop Words) 移除** 像 `a`, `the`, `in`, `of`, `it` 这样的词，在几乎所有文档中都大量出现。它们对表达文档的核心主题意义不大，但会占用大量的索引空间，并在查询处理时增加不必要的计算。这些词被称为“停用词”，我们通常在索引前将它们剔除。

#### 数据结构的选择

构建索引时，我们需要一个高效的数据结构来存储**词典**，以便快速查找、插入。

**【讨论】** 在访问词典时，使用**哈希表 (Hashing)** 和**搜索树 (Search Trees)** 各有什么优缺点？

**1\. 哈希表 (e.g., C++ `std::unordered_map`)**

*   **优点**:
    *   **速度极快**：平均查找、插入和删除的时间复杂度为 **O(1)**。
*   **缺点**:
    *   **无序性**：哈希表不保留词项的顺序。这使得它无法支持**范围查询**或**前缀查询**（例如，查找所有以 `comp*` 开头的词）。
    *   **空间开销**：为了维持低冲突率，哈希表通常需要预留比实际元素更多的空间（较低的装载因子）。
    *   **哈希冲突**：虽然有好的哈希函数可以缓解，但冲突处理总会带来一些性能开销。

**2\. 搜索树 (e.g., B-Tree, B+Tree, C++ `std::map`)**

*   **优点**:
    *   **有序性**：树结构（特别是B树）本身就是有序的，可以高效地支持范围查询和前缀查询。这对于实现搜索建议（autocomplete）等功能至关重要。
    *   **性能稳定**：最坏情况下的时间复杂度为 **O(log N)**，没有哈希表的极端情况。
*   **缺点**:
    *   **速度稍慢**：O(log N) 普遍慢于 O(1)。
    *   **实现复杂**：相比哈希表，平衡树的实现和维护更复杂。
    *   **空间开销**：每个节点需要存储指向子节点的指针，有额外的空间开销。

**结论**：在实际的搜索引擎中，常常是两者结合使用。例如，使用\*\*Trie树（字典树）\*\*或其变种来存储词典，它在支持前缀查询方面表现出色，同时空间效率也高。而对于一些内部查找，哈希表因其速度优势仍被广泛应用。

**C++代码示例 (数据结构定义)**

```cpp
#include <iostream>
#include <vector>
#include <string>
#include <map>
#include <unordered_map>
#include <algorithm>

// 表示一个词项在某个文档中的具体信息
struct Posting {
    int doc_id;
    int frequency;
    std::vector<int> positions;
};

// 倒排列表是一个Posting的向量
using PostingList = std::vector<Posting>;

// 基于搜索树（红黑树）的倒排索引
using TreeBasedInvertedIndex = std::map<std::string, PostingList>;

// 基于哈希表的倒排索引
using HashBasedInvertedIndex = std::unordered_map<std::string, PostingList>;
```

* * *

### Part 4: 应对海量数据 —— 扩展性设计

#### 1\. 内存不足问题：单机大规模索引构建 (SPIMI)

当文档集合非常大，以至于无法在内存中一次性构建整个倒排索引时，我们怎么办？

这里介绍一种广泛使用的算法：**单遍在内存索引 (Single-Pass In-Memory Indexing, SPIMI)**。

**核心思想**：分而治之，然后合并。

1.  **分块处理**：从磁盘读取文档，在内存中构建一个“临时”倒排索引，直到内存快要用完。
2.  **块内排序**：对这个内存中的临时索引，按**词项**进行字母序排序。
3.  **写入磁盘**：将这个排好序的临时索引块完整地写入磁盘。
4.  **重复**：清空内存，继续处理下一批文档，生成下一个排好序的索引块。
5.  **多路归并**：当所有文档都处理完毕后，磁盘上会有一堆按词项排序的索引块。最后，执行一个**多路归并排序 (multi-way merge)**，将这些块合并成一个最终的、巨大的、有序的倒排索引。

这个过程巧妙地利用了外部排序的思想，使得我们可以在有限的内存下，处理几乎无限大的文档集合。

#### 2\. Web级索引：分布式索引 (Distributed Indexing)

当数据量达到千亿网页级别时，单台机器无论如何也无法存储和处理。这时必须采用分布式集群。有两种主流的分布式索引策略：

**策略一: 按词项分区 (Term-partitioned Index)** 将词典切分，分配到不同的机器上。

*   机器 A 负责 `a` - `c` 开头的词
    
*   机器 B 负责 `d` - `f` 开头的词
    
*   ...
    
*   机器 Z 负责 `x` - `z` 开头的词
    
*   **查询处理**：一个查询，如 "distributed indexing"，需要被分发到 "d" 所在的机器和 "i" 所在的机器，分别获取倒排列表，然后由一个聚合节点合并结果。
    
*   **优缺点**：并发性好，但跨节点的查询会增加网络开销和延迟。
    

**策略二: 按文档分区 (Document-partitioned Index)** 将文档集合切分，每台机器负责一个子集，并为这个子集建立一个**完整**的倒排索引。

*   机器 A 负责文档 1 ~ 1000万
    
*   机器 B 负责文档 1001万 ~ 2000万
    
*   ...
    
*   **查询处理**：一个查询需要被广播到**所有**的机器上。每台机器在自己的索引上进行查询，返回局部结果。最后由一个聚合节点合并所有局部结果。
    
*   **优缺点**：扩展性极好，增加新文档只需增加新机器。查询时并行度高。这是当今大型搜索引擎（如Google）采用的主流方案，通常被称为**分片 (Sharding)**。
    

#### 3\. 动态索引 (Dynamic Indexing)

互联网是动态变化的，新的网页不断产生，旧的网页可能被删除或修改。我们不可能每天都重新构建整个索引。

解决方案是采用 **主-辅索引 (Main-Auxiliary Index)** 结构。

graph TD subgraph Legend direction LR NewDocs((New Docs)) MainIndex\[\[Main Index\]\] AuxIndex\[(Auxiliary Index)\] SearchResults\[Search Results\] Merge(Periodic Merge) end NewDocs --> AuxIndex MainIndex -- Query --> SearchResults AuxIndex -- Query --> SearchResults AuxIndex -- Merge --> MainIndex

*   **主索引 (Main Index)**: 一个巨大的、静态的、存储在磁盘上的索引，它不直接接受修改。
*   **辅助索引 (Auxiliary Index)**: 一个较小的、动态的、通常存储在内存中的索引。所有新来的文档都先被加入到这个索引中。
*   **删除列表 (Deletion List)**: 当一个文档被删除时，我们不立即从主索引中移除它（因为磁盘操作很慢），而是将其ID记录在一个“删除列表”中。

**查询流程**:

1.  用户发起查询。
2.  系统同时查询**主索引**和**辅助索引**。
3.  合并两边的结果。
4.  使用**删除列表**过滤掉已删除的文档。
5.  返回最终结果给用户。

**【回答问题】**

*   **何时重建索引 (Re-index)?** 当辅助索引变得太大，或者删除列表过长时，查询性能会下降。此时，系统会触发一个**合并 (Merge)** 操作：将辅助索引中的内容合并到主索引中，并真正地移除被标记为删除的文档，生成一个新的、干净的主索引。这个过程在后台进行，不影响线上服务。
    
*   **如何删除文档?** 采用**逻辑删除**。即，只将其ID加入删除列表，而不是物理删除。物理删除留到下一次合并时进行。
    

* * *

### Part 5: 性能优化与评估

#### 1\. 索引压缩 (Compression)

倒排索引，特别是倒排列表，会占用巨大的存储空间。压缩是必不可少的。

*   **词典压缩**: 对于排好序的词典，相邻的词项通常有共同的前缀。可以使用**前缀编码 (Front Coding)** 等技术来压缩。 `arrived, damaged, deliver, fire, ...` -> `arrivedamagedeliverfire...` + 指针
    
*   **倒排列表压缩**: 这是压缩的重点。 一个词的倒排列表（文档ID列表）是**单调递增**的。 `computer` -> `[2, 15, 47, ..., 58879, 58890, ...]`
    
    我们可以不存储原始ID，而是存储ID之间的**差值 (Gap / Delta)**。 `computer` -> `[2, 13, 32, ..., (gap), 11, ...]`
    
    这些差值通常是小数字，而小数字可以用更少的比特位来表示。**可变字节编码 (Variable Byte Encoding)** 或 **Gamma/Delta 编码**等技术就是专门用来高效存储这些小整数的。这可以极大地减少索引的磁盘占用，同时由于读取的数据量变小，也能提升I/O速度。
    

#### 2\. 查询处理优化：阈值法 (Thresholding)

对于一个热门查询，可能有上百万个匹配的文档。用户只关心前10个或前20个最相关的结果。我们没有必要为所有一百万个文档都计算精确的相关性得分。

*   **文档阈值**: 只计算排名前 `k` 个文档的得分。例如，基于一些静态质量分（如PageRank）先筛选出高质量的文档，只在这些文档中进行详细匹配。
*   **词项阈值**: 对于一个长查询（比如10个词），我们可以先用最稀有（IDF值最高）的2-3个词进行查询，找到一个候选文档集合，然后再用剩下的词在这个小得多的集合里进行打分和过滤。

#### 3\. 搜索引擎的评估指标

一个搜索引擎的好坏，可以从多个维度来衡量：

*   **效率 (Efficiency)**
    *   **索引速度**: 每小时能处理多少文档？
    *   **查询速度 (Latency)**: 返回查询结果需要多长时间？
*   **表达能力 (Expressiveness)**
    *   查询语言是否强大？能否支持复杂的布尔逻辑、短语查询、模糊查询？
*   **用户满意度 (User Happiness)**: 这是最终极、也最难衡量的指标。

为了量化用户满意度，信息检索领域引入了两个核心的学术指标：**精确率 (Precision)** 和 **召回率 (Recall)**。

要进行评测，我们需要：

1.  一个标准的**文档集合**。
2.  一个标准的**查询集合**。
3.  对于每个查询，由专家**人工标注**出文档集中哪些是相关的，哪些是不相关的。

然后，我们可以定义：

*   **RR (Retrieved Relevant)**: 检索到的，并且是相关的文档。
*   **IR (Retrieved Irrelevant)**: 检索到的，但是不相关的文档（误报）。
*   **RN (Retrieved Not)**: 未检索到，但是相关的文档（漏报）。

graph TD subgraph "整个文档集合" subgraph "相关文档 (Relevant Docs)" RR RN end subgraph "不相关文档 (Irrelevant Docs)" IR IN("IN: 未检索到的不相关文档") end subgraph "检索到的结果 (Retrieved)" style RR fill:#f9f,stroke:#333,stroke-width:2px style IR fill:#ccf,stroke:#333,stroke-width:2px RR IR end end

*   **精确率 (Precision)**: 在你返回的结果中，有多少是用户真正想要的？ **P = RR / (RR + IR)** _追求高精确率，意味着“宁缺毋滥”。_
    
*   **召回率 (Recall)**: 在所有用户想要的结果中，你返回了多少？ **R = RR / (RR + RN)** _追求高召回率，意味着“宁滥勿缺”。_
    

**精确率与召回率的权衡 (Precision-Recall Tradeoff)** 这两者通常是相互矛盾的。

*   为了提高召回率，搜索引擎可能会放宽标准，返回更多可能相关的结果，但这也会引入更多不相关的“垃圾”，导致精确率下降。
*   为了提高精确率，搜索引擎会采用非常严格的标准，只返回非常有把握的结果，但这可能会漏掉一些同样相关但不那么匹配的结果，导致召回率下降。

理想的搜索引擎是在右上角（精确率和召回率都为1），但现实中我们只能在这条曲线上寻找一个平衡点。

* * *

### Part 6: 提升相关性 —— 不止是匹配

**【讨论】** 如何提升搜索结果的相关性？ 仅仅找到包含查询词的文档是远远不够的。我们需要对结果进行排序，把最可能满足用户需求的排在最前面。

1.  **基于内容的排序算法：TF-IDF** 我们之前提到了词频 (TF)。一个词在文档中出现次数越多，越可能相关。但我们还需要考虑一个词的“区分度”。
    
    *   **TF (Term Frequency)**: 词 t 在文档 d 中出现的频率。
    *   **IDF (Inverse Document Frequency)**: 逆文档频率。一个词在越多的文档中出现，它的区分度就越低（如“的”、“是”），IDF值就越小。反之，一个词越稀有，IDF值越大。 **IDF(t) = log(总文档数 / 包含词 t 的文档数)**
    *   **TF-IDF Score**: `Score(t, d) = TF(t, d) * IDF(t)` 一个文档的总得分，可以是查询中所有词的TF-IDF得分之和。
2.  **基于链接分析的算法：PageRank** Google的成名绝技。它的核心思想是：一个网页的重要性，取决于指向它的其他网页的数量和质量。一个被很多“重要”网页链接的网页，自己也很可能是一个重要的网页。PageRank是一种独立于查询的、对网页的静态质量评分。
    
3.  **向量空间模型 (Vector Space Model)** 将文档和查询都表示为高维空间中的一个向量，向量的每一维对应一个词，值可以是TF-IDF。然后通过计算查询向量和文档向量之间的**余弦相似度 (Cosine Similarity)** 来判断它们的相关性。夹角越小，相似度越高。
    
4.  **现代搜索引擎的综合策略** 现代搜索引擎的排序模型极其复杂，是一个综合了上百种特征（features）的机器学习模型。这些特征包括：
    
    *   内容相关性（TF-IDF, BM25等）
    *   网页质量（PageRank, TrustRank等）
    *   用户行为数据（点击率、停留时间等）
    *   查询的上下文和个性化信息（用户历史、地理位置等）

* * *

### Part 7: 实践项目与总结

#### 迷你搜索引擎实现伪代码

现在，让我们把今天学到的知识串起来，构思一个迷你搜索引擎的完整实现流程。

**数据结构定义**

```cpp
// 在前面已定义
struct Posting { ... };
using PostingList = std::vector<Posting>;
using InvertedIndex = std::map<std::string, PostingList>;
```

**1\. 索引构建模块 `buildIndex`**

```
function buildIndex(document_collection):
    index = new InvertedIndex()
    stop_words = load_stop_words()
    doc_id = 0

    for each document in document_collection:
        doc_id++
        content = document.text
        
        // 1. 分词
        tokens = tokenize(content)
        position = 0
        
        // 统计词频
        term_frequencies = new Map<string, vector<int>>()
        
        for each token in tokens:
            position++
            
            // 2. 预处理
            normalized_token = to_lower_case(token)
            if stop_words.contains(normalized_token):
                continue
            stemmed_token = stem(normalized_token)
            
            // 记录词频和位置
            if not term_frequencies.has(stemmed_token):
                term_frequencies[stemmed_token] = new vector<int>()
            term_frequencies[stemmed_token].push(position)

        // 3. 更新倒排索引
        for each term, positions in term_frequencies:
            if not index.has(term):
                index[term] = new PostingList()
            
            posting = new Posting(doc_id, positions.size(), positions)
            index[term].push(posting)
            
    return index
```

**2\. 查询处理模块 `performQuery`**

```
function intersect_postings(list1, list2):
    // 高效的列表求交集算法（使用双指针）
    result = new PostingList()
    p1 = 0, p2 = 0
    while p1 < list1.size() and p2 < list2.size():
        if list1[p1].doc_id == list2[p2].doc_id:
            // 这里可以合并posting信息，但为简化，只保留一个
            result.push(list1[p1])
            p1++, p2++
        else if list1[p1].doc_id < list2[p2].doc_id:
            p1++
        else:
            p2++
    return result

function performQuery(query_string, index):
    // 1. 解析查询
    query_terms = parse_and_process_query(query_string) // 分词、小写、词干化等
    
    if query_terms is empty:
        return []
    
    // 2. 获取倒排列表并求交集 (处理 AND 查询)
    result_postings = index[query_terms[0]]
    for i = 1 to query_terms.size() - 1:
        current_postings = index[query_terms[i]]
        result_postings = intersect_postings(result_postings, current_postings)
        
    // 3. 计算得分 (这里用一个简化的得分：词频之和)
    scored_results = []
    for each posting in result_postings:
        score = calculate_score(posting, query_terms, index) // e.g., TF-IDF
        scored_results.push({doc_id: posting.doc_id, score: score})

    // 4. 排序
    sort scored_results by score in descending order
    
    // 5. 返回结果
    return scored_results
```