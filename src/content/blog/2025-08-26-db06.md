---
title: "数据库系统设计01:存储与文件结构"
description: ""
pubDate: "2025-08-26"
heroImage: ""
---

# 数据库系统设计01:存储与文件结构

数据库系统，它的核心使命是**持久化**，这意味着它必须生活在磁盘的“炼狱”里。在这个炼狱中，空间不是连续的，访问不是瞬时的，延迟是巨大的，失败是常态。

这节课，我们将扮演一个数据库内核设计师的角色，直面四大“元问题” (Meta-Problems)：

1.  **时空鸿沟 (The Space-Time Gulf):** 如何弥合CPU与磁盘之间高达$10^7$倍的速度差异？
2.  **逻辑与物理的转换 (The Logical-Physical Translation):** 如何将逻辑上的“表”和“行”映射到物理上的磁道和闪存单元？
3.  **无序中的有序 (The Order within Chaos):** 如何在充满随机更新和删除的混乱操作中，维持数据的有序性和高性能访问？
4.  **信任与控制的博弈 (The Trust vs. Control Dilemma):** 我们应该在多大程度上信任并利用操作系统，又在何处必须“夺权”，构建自己的王国？

这四个问题，就是我们今天探索的路线图。每一种技术，每一个算法，都是对这些问题的一个回答。

### **第一部分：存储介质的物理真相与存储体系的必然性**

#### **1.1 存储介质的“物理宿命”**

一切设计的起点，是对工具的深刻理解。我们的工具就是物理存储介质，它们各自带有无法摆脱的“宿命”。

**深度对比：HDD vs. SSD vs. NVM (新兴技术)**

特性维度

机械硬盘 (HDD)

固态硬盘 (SSD)

非易失性内存 (NVM / PMem)

**设计哲学启示**

**物理原理**

磁性涂层，机械臂

浮栅晶体管，电荷囚禁

相变材料(PCM), MRAM

物理原理决定了性能模型，软件必须适配。

**访问单元**

**扇区(Sector)**, 512B/4KB

**页(Page)**, 4-16KB (读/写)  
**块(Block)**, 512KB-4MB (擦除)

**字节(Byte)**

**“阻抗不匹配”**：CPU按字节思考，存储按块工作。这是DBMS需要解决的核心矛盾。

**性能模型**

**寻道+旋转+传输**  
随机I/O: ~10ms  
顺序I/O: >150MB/s

**电路延迟**  
随机读: ~100μs  
随机写: 更慢, 受GC影响

**内存总线速度**  
随机访问: ~200-300ns

**HDD的世界：顺序为王。SSD的世界：随机读廉价，但写操作有陷阱。NVM的世界：存储即内存，彻底颠覆。**

**核心瓶颈**

**机械移动 (Seek/Rotation)**

**垃圾回收 (GC), 写放大 (WAF)**

**有限的写寿命，更高的延迟**

软件优化的目标，就是规避这些核心瓶颈。

**原地更新**

**可以，但性能差** (引发随机I/O)

**不可以 (物理上)**

**可以，且速度快**

SSD的这个特性是催生LSM-Tree等现代存储引擎的根本原因。

**数据一致性**

扇区写失败(Torn Write)

页写失败, 块擦除失败

处理器缓存行与PMem的原子性问题

数据库必须在硬件之上构建自己的原子写协议(如Doublewrite Buffer)。

**\[拓展讨论\] Zoned Namespace (ZNS) SSDs 和 SMR HDDs:** 这些是“更诚实”的硬件。它们向软件暴露了其内部的顺序写入限制。DBMS可以利用这些信息进行更底层的优化，但这要求软件承担更多管理责任。这是“控制权”从硬件向软件转移的趋势。

#### **1.2 基于“数据温度”的存储层次结构**

面对如此多样且充满缺陷的介质，将所有数据一视同仁地放在一种介质上是愚蠢的。**数据的访问模式并非均匀分布**，而是遵循**帕累托法则（80/20法则）**：少量数据（热数据）承担了绝大部分访问。

这个洞察催生了存储层次结构，其本质是一个**基于成本和性能的自动数据分层系统**。

*   **Cache/DRAM:** “VIP休息室”。只为当前最活跃的数据服务。易失性决定了它只能是“临时”工作区。
*   **SSD:** “市区地产”。为频繁访问的温数据提供快速存取，成本较高。
*   **HDD:** “郊区仓库”。为不常访问的冷数据提供廉价的海量存储。
*   **Tape/Cloud Archive:** “地下金库”。为极少访问的归档数据提供最低成本的长期保存。

**设计的精髓：** 整个体系的效率，取决于**数据在层级间流动的策略**。这个策略的优劣，直接决定了用户感受到的平均访问延迟。而这个策略的核心，就是我们下一幕要讲的——缓冲区管理器。

### **第二部分：缓冲区管理器的内核**

如果说数据库是连接应用和磁盘的桥梁，那么缓冲区管理器就是这座桥的**总工程师和调度中心**。它管理着数据库最宝贵的资源：**内存**。

#### **2.1 缓冲池”**

DBMS为什么要自己管理内存，而不是直接依赖操作系统的文件缓存（Page Cache）？这是关于“控制权”的第一个核心问题。

*   **操作系统缓存的问题 (Why bypass OS Cache?):**
    1.  **通用而非专用:** OS的LRU策略对数据库的复杂查询模式（如全表扫描）是灾难性的。
    2.  **缺乏语义信息:** OS不知道一个页是索引页、数据页还是日志页。但DBMS知道，索引页通常比数据页更“有价值”，应该有更高的缓存优先级。
    3.  **双重缓冲 (Double Buffering):** 数据同时存在于DBMS缓冲池和OS Page Cache中，浪费内存。
    4.  **无法控制写回时机:** DBMS需要精确控制数据何时刷盘（`fsync`），以满足事务的持久性（Durability），而OS的缓存写回时机通常是异步且不可预测的。

因此，几乎所有高性能数据库都选择**直接I/O (Direct I/O)**，绕过OS缓存，建立自己的缓冲池。

#### **2.2 缓冲页的生命周期**

stateDiagram-v2 \[\*\] --> Free: System Startup Free --> Reading: Miss & Alloc Frame Reading --> Pinned\_Clean: I/O Complete state Pinned { Pinned\_Clean --> Pinned\_Dirty: Page is Modified Pinned\_Dirty --> Pinned\_Clean: Abort/Undo } Pinned\_Clean --> Unpinned\_Clean: Unpin Pinned\_Dirty --> Unpinned\_Dirty: Unpin Unpinned\_Clean --> Pinned\_Clean: Pin (Hit) Unpinned\_Dirty --> Pinned\_Dirty: Pin (Hit) Unpinned\_Clean --> Writing: Victim (Clean) Unpinned\_Dirty --> Writing: Victim (Dirty) Writing --> Free: Flush Complete

**核心控制结构剖析:**

*   **`pin_count` (钉住计数):** 这是**并发正确性的基石**。它像一个引用计数，只要>0，就意味着“有人正在使用，不许动！”。任何替换算法在选择牺牲品时，第一条规则就是**跳过所有`pin_count > 0`的页**。
*   **`dirty_bit` (脏位):** 这是**性能与持久性的权衡开关**。它告诉我们，这个页是否需要写回磁盘。没有它，每次换出干净的页也需要写盘，造成无谓的I/O。
*   **页表 (Page Table):** `PageID -> FrameID`的哈希表，实现O(1)的缓存查找。
*   **空闲列表 (Free List):** 链接所有空闲帧的链表，用于快速分配。
*   **替换队列 (Replacer):** 一个独立的数据结构（如LRU链表），只管理\*\*`pin_count = 0`\*\*的页，用于高效地选择牺牲品。

#### **2.3 替换策略的演化**

页面替换策略的目标是：**预测未来，保留最有价值的页**。这是一场没有完美答案的博弈。

*   **Level 1: LRU/Clock**
    
    *   **优点:** 简单，通用。
    *   **致命缺陷:** **扫描不友好**。一次大表扫描可以“污染”整个缓存，驱逐所有热点数据。
*   **Level 2: 改进型LRU**
    
    *   **LRU-K:** 记录一个页**最近K次**的访问历史，而不是仅仅最后一次。K=2能有效区分一次性扫描和真正频繁访问的页。
    *   **2Q (Two-Queue):** 将缓冲池分为两个队列：一个FIFO的“入门”队列(A1)，一个LRU的“长期”队列(Am)。新页先入A1，只有被再次访问才能“晋升”到Am。这能有效过滤掉扫描数据。
*   **Level 3: 感知工作负载的智能策略**
    
    *   **缓冲池分区 (Buffer Pool Partitioning):** 现代DBMS（如PostgreSQL, MySQL/InnoDB）会将缓冲池分为多个区域。例如：
        *   一个大的“主区域”给普通数据，采用LRU类策略。
        *   一个小的“扫描区域”给大表扫描，采用MRU或循环策略。
        *   甚至为不同类型的页（索引、数据）设置不同分区。
    *   **查询优化器提示:** 允许优化器在生成执行计划时，向缓冲管理器提供“元信息”，如“这是一个一次性查询，请不要污染主缓存”。

#### **2.4 写策略**

*   **预读/提前读 (Read-Ahead):** 当DBMS检测到顺序扫描模式时，它会**主动、异步地**将即将被访问的页提前读入缓存。这是将随机I/O转化为顺序I/O的又一利器。
*   **写回/刷盘 (Flushing Dirty Pages):**
    *   **Checkpointing:** 数据库会定期（或在日志文件满时）触发一个检查点，强制将**某个时间点之前**的所有脏页写回磁盘。这是为了缩短崩溃恢复(Crash Recovery)时需要重做(Redo)的日志量。
    *   **后台写者 (Background Writer):** 一个或多个后台线程，持续不断地、小批量地将脏页刷盘，以确保缓冲池中有足够的干净页可供替换，避免前台查询线程因为要等待刷盘而阻塞。
    *   **`fsync()`的代价:** 每次事务提交时，为了保证`D`(Durability)，必须将对应的日志记录`fsync`到磁盘。这是一个极其昂贵的操作。因此，**组提交 (Group Commit)** 技术应运而生：将多个并发事务的日志一次性打包提交，用一次`fsync`的成本服务多个事务，极大提高写密集型应用的TPS。

### **第三部分：数据在页上结构**

我们已经把页调入内存，现在要深入其内部，看看字节是如何被排布的。页内布局的设计目标是：**空间利用率最大化、页内操作效率最高化、支持变长数据和并发控制**。

#### **3.1 槽页 (Slotted Page)**

```
+-----------------------------------------------------------------+
| Page Header (e.g., 24 bytes)                                    |
| - Page LSN (8 bytes)         - Num of Slots (2 bytes)           |
| - Free Space Pointer (2 bytes) - ... other metadata ...         |
+-----------------------------------------------------------------+
| Slot Array (or Line Pointer Array) (grows downwards --->)       |
| Slot 1: (Offset, Length) | Slot 2: (Offset, Length) | ...     |
+-----------------------------------------------------------------+
|                                                                 |
|                          Free Space                             |
|                                                                 |
+-----------------------------------------------------------------+
| Record Data (<--- grows upwards)                                |
| ... | Record 2 Data | Record 1 Data                             |
+-----------------------------------------------------------------+
^                                                                 ^
0                                                               8191 (for 8KB page)
```

**设计的精髓再剖析：**

*   **指针的稳定性：** `RID = <PageID, Slot#>` 是一个**逻辑指针**。只要记录还在这个页上，无论它在页内如何移动，它的RID都**永不改变**。这解耦了记录的逻辑身份和物理位置，是所有上层索引结构能够稳定工作的基础。这个\*\*“间接层” (Layer of Indirection)\*\* 是计算机科学中解决复杂问题的万能钥匙。
*   **无页内碎片：** 槽数组和记录数据从两端相向生长，中间的空闲空间永远是连续的。这使得空间分配和回收极其高效。
*   **原子性：** 对一个页的修改（如插入一条记录）可以被设计成一个**物理上原子**的操作。例如，最后一步才更新页头中的槽数量。如果在更新过程中崩溃，页的状态也是可恢复的。

#### **3.2 记录的内部结构**

一条记录本身也是一个微缩的结构：

```
[ Record Header ] [ Column 1 Data ] [ Column 2 Data ] ...
```

*   **记录头 (Record Header):**
    *   **NULL 位图:** 紧凑地表示哪些列是NULL。
    *   **变长字段偏移量数组:** 对于VARCHAR、TEXT等类型，记录头会存储一个数组，指出每个变长字段在记录数据区的真实起始位置。
    *   **事务信息:** 在支持多版本并发控制(MVCC)的系统中（如PostgreSQL, InnoDB），记录头还会包含创建该版本的事务ID (`xmin`)、删除该版本的事务ID (`xmax`)等信息。

**定长 vs. 变长数据的存储艺术：**

*   先存储所有定长字段，再存储所有变长字段。这样，定长字段的访问可以通过固定的偏移量计算，非常快。而变长字段的访问需要先从记录头读取偏移量。

#### **3.3 超越页**

*   **溢出页 (Overflow Pages):**
    *   当一个记录太大时，会使用一个页链表来存储它。
    *   **性能警示：** 这意味着读取一条记录可能需要多次（随机）I/O。这是数据库设计中的一个**巨大红灯**。应用开发者应极力避免在频繁访问的表中设计超大字段。
*   **TOAST (The Oversized-Attribute Storage Technique):** PostgreSQL的独门绝技，它在溢出之前，会先尝试两件事：
    1.  **压缩 (Compression):** 对大字段进行行内压缩。
    2.  **切片 (Slicing):** 如果压缩后仍然太大，就将其切成多个小块(chunks)，存入一个专门的TOAST表中。主表只保留一个指向TOAST表的指针。这使得对主表的扫描不会因为大字段而变得缓慢。

### **第四部分：DBMS与操作系统的关系**

这部分是本讲的升华。一个数据库系统，是运行在操作系统之上的一个应用程序，但它又渴望成为一个“迷你操作系统”。

#### **4.1 文件系统：**

*   **选项A: 使用OS文件系统 (Files on a File System)**
    *   **优点:** 方便、可移植、易于管理（文件可以复制、备份）。
    *   **缺点:**
        *   **性能开销:** 文件系统的日志(Journaling)、权限检查、元数据更新都会带来额外开销。
        *   **布局不可控:** DBMS无法精确控制文件块在磁盘上的物理布局，可能导致碎片化。
        *   **双重缓冲:** 如前所述。
*   **选项B: 使用裸设备 (Raw Disk Partitions)**
    *   **优点:**
        *   **极致控制:** DBMS完全接管磁盘块的分配和布局，可以实现最优的顺序I/O。
        *   **绕过OS缓存:** 天然避免双重缓冲。
    *   **缺点:**
        *   **管理复杂:** 备份、迁移等操作变得非常困难。
        *   **可移植性差:** 与特定设备和OS紧密绑定。

**现代的折中方案:** 大多数现代DBMS默认使用文件系统，但通过`O_DIRECT`等标志位来绕过OS缓存，并使用`fallocate`等接口来预分配连续空间，从而在便利性和控制力之间取得平衡。

#### **4.2 内存映射 (mmap)**

`mmap`可以将一个文件直接映射到进程的虚拟地址空间，之后就可以像访问内存数组一样访问文件，读写操作由OS的虚拟内存系统自动处理。

*   **诱惑之处:** 极大地简化了代码。缓冲区管理器的很多复杂逻辑似乎都“消失”了。
*   **陷阱之处:**
    1.  **失去控制:** 何时读页、何时写回脏页，完全由OS决定。DBMS无法实现自己的高级替换策略，也无法精确控制`fsync`。
    2.  **错误处理困难:** I/O错误会以信号（如`SIGBUS`）的形式出现，难以优雅地处理。
    3.  **性能抖动:** OS的缺页中断和后台刷盘行为可能导致不可预测的性能抖动。

**结论:** 对于需要高性能、高可靠性和可预测行为的数据库内核，`mmap`通常是一个需要避开的陷阱。SQLite和一些内存数据库可能会使用它，但大型事务型数据库几乎都选择自己手动管理I/O。

### **总结**

我们看到所有复杂的设计都围绕着几条永恒的原则：

1.  **I/O是瓶颈，最小化它:** 这是第一原则。缓存、预读、压缩、索引……一切都是为了减少访问磁盘的次数。
2.  **顺序优于随机:** 拥抱顺序I/O，规避随机I/O。数据布局、电梯算法、LSM-Tree，都是这一原则的体现。
3.  **用间接层解耦:** 槽页中的RID就是一个完美的例子。增加一个间接层，可以换来巨大的灵活性和稳定性。
4.  **批量处理摊销成本:** 组提交、一次I/O读取一个大块而非一个字节，都是用“批发”的思路来降低单位操作的固定成本。
5.  **为最坏情况设计:** 数据库必须能在任何时刻断电后恢复。这意味着需要日志、原子写协议(WAL, ARIES)等机制来保证持久性和一致性。