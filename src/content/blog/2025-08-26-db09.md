---
title: "数据库系统设计04:查询处理(上)"
description: ""
pubDate: "2025-08-26"
heroImage: ""
---

# 数据库系统设计04:查询处理(上)

当用户通过SQL发出一个指令，比如“查询所有在杭州、过去一个月内购买过手机、且消费总额超过5000元的VIP客户”，数据库内部究竟发生了什么？

这个从一条SQL语句到一个结果集的旅程，就是**查询处理 (Query Processing)** 的全部内容。它通常分为两个宏大的阶段：

1.  **查询优化 (Query Optimization):** 数据库的“大脑”，负责将用户的SQL翻译成一个高效的**执行计划 (Execution Plan)**。它会探索成千上万种可能的执行方式，并选择成本最低的一种。这是我们下一讲的主题。
2.  **查询执行 (Query Execution):** 数据库的“肌肉”，负责忠实地、高效地执行优化器给出的计划。

今天，我们的焦点是**查询执行**。我们将打开查询执行引擎的“工具箱”，检视里面用于实现关系代数操作（如`SELECT`, `PROJECT`, `JOIN`, `SORT`, `GROUP BY`）的各种算法。我们会发现，对于同一个逻辑操作，存在多种物理实现算法，它们的性能在不同数据规模、分布和索引条件下，有着天壤之别。

这节课的目标，是让你们掌握评估和选择这些算法的能力。我们将学会像数据库内核一样思考：**如何用最少的I/O，完成最复杂的计算任务？**

### **第一部分：查询成本模型**

在比较算法优劣之前，我们必须先建立一把统一的“度量衡”，这就是**成本模型 (Cost Model)**。

#### **1.1 成本的主要来源：I/O”**

正如我们在存储课上反复强调的，CPU的速度远超磁盘。因此，在传统的、以磁盘为主要存储的数据库中，**磁盘I/O是成本的主要矛盾**。我们的首要目标是最小化I/O。

*   **成本单位:**
    
    *   $B$: 数据关系占用的**数据块 (Blocks)** 数量。
    *   $T$: 数据关系拥有的**元组 (Tuples)** 数量。
    *   $M$: 内存中可用于操作的**缓冲区块 (Memory Blocks/Pages)** 数量。
*   **I/O操作成本:**
    
    *   **顺序读/写 (Sequential I/O):** 读写物理上连续的块。成本主要在于传输时间。
    *   **随机读/写 (Random I/O):** 读写物理上不连续的块。成本 = 寻道时间 + 旋转延迟 + 传输时间。随机I/O比顺序I/O昂贵得多。
*   **简化的成本公式:** 我们的分析将主要关注**I/O成本**，即算法执行过程中需要读写多少个磁盘块。我们会忽略CPU成本，但在分析哈希连接等计算密集型算法时会提及。
    

#### **1.2 目录信息 (Catalog) 的重要性**

数据库不是在“黑暗”中做决策。它维护着一个名为**系统目录 (System Catalog)** 或**数据字典**的元数据仓库，里面存储着关于数据库所有对象的“统计信息”，例如：

*   每个关系 $R$ 的块数 $B(R)$ 和元组数 $T(R)$。
*   每个属性的**值基数 (Cardinality)**，即不同值的数量。
*   每个属性值的**分布直方图 (Histograms)**。
*   索引信息，如索引的高度、叶子节点数等。

这些统计信息，是成本估算的基石，也是查询优化器做出明智选择的依据。

### **第二部分：选择 (Selection) 与投影 (Projection)**

`SELECT` 和 `PROJECT` 是关系代数中最基本的操作，对应SQL中的`WHERE`和`SELECT <column_list>`子句。

#### **2.1 选择操作 (Selection, $\\sigma\_P(R)$)**

目标：从关系 $R$ 中找出所有满足谓词条件 $P$ 的元组。

##### **算法S1：全文件扫描 (Full File Scan)**

*   **描述:** 简单粗暴。逐块读取关系 $R$ 的所有数据块，对块中的每个元组检查其是否满足条件 $P$。
*   **适用场景:** **万能算法**。无论有无索引、数据是否排序，它总能工作。
*   **I/O成本:** $B(R)$ 次读I/O。
*   **设计思考:** 这是**最坏情况下的保底方案**。如果没有任何捷径可走，就只能全盘扫描。

##### **算法S2：基于排序的二分查找**

*   **前提:**
    1.  选择条件 $P$ 是一个**等值比较**，如 `attr = value`。
    2.  关系 $R$ 的文件**物理上**按照 `attr` 排序。
*   **描述:** 利用二分查找，在 $B(R)$ 个块中定位到第一个可能包含目标元组的块。
*   **I/O成本:**
    *   **定位成本:** $\\lceil \\log\_2 B(R) \\rceil$ 次随机I/O。
    *   **获取成本:** 如果 `attr` 是唯一键，找到后即可停止。如果非唯一，还需要顺序读取所有包含该值的后续块。设满足条件的元组分布在 $S$ 个块中，则总成本为 $\\lceil \\log\_2 B(R) \\rceil + S$。
*   **设计思考:** 用物理有序性换取了 $O(\\log N)$ 的查找效率，但付出了极高的维护成本（插入/删除困难）。

##### **算法S3：基于B+树索引的查找**

*   **前提:** 在选择条件的属性上，存在一个B+树索引。
*   **场景A: 等值选择 `attr = value`**
    *   **I/O成本:**
        *   **主索引/聚集索引 (Primary/Clustered):** 从B+树根节点走到叶子节点，成本为 `树高 + S` 次I/O，其中 $S$ 是存放结果的块数。因为数据物理连续，所以 $S$ 很小。
        *   **辅助索引 (Secondary):** 成本为 `树高 + T(P)` 次I/O，其中 $T(P)$ 是满足条件的元组数。因为每个元组都可能需要一次**回表**，导致一次随机I/O。**这是辅助索引最坏的情况**。
*   **场景B: 范围选择 `value1 <= attr <= value2`**
    *   **描述:**
        1.  使用B+树找到第一个满足 `attr >= value1` 的叶子节点条目。
        2.  利用叶子节点的**双向链表**，向右顺序扫描，直到 `attr > value2`。
    *   **I/O成本:**
        *   **主索引:** `树高 + 结果块数`。因为数据物理连续，所以性能极高。
        *   **辅助索引:** `树高 + 索引叶子块数 + T(P)`。每次回表都是随机I/O，当 $T(P)$ 很大时，成本可能比全表扫描还高！
*   **设计思考:** B+树是通用且高效的选择。但优化器必须清醒地认识到**使用非聚集索引进行大范围扫描的巨大代价**。它会根据统计信息估算 $T(P)$ 的大小，如果选择率（$T(P)/T(R)$）很高（比如超过5-10%），它可能会明智地**放弃使用索引，退化为全表扫描**。

##### **算法S4：基于哈希索引的查找**

*   **前提:**
    1.  选择条件 $P$ 必须是**等值比较**。
    2.  在 `attr` 上存在哈希索引。
*   **描述:** 计算 `value` 的哈希值，直接定位到对应的桶。
*   **I/O成本:** 平均情况下是**1到2次I/O**。如果存在长的溢出链，成本会增加。
*   **设计思考:** 等值查询的“核武器”，但功能单一，不支持范围查询。

#### **2.2 复杂选择条件的实现**

*   **合取 (Conjunction, AND):** `P1 AND P2`
    *   **策略1:** 选择一个“选择性最高”（返回结果最少）的谓词（如`P1`），用它先过滤出中间结果集，然后再在内存中检查`P2`。
    *   **策略2 (索引合并/交集):** 如果`P1`和`P2`的属性上都有索引，可以分别用两个索引得到满足条件的RID列表，然后在内存中求这两个列表的**交集**，最后统一回表。
*   **析取 (Disjunction, OR):** `P1 OR P2`
    *   **策略 (索引合并/并集):** 如果`P1`和`P2`都有索引，可以分别获取RID列表，求**并集**后回表。如果其中一个没有索引，通常只能退化为全表扫描。

#### **2.3 投影操作 (Projection, $\\pi\_{A1, A2, ...}(R)$)**

目标：从关系 $R$ 中选择指定的列。

*   **核心挑战：去重 (Duplicate Elimination)**，对应SQL中的`SELECT DISTINCT`。
*   **算法P1：基于排序的去重**
    1.  **扫描与投影:** 扫描整个关系 $R$，对每个元组，只保留需要的列，写入一个临时中间文件。
    2.  **排序:** 对这个巨大的中间文件进行**外部排序 (External Sorting)**。
    3.  **去重:** 再次扫描已排序的中间文件，只输出不与前一个元组重复的元组。
*   **I/O成本:** 外部排序的成本通常是 $O(B(R) \\log\_M B(R))$，非常昂贵。
*   **算法P2：基于哈希的去重**
    1.  **分区 (Partitioning):** 类似哈希连接的分区阶段。使用哈希函数 `h1` 将元组按需投影后，散列到 $M-1$ 个磁盘分区中。
    2.  **去重 (Duplicate Elimination):** 逐一将每个分区读入内存，使用内存哈希表 `h2` 进行去重。
*   **I/O成本:** 读写一遍数据，成本约为 $3 \\times B(R)$。通常比排序法快。
*   **设计思考:** 如果投影操作**不需要去重** (`SELECT` 而非 `SELECT DISTINCT`)，且所需列上存在一个**覆盖索引 (Covering Index)**，那么数据库就可以**只扫描索引，完全避免访问数据文件**，这是极大的性能提升。

### **第三部分：连接 (Join)**

连接操作是关系数据库的灵魂，也是性能开销最大的操作之一。我们将探索四种主流的连接算法。假设我们要连接关系 $R$ 和 $S$ (`R JOIN S ON R.a = S.b`)。

#### **3.1 嵌套循环连接 (Nested Loop Join, NLJ)**

这是最朴素、最暴力的算法，就像两层`for`循环。

##### **算法J1：元组级嵌套循环连接 (Tuple-based NLJ)**

```
FOR each tuple r in R:
  FOR each tuple s in S:
    IF r.a == s.b THEN
      output <r, s>
```

*   **I/O成本:** $T(R) \\times B(S) + B(R)$。这是一个**灾难性**的成本，因为对 $R$ 的每一个元组，我们都要把整个 $S$ 扫描一遍。

##### **算法J2：块级嵌套循环连接 (Block-based NLJ / Page-oriented NLJ)**

*   **改进:** 我们不是逐元组，而是逐块地进行循环。

```
FOR each block br in R:
  FOR each block bs in S:
    FOR each tuple r in br:
      FOR each tuple s in bs:
        IF r.a == s.b THEN
          output <r, s>
```

*   **I/O成本:** $B(R) \\times B(S) + B(R)$。仍然非常高昂。

##### **算法J3：优化的块级嵌套循环 (Buffered NLJ)**

*   **核心思想:** 最大化利用内存。
*   **描述:**
    1.  将外层关系 $R$ 的 $M-2$ 个块读入内存缓冲区。
    2.  扫描一遍内层关系 $S$，将其每个块与内存中 $R$ 的所有块进行连接。
    3.  重复此过程，直到 $R$ 的所有块都被处理完。
*   **I/O成本:** $B(R) + (\\lceil B(R) / (M-2) \\rceil \\times B(S))$。
*   **选角的重要性:** 应该选择**较小的关系作为外层关系**，以减少外层循环的次数。
*   **设计思考:** NLJ是**唯一可以处理任何连接条件**（包括非等值连接如`>`）的通用算法。在内层关系上有索引时，它会蜕变成下面要讲的索引嵌套循环。

#### **3.2 索引嵌套循环连接 (Index Nested Loop Join, INLJ)**

*   **前提:** 在内层关系 $S$ 的连接属性 `S.b` 上有一个索引。
*   **描述:**

```
FOR each tuple r in R:
  use index on S.b to find all tuples s where s.b == r.a
  FOR each matching tuple s:
    output <r, s>
```

*   **I/O成本:** $B(R) + T(R) \\times (\\text{索引查找成本})$。
*   **设计思考:** 当外层关系 $R$ 非常小，或者索引的选择性极高（每次查找只返回极少数记录）时，INLJ的性能极佳。它特别适合于OLTP场景下的点查询关联。

#### **3.3 排序归并连接 (Sort-Merge Join, SMJ)**

*   **前提:** 必须是**等值连接**或**范围连接**。
*   **描述:**
    1.  **排序阶段 (Sort Phase):** 如果关系 $R$ 和 $S$ 尚未按连接键（`R.a` 和 `S.b`）排序，则分别使用外部排序将它们排序。
    2.  **归并阶段 (Merge Phase):**
        *   使用两个指针，分别指向已排序的 $R$ 和 $S$ 的开头。
        *   类似归并排序的合并过程，同步地向前扫描两个关系：
            *   `IF R.a < S.b`, 前进 $R$ 的指针。
            *   `IF R.a > S.b`, 前进 $S$ 的指针。
            *   `IF R.a == S.b`, 找到了一个匹配。输出结果。**处理重复键是这里的关键和难点**：需要标记当前匹配的起始位置，然后将一个关系的指针扫描完所有重复值，再将另一个关系的指针重置回起始位置，进行交叉匹配。
*   **I/O成本:**
    *   **排序成本:** $O(B(R)\\log\_M B(R)) + O(B(S)\\log\_M B(S))$
    *   **归并成本:** $B(R) + B(S)$ (只需扫描一遍)
    *   **总成本:** 主要由排序阶段决定。
*   **设计思考:** SMJ对**预排序**的数据（例如通过聚集索引或前一个查询的`ORDER BY`结果）非常友好。它的一个巨大优势是，**连接的结果本身也是有序的**，这对于后续的`ORDER BY`或`GROUP BY`操作可能非常有价值。

#### **3.4 哈希连接 (Hash Join, HJ)**

*   **前提:** 必须是**等值连接**。
    
*   **描述:** 分为两个阶段：
    
    1.  **构建阶段 (Build Phase):**
        *   选择较小的关系（比如 $S$）作为**构建输入 (Build Input)**。
        *   扫描 $S$，使用哈希函数 `h1`，在内存中构建一个关于连接键 `S.b` 的哈希表。
    2.  **探测阶段 (Probe Phase):**
        *   扫描较大的关系 $R$ (探测输入, Probe Input)。
        *   对于 $R$ 中的每个元组 $r$，计算 `h1(r.a)`，然后去内存中的哈希表中查找匹配的 $S$ 元组。
        *   找到匹配则输出。
*   **内存的挑战:** 如果构建输入的哈希表**无法完全放入内存** ($B(S) > M$) 怎么办？
    
    *   **Grace Hash Join (分区哈希连接):** a. **分区阶段 (Partitioning):**
        
        *   使用一个分区哈希函数 $h\_p$，将 $R$ 和 $S$ 都分别散列到 $k$ 个磁盘分区中 ($R\_1, ..., R\_k$ 和 $S\_1, ..., S\_k$) 。
        *   $h\_p$ 保证了所有可能匹配的元组（`r.a = s.b`）必定落在对应的分区中（$R\_i$ 和 $S\_i$）。
        
        b. **连接阶段 (Joining):**
        *   对每一对分区 `(R_i, S_i)`，执行内存哈希连接算法。此时，我们只需要保证每个 $S\_i$ 的大小小于 $M$ 即可。
*   **I/O成本:**
    
    *   **分区阶段:** 读写 $R$ 和 $S$ 一遍，成本为 $2 \\times (B(R) + B(S))$。
    *   **连接阶段:** 再读一遍 $R$ 和 $S$，成本为 $B(R) + B(S)$。
    *   **总成本:** 约为 $3 \\times (B(R) + B(S))$。
*   **设计思考:**
    
    *   哈希连接是处理**大规模数据等值连接**的**主力算法**，尤其是在数据无序且没有合适索引的情况下。它的平均性能通常优于排序归并连接。
    *   它对**数据倾斜 (Data Skew)** 非常敏感。如果某个哈希值对应的分区过大，无法放入内存，就会导致性能问题（需要递归分区或退化到其他连接算法）。