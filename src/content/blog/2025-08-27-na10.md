---
title: "数值分析10:数值微积分与最佳多项式逼近"
description: ""
pubDate: "2025-08-27"
heroImage: ""
---

# 数值分析10:数值微积分与最佳多项式逼近

### **引言：从函数逼近到函数操作**

在过去的几讲中，我们花了大量时间探讨一个核心主题：**函数逼近**。无论是通过**插值**（拉格朗日、牛顿、样条）来精确穿过数据点，还是通过**最小二乘法**来拟合含噪声数据的整体趋势，我们的目标都是用一个“简单”的函数（主要是多项式）去“代替”一个“复杂”或未知的函数。

今天，我们将把这一思想推向其逻辑上的下一个阶段：我们为什么要逼近函数？一个非常重要的原因就是为了对它们进行**微积分操作**。

*   如果我们只有一个函数的离散数据点，我们如何估算它在某一点的**导数**？
*   如果一个函数的原函数无法用初等函数表示（例如 $e^{-x^2}$），我们如何计算它在某个区间上的**定积分**？

答案很简单：**我们不对原始的复杂函数进行操作，而是对它的简单逼近函数（比如插值多项式）进行操作。** 这就是**数值微分 (Numerical Differentiation)** 和**数值积分 (Numerical Integration)** 的基本思想。

课程的第一部分，我们将探讨数值微分。我们会发现，这是一个非常“微妙”甚至有些“危险”的过程。一个看似自然的近似方法，可能会因为对舍入误差的极度敏感而变得非常**不稳定**。

课程的第二部分，我们将转向数值积分，也称为**数值求积 (Numerical Quadrature)**。幸运的是，积分在数学上是一个“平滑”或“平均”的过程，因此数值积分方法通常具有非常好的**稳定性**和**收敛性**。我们将从最基础的牛顿-柯特斯公式（梯形法则、辛普森法则）入手。

最后，课程的第三部分，我们将回到逼近理论的一个巅峰话题。在最小二乘法中，我们最小化了**L2范数**下的误差（平方误差和）。但是，如果我们想让逼近多项式在整个区间上的**最大误差**（**L∞范数**）最小化，该怎么做？这个问题，即**minimax问题**，引出了数值分析中最优雅、最深刻的理论之一，以及一类极其重要的特殊函数——**切比雪夫多项式 (Chebyshev Polynomials)**。我们将看到，这些多项式不仅是minimax问题的答案，还能帮助我们解决龙格现象，并引出一种被称为**幂级数经济化**的巧妙技术。

### **第一部分：数值微分——一个“病态”的问题**

#### **4.1 基本思想与低阶公式**

**核心思想：** 给定函数 $f(x)$，我们想近似 $f'(x\_0)$。最直接的来源是导数的极限定义： $$f'(x\_0) = \\lim\_{h \\to 0} \\frac{f(x\_0+h) - f(x\_0)}{h}$$

如果我们取一个很小但非零的 $h$，就可以得到近似公式。

**1\. 前向差分公式 (Forward-Difference Formula):** $$f'(x\_0) \\approx \\frac{f(x\_0+h) - f(x\_0)}{h}$$ 几何上，这是用连接点 $(x\_0, f(x\_0))$ 和 $(x\_0+h, f(x\_0+h))$ 的**割线斜率**来近似点 $x\_0$ 处的**切线斜率**。

**2\. 后向差分公式 (Backward-Difference Formula):** $$f'(x\_0) \\approx \\frac{f(x\_0) - f(x\_0-h)}{h}$$ 这是用点 $(x\_0-h, f(x\_0-h))$ 和 $(x\_0, f(x\_0))$ 的割线斜率来近似。

**误差分析：** 这些公式的精度如何？我们可以用泰勒展开来分析。将 $f(x\_0+h)$ 在 $x\_0$ 处展开： $$f(x\_0+h) = f(x\_0) + f'(x\_0)h + \\frac{f''(\\xi)}{2}h^2$$ 整理后得到： $$\\frac{f(x\_0+h) - f(x\_0)}{h} = f'(x\_0) + \\frac{f''(\\xi)}{2}h$$ **截断误差 (Truncation Error):** $$f'(x\_0) - \\left\[\\frac{f(x\_0+h) - f(x\_0)}{h}\\right\] = -\\frac{f''(\\xi)}{2}h = O(h)$$ 前向和后向差分公式的截断误差都是 $h$ 的一阶，我们称之为**一阶方法**。这意味着，如果步长 $h$ 减半，误差大约也减半，收敛速度很慢。

**3\. 中心差分公式 (Central-Difference Formula):** 有没有更好的方法？我们可以组合两个泰勒展开： $$f(x\_0+h) = f(x\_0) + f'(x\_0)h + \\frac{f''(x\_0)}{2}h^2 + \\frac{f'''(\\xi\_1)}{6}h^3$$ $$f(x\_0-h) = f(x\_0) - f'(x\_0)h + \\frac{f''(x\_0)}{2}h^2 - \\frac{f'''(\\xi\_2)}{6}h^3$$ 两式相减： $$f(x\_0+h) - f(x\_0-h) = 2f'(x\_0)h + \\frac{f'''(\\xi\_1)+f'''(\\xi\_2)}{6}h^3$$ 整理得到： $$f'(x\_0) = \\underbrace{\\frac{f(x\_0+h) - f(x\_0-h)}{2h}}\_{\\text{中心差分公式}} - \\underbrace{\\frac{f'''(\\xi)}{6}h^2}\_{\\text{截断误差}}$$ 中心差分公式的截断误差是 $O(h^2)$，是一个**二阶方法**！步长 $h$ 减半，误差会减小到原来的四分之一，精度远高于前向/后向差分。这是最常用的数值微分公式之一。

#### **4.1.1 高阶公式的系统推导**

如何系统地推导更高阶的公式？ **方法：** 用 $n+1$ 个点的**拉格朗日插值多项式** $P\_n(x)$ 及其误差项 $R\_n(x)$ 来逼近 $f(x)$，然后对整个表达式求导： $$f(x) = \\sum\_{k=0}^n f(x\_k)L\_k(x) + \\frac{f^{(n+1)}(\\xi\_x)}{(n+1)!} \\prod\_{k=0}^n(x-x\_k)$$ $$f'(x) = \\sum\_{k=0}^n f(x\_k)L'\_k(x) + \\frac{d}{dx}\\left\[ \\frac{f^{(n+1)}(\\xi\_x)}{(n+1)!} \\prod\_{k=0}^n(x-x\_k) \\right\]$$ 当 $x$ 是一个插值节点 $x\_j$ 时，对误差项求导变得复杂。但这个方法给出了推导各种差分公式的统一框架。

**例如 (Discussion 26):** 使用点 $x\_0, x\_0+h, x\_0+2h$ 构造二次插值多项式，然后求导并分别在三个点上取值，可以得到三个不同的**三点公式**。

*   $f'(x\_0) = \\frac{1}{2h}\[-3f(x\_0) + 4f(x\_0+h) - f(x\_0+2h)\] + \\frac{h^2}{3}f'''(\\xi)$
*   $f'(x\_0+h) = \\frac{1}{2h}\[f(x\_0+2h) - f(x\_0)\]$ (这正是以 $x\_0+h$ 为中心的中心差分公式！)
*   $f'(x\_0+2h) = \\frac{1}{2h}\[f(x\_0) - 4f(x\_0+h) + 3f(x\_0+2h)\] + \\frac{h^2}{3}f'''(\\xi)$

可以看到，中心点公式的截断误差项系数（$1/6$）比端点公式（$1/3$）更小，因此精度更高。

#### **4.1.2 数值微分的不稳定性**

"numerical differentiation is unstable!" 为什么？ 让我们重新审视中心差分公式。在计算机上，我们计算的函数值 $f(x\_0\\pm h)$ 并非精确值，而是带有舍入误差的 $\\tilde{f}(x\_0\\pm h)$。设 $|f(x) - \\tilde{f}(x)| \\le \\epsilon$。 我们实际计算的导数是： $$\\tilde{f}'(x\_0) = \\frac{\\tilde{f}(x\_0+h) - \\tilde{f}(x\_0-h)}{2h}$$ 总误差 = 截断误差 + 舍入误差 $$|f'(x\_0) - \\tilde{f}'(x\_0)| \\le \\left| \\frac{f'''(\\xi)}{6}h^2 \\right| + \\left| \\frac{(f(x\_0+h)-\\tilde{f}(x\_0+h)) - (f(x\_0-h)-\\tilde{f}(x\_0-h))}{2h} \\right|$$ $$|f'(x\_0) - \\tilde{f}'(x\_0)| \\le \\frac{M\_3}{6}h^2 + \\frac{\\epsilon+\\epsilon}{2h} = \\frac{M\_3}{6}h^2 + \\frac{\\epsilon}{h}$$

**误差行为分析：**

*   当步长 $h$ 减小时，**截断误差** ($\\propto h^2$) 减小。
*   当步长 $h$ 减小时，**舍入误差** ($\\propto 1/h$) **增大**！

这是一个致命的矛盾。我们不能像在数学理论中那样让 $h$ 任意趋于0。存在一个**最优步长 $h\_{opt}$**，使得总误差最小。小于这个 $h$，舍入误差将占主导，结果会越来越差！这就是**数值微分的不稳定性**。它对输入数据的噪声（在此即为舍入误差）非常敏感。

#### **4.2 二阶导数近似**

类似地，我们可以通过组合泰勒展开来推导二阶导数的公式 (Discussion 27)。 $$f(x\_0+h) = f(x\_0) + f'(x\_0)h + \\frac{f''(x\_0)}{2}h^2 + \\frac{f'''(x\_0)}{6}h^3 + O(h^4)$$ $$f(x\_0-h) = f(x\_0) - f'(x\_0)h + \\frac{f''(x\_0)}{2}h^2 - \\frac{f'''(x\_0)}{6}h^3 + O(h^4)$$ 两式相加： $$f(x\_0+h) + f(x\_0-h) = 2f(x\_0) + f''(x\_0)h^2 + O(h^4)$$ 整理得到： $$f''(x\_0) = \\frac{f(x\_0+h) - 2f(x\_0) + f(x\_0-h)}{h^2} - \\frac{h^2}{12}f^{(4)}(\\xi)$$ 这是一个 $O(h^2)$ 精度的**中心差分公式**，用于近似二阶导数。它同样面临着 $1/h^2$ 形式的舍入误差放大问题，比一阶导数更不稳定。

### **第二部分：数值积分——一个“稳定”的过程**

#### **4.3 基本思想：插值型求积**

**核心思想：** 我们想计算 $I = \\int\_a^b f(x)dx$。

1.  在 $\[a,b\]$ 上选择 $n+1$ 个节点 $x\_0, \\dots, x\_n$。
    
2.  构造一个穿过这些点的插值多项式 $P\_n(x)$。
    
3.  用 $P\_n(x)$ 的积分来近似 $f(x)$ 的积分：
    
    $$ \\begin{aligned} I &= \\int\_a^b f(x)dx \\approx \\int\_a^b P\_n(x)dx = \\int\_a^b \\sum\_{k=0}^n f(x\_k)L\_k(x)dx \\\\ &= \\sum\_{k=0}^n f(x\_k) \\underbrace{\\int\_a^b L\_k(x)dx}\_{A\_k} = \\sum\_{k=0}^n A\_k f(x\_k) \\end{aligned} $$
    

这个形式被称为**插值型求积公式 (Interpolatory Quadrature)**。$x\_k$ 称为**节点 (nodes)**，$A\_k$ 称为**权 (weights) 或 Cotes 系数**。 数值积分的本质就是用一个**带权和**来近似积分值。

**误差分析：** $$ \\begin{aligned} Error &= \\int\_a^b f(x)dx - \\int\_a^b P\_n(x)dx = \\int\_a^b (f(x)-P\_n(x))dx = \\int\_a^b R\_n(x)dx \\\\ &= \\int\_a^b \\frac{f^{(n+1)}(\\xi\_x)}{(n+1)!} \\prod\_{k=0}^n(x-x\_k) dx \\end{aligned} $$

与微分不同，积分是一个平均过程，它会“平滑”掉函数值的微小误差。因此，数值积分方法通常是**非常稳定**的。

#### **4.3.1 Newton-Cotes 公式**

这是一族最经典的求积公式，它们基于在 $\[a,b\]$ 区间上取**等距节点**。

**1\. 梯形法则 (Trapezoidal Rule, n=1):** 使用两个端点 $x\_0=a, x\_1=b$ 进行线性插值。 $$A\_0 = \\int\_a^b L\_0(x)dx = \\int\_a^b \\frac{x-b}{a-b}dx = \\frac{b-a}{2}$$ $$A\_1 = \\int\_a^b L\_1(x)dx = \\int\_a^b \\frac{x-a}{b-a}dx = \\frac{b-a}{2}$$ **公式：** $\\int\_a^b f(x)dx \\approx \\frac{b-a}{2}\[f(a)+f(b)\]$ **误差：** $E\_T = -\\frac{(b-a)^3}{12}f''(\\xi) = O(h^3)$ **精度 (Degree of Precision):** 一个求积公式的精度是指它能精确积分的最高次多项式的次数。梯形法则是对线性函数精确的，所以其**精度为1**。

**2\. 辛普森法则 (Simpson's Rule, n=2):** 使用三个点 $x\_0=a, x\_1=(a+b)/2, x\_2=b$ 进行二次插值。 **公式：** $\\int\_a^b f(x)dx \\approx \\frac{b-a}{6}\\left\[f(a) + 4f\\left(\\frac{a+b}{2}\\right) + f(b)\\right\]$ **误差：** $E\_S = -\\frac{(b-a)^5}{2880}f^{(4)}(\\xi) = O(h^5)$ **精度：** 令人惊讶的是，辛普森法则不仅对二次多项式精确，对**三次多项式也精确**！所以其**精度为3**。这种精度的“意外”提升是由于误差项中奇数阶导数项的对称性抵消造成的。

**更高阶的Newton-Cotes公式**（如Simpson's 3/8 Rule, Boole's Rule）可以类似推导，但它们在高阶时可能出现负权，导致数值不稳定，因此不常用。实用的做法是将低阶公式进行复合。

### **第三部分：最佳多项式逼近与切比雪夫多项式**

#### **8.3.1 Minimax 逼近问题**

我们已经学习了最小二乗（L2）逼近。现在我们考虑一个更严格的逼近标准：**最小化最大误差（L∞）**。

**Minimax 问题:** 给定函数 $f(x)$，在所有次数不超过 $n$ 的多项式 $\\Pi\_n$ 中，找到那个 $P\_n^\*(x)$，使得**一致范数（或无穷范数）** $||f - P\_n||\_\\infty = \\max\_{x \\in \[a,b\]} |f(x) - P\_n(x)|$ 达到最小。

**切比雪夫等振荡定理 (Chebyshev's Equioscillation Theorem):** 这个问题的解 $P\_n^\*(x)$ 存在且唯一，其充要条件是误差函数 $E(x)=f(x)-P\_n^\*(x)$ 在区间 $\[a,b\]$ 上至少有 **$n+2$ 个点**，在这些点上误差达到其最大值（或最小值），并且**正负交替**。 这些点被称为**切比雪夫交错点组 (Chebyshev Alternating Set)**。

#### **8.3.2 切比雪夫多项式**

如何找到这个最佳逼近多项式？直接构造非常困难。但切比雪夫找到了一个相关问题的巧妙解。

**问题 (v 3.0):** 在所有次数为 $n-1$ 的多项式中，找到 $P\_{n-1}(x)$，使得 $||x^n - P\_{n-1}(x)||\_\\infty$ 在 $\[-1,1\]$ 上最小。 这等价于寻找一个**首项系数为1 (monic) 的 $n$ 次多项式**，使其在 $\[-1,1\]$ 上的无穷范数最小。

**切比雪夫的洞察：** 考虑函数 $T\_n(x) = \\cos(n \\arccos x)$。

*   通过变量替换 $x=\\cos\\theta$，我们有 $T\_n(\\cos\\theta) = \\cos(n\\theta)$。
*   利用三角恒等式，可以证明 $T\_n(x)$ 是一个关于 $x$ 的 $n$ 次多项式。 $T\_0(x)=1, T\_1(x)=x, T\_{n+1}(x)=2xT\_n(x)-T\_{n-1}(x)$。
*   $T\_n(x)$ 的首项系数是 $2^{n-1}$。
*   在 $\[-1,1\]$ 区间内，$\\cos(n\\theta)$ 的值在 $+1$ 和 $-1$ 之间振荡。它在 $n+1$ 个点上达到其极值 $\\pm 1$，并且正负交替！

这完美地满足了等振荡定理的要求！ 因此，使得 $||x^n - P\_{n-1}(x)||\_\\infty$ 最小的那个多项式正是**缩放后的切比雪夫多项式**： $$\\tilde{T}\_n(x) = \\frac{1}{2^{n-1}} T\_n(x)$$ 这个多项式的最小最大值为 $\\frac{1}{2^{n-1}}$。

#### **8.3.3 切比雪夫多项式的应用**

**1\. 最佳插值节点的选择:** 回顾插值误差公式：$|f(x)-P\_n(x)| = \\left| \\frac{f^{(n+1)}(\\xi\_x)}{(n+1)!} \\prod\_{k=0}^n(x-x\_k) \\right|$。 为了最小化误差上界，我们需要选择一组插值节点 $x\_0, \\dots, x\_n$，使得节点多项式 $\\prod(x-x\_k)$ 的最大值最小。 这个问题正是我们刚刚解决的：这个最佳的节点多项式就是 $\\tilde{T}\_{n+1}(x)$。 因此，**最佳的插值节点**就是 \*\*$n+1$ 次切比雪夫多项式 $T\_{n+1}(x)$ 的根\*\*。 $$x\_k = \\cos\\left(\\frac{(2k+1)\\pi}{2(n+1)}\\right), \\text{ for } k=0, \\dots, n.$$ 这些根在区间 $\[-1,1\]$ 的两端更密集，中间更稀疏，正好可以抑制龙格现象。

**2\. 幂级数经济化 (Economization of Power Series):** 假设我们有一个高次多项式（例如，一个截断的泰勒级数）$P\_n(x)$ 来逼近 $f(x)$。我们想用一个次数更低的 $P\_{n-1}(x)$ 来代替它，同时希望损失的精度尽可能小。 $P\_n(x) - P\_{n-1}(x) = Q\_{n-1}(x)$ $P\_n(x) = a\_n x^n + \\dots$ 我们可以将 $x^n$ 用切比雪夫多项式表示：$x^n = \\frac{1}{2^{n-1}}T\_n(x) + (\\text{lower degree terms})$。 于是 $P\_n(x) = a\_n \\left(\\frac{1}{2^{n-1}}T\_n(x) + \\dots\\right) + \\dots$ 如果我们直接扔掉包含 $T\_n(x)$ 的这一项，即令 $P\_{n-1}(x) = P\_n(x) - \\frac{a\_n}{2^{n-1}}T\_n(x)$，那么我们引入的误差在 $\[-1,1\]$ 上的最大值仅为 $|\\frac{a\_n}{2^{n-1}}|$。 这是一种非常高效的降低多项式次数的方法，其精度损失远小于直接截断泰勒级数的最高次项。

### **课程总结**

**本讲核心要点：**

1.  **数值微分**通过逼近多项式的导数来估算函数导数，但它是一个**不稳定**的过程，因为舍入误差会随着步长 $h$ 的减小而被放大。中心差分格式 ($O(h^2)$) 优于前向/后向差分 ($O(h)$)。
2.  **数值积分**通过对插值多项式积分来估算定积分，它是一个**稳定**的过程。**梯形法则**和**辛普森法则**是基于等距节点的Newton-Cotes公式中最简单和常用的两种。
3.  **最佳多项式逼近**旨在最小化逼近的**最大误差 (minimax)**。其解由**切比雪夫等振荡定理**刻画。
4.  **切比雪夫多项式**是minimax逼近理论的核心，它解决了首一多项式的最小范数问题，并为我们提供了**最佳插值节点**的选择方案，以及**幂级数经济化**的强大工具。