---
title: "数值分析04:矩阵分解与线性系统迭代解法"
description: ""
pubDate: "2025-08-27"
heroImage: ""
---

# 数值分析04:矩阵分解与线性系统迭代解法

### **引言：算法的结构与选择**

在上一讲的后半部分，我们重新审视了高斯消元法，并强调了**部分主元法 (Partial Pivoting)** 对于保证数值稳定性的关键作用。我们已经有了一个强大而鲁棒的工具来求解一般的中小型线性方程组 $A\\mathbf{x} = \\mathbf{b}$。

然而，数值分析的探索永无止境。我们仍然面临着更深层次的问题：

1.  **结构化视角：** 高斯消元法的一系列行变换，能否用更优雅、更结构化的**矩阵语言**来描述？这样做有什么好处？这将引出我们今天第一个主题：**LU分解**。
2.  **特殊性利用：** 如果矩阵 $A$ 具有某些特殊性质（例如对称、正定或带状结构），我们能否设计出比通用高斯消元法更高效、更节省内存的算法？
3.  **规模的挑战：** 当矩阵 $A$ 的维度达到数万、数百万甚至更大时（这在科学和工程计算中很常见），$O(n^3)$ 的计算量和 $O(n^2)$ 的存储需求将变得无法承受。特别是当矩阵是**稀疏 (Sparse)** 的（即大部分元素为零）时，直接法会产生大量非零元，破坏其稀疏性。我们是否需要一种全新的思路？

这些问题将引导我们完成今天的学习。首先，我们将深入挖掘**直接法**的潜力，学习LU分解及其在特殊矩阵上的应用。然后，我们将开启**迭代法求解线性系统**的大门，这为解决超大规模问题提供了可能。

### **第一部分：矩阵分解**

#### **6.5.1 LU 分解 (LU Factorization)**

**核心思想：** 将高斯消元的过程，看作是用一系列**初等下三角矩阵**左乘矩阵 $A$，最终将其化为上三角矩阵 $U$ 的过程。

回忆高斯消元的第一步，我们用第一行去消去第一列的其他元素。这个操作可以由一个矩阵 $L\_1$ 来表示： $$L\_1 = \\begin{pmatrix} 1 & 0 & \\dots & 0 \\\\ -m\_{21} & 1 & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ -m\_{n1} & 0 & \\dots & 1 \\end{pmatrix}$$ 其中 $m\_{i1} = a\_{i1}/a\_{11}$。

经过 $n-1$ 步消元后，我们得到： $$L\_{n-1} \\dots L\_2 L\_1 A = U$$

其中 $U$ 是一个上三角矩阵。令 $L = (L\_{n-1} \\dots L\_2 L\_1)^{-1} = L\_1^{-1} L\_2^{-1} \\dots L\_{n-1}^{-1}$。可以证明，$L$ 是一个对角线元素全为1的**单位下三角矩阵**，其非对角线元素 $(i,j)$ 恰好就是消元过程中的乘数 $m\_{ij}$。

于是，我们得到了矩阵 $A$ 的一个分解：$A = LU$。

**定理 (LU 分解):** 如果对矩阵 $A$ 施行高斯消元法**不需要行交换**，那么 $A$ 可以唯一地分解为一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$ 的乘积。

**用 LU 分解求解 $A\\mathbf{x} = \\mathbf{b}$:** 一旦我们得到了 $A=LU$，求解过程分为两步：

1.  **前向替换 (Forward Substitution):** 求解 $L\\mathbf{y} = \\mathbf{b}$。 由于 $L$ 是下三角矩阵，这个过程非常快，计算量为 $O(n^2)$。 $$y\_1 = b\_1$$ $$y\_i = b\_i - \\sum\_{j=1}^{i-1} l\_{ij}y\_j, \\text{ for } i=2, \\dots, n$$
2.  **反向回代 (Backward Substitution):** 求解 $U\\mathbf{x} = \\mathbf{y}$。 这正是我们熟悉的标准回代过程，计算量也为 $O(n^2)$。

**LU 分解的优势：**

*   **计算解耦：** 将耗时最长（$O(n^3)$）的分解过程与求解过程（$O(n^2)$）分离开。
*   **高效处理多右端项：** 如果需要对同一个矩阵 $A$ 和多个不同的右端项 $\\mathbf{b}\_1, \\mathbf{b}\_2, \\dots$ 求解，我们只需做**一次** LU 分解，然后对每个 $\\mathbf{b}\_k$ 分别执行廉价的前向/后向替换即可。这在工程设计和逆矩阵计算中非常有用。

**带主元选择的 LU 分解：** 在实际应用中，我们必须考虑主元选择。部分主元法等价于在分解前对矩阵的行进行重新排列。这可以用一个**置换矩阵 (Permutation Matrix)** $P$ 来表示。因此，带部分主元的高斯消元法等价于对 $PA$ 进行 LU 分解，即 $PA = LU$。求解 $A\\mathbf{x}=\\mathbf{b}$ 就变成了求解 $LU\\mathbf{x} = P\\mathbf{b}$。

#### **6.5.2 特殊矩阵的分解**

当矩阵 $A$ 具有特殊结构时，我们可以设计出更高效的分解算法。

**1\. 严格对角占优矩阵 (Strictly Diagonally Dominant Matrix):** **定义：** 对于矩阵 $A$ 的每一行 $i$，其对角元 $a\_{ii}$ 的绝对值**严格大于**该行所有其他非对角元绝对值之和。 $$|a\_{ii}| > \\sum\_{j=1, j \\neq i}^{n} |a\_{ij}|, \\text{ for } i=1, \\dots, n$$

**重要性质：**

*   严格对角占优矩阵一定是**非奇异的**。
*   对其进行高斯消元**永远不需要行交换**，并且过程是**数值稳定的**。
*   消元过程中，矩阵会**保持**严格对角占优的性质。

**2\. 对称正定矩阵 (Symmetric Positive Definite, SPD):** **定义：** 矩阵 $A$ 是对称的 ($A=A^T$)，并且对于任意非零向量 $\\mathbf{x}$，二次型 $\\mathbf{x}^T A \\mathbf{x} > 0$。

**重要性质：**

*   所有对角元 $a\_{ii} > 0$。
*   绝对值最大的元素一定在对角线上。
*   所有主子矩阵也都是对称正定的。
*   高斯消元无需主元选择且数值稳定。

对于SPD矩阵，存在一种更高效、更节省内存的分解方法。 由于 $A=A^T$，且可以进行 LU 分解 $A=LU$，可以进一步推导出 $A=LDL^T$ 的分解，其中 $D$ 是对角元为正的对角矩阵。

**Cholesky 分解:** 更进一步，可以把 $D$ 的平方根吸收到 $L$ 中，得到 $A = (LD^{1/2})(D^{1/2}L^T)$。令 $\\tilde{L} = LD^{1/2}$，则 $\\tilde{L}$ 是一个下三角矩阵，我们有： $$A = \\tilde{L}\\tilde{L}^T$$ 这就是**Cholesky 分解**。它将一个SPD矩阵分解为一个下三角矩阵和其转置的乘积。

**Cholesky 分解的优势：**

*   **计算量减半：** 计算量约为 $\\frac{n^3}{6}$，是标准 LU 分解的一半。
*   **存储量减半：** 只需要计算并存储下三角矩阵 $\\tilde{L}$ 即可。
*   **数值稳定性极佳**，并且不需要计算平方根以外的其他复杂运算。

**3\. 三对角矩阵 (Tridiagonal Matrix):** 在偏微分方程和样条插值中，经常遇到三对角矩阵。对这类稀疏矩阵使用标准高斯消元会产生大量不必要的零元运算。 **Crout 约简法 (或 Thomas 算法):** 这是一种为三对角系统定制的、不进行主元选择的 LU 分解。它将三对角矩阵 $A$ 分解为一个对角元为1的下双对角矩阵 $L$ 和一个上双对角矩阵 $U$。整个过程的计算量和存储量都只是 $O(n)$，而非 $O(n^3)$！

**Lab 03 启示 (No Free Lunch):** 这个实验描述了一个场景，最终可以建立一个线性方程组。通过分析价格 $p\_i$ 和成本 $c\_i$ 的关系： $p\_i = 2c\_i + 0.5c\_{i-1} + 0.5c\_{i+1}$ 并处理边界情况（$i=1$ 和 $i=n$），我们可以得到一个形如 $A\\mathbf{c}=\\mathbf{p}$ 的线性方程组。这个矩阵 $A$ 正是一个**严格对角占优的三对角矩阵**！ $$\\begin{pmatrix} 2 & 0.5 & & & 0.5 \\\\ 0.5 & 2 & 0.5 & & \\\\ & \\ddots & \\ddots & \\ddots & \\\\ & & 0.5 & 2 & 0.5 \\\\ 0.5 & & & 0.5 & 2 \\end{pmatrix} \\begin{pmatrix} c\_1 \\\\ c\_2 \\\\ \\vdots \\\\ c\_{n-1} \\\\ c\_n \\end{pmatrix} = \\begin{pmatrix} p\_1 \\\\ p\_2 \\\\ \\vdots \\\\ p\_{n-1} \\\\ p\_n \\end{pmatrix}$$ （注意 $i=1$ 时邻居是 $d\_2, d\_n$， $i=n$ 时邻居是 $d\_{n-1}, d\_1$，导致矩阵首尾有非零元，这是一个**循环三对角矩阵**，但求解思想类似）。 因此，这个问题是应用高效的三对角求解器（如Thomas算法）的绝佳范例。

### **第二部分：迭代法求解线性系统**

#### **7.0 动机与基本思想**

**为什么需要迭代法？** 当矩阵 $A$ 是**大规模**且**稀疏**的（例如，在有限元分析中，$n$ 可能达到 $10^6$，但每行只有几个非零元），直接法面临两大挑战：

1.  **计算成本：** $O(n^3)$ 无法承受。
2.  **填充 (Fill-in)：** 消元过程会引入大量新的非零元，破坏稀疏性，导致内存爆炸。

**迭代法的思想：** 与求解非线性方程类似，我们将 $A\\mathbf{x}=\\mathbf{b}$ 转化为一个等价的**不动点形式**： $$\\mathbf{x} = T\\mathbf{x} + \\mathbf{c}$$ 其中 $T$ 是一个 $n \\times n$ 的矩阵，称为**迭代矩阵**，$\\mathbf{c}$ 是一个向量。 然后构造迭代序列： $$\\mathbf{x}^{(k+1)} = T\\mathbf{x}^{(k)} + \\mathbf{c}$$ 从一个初始猜测 $\\mathbf{x}^{(0)}$ 开始，我们希望这个向量序列 $\\mathbf{x}^{(k)}$ 能收敛到真实解 $\\mathbf{x}$。

**核心问题 (Discussion 12):**

1.  **如何构造 $T$ 和 $\\mathbf{c}$？** (设计方案)
2.  **在什么条件下序列会收敛？** (收敛性)
3.  **收敛有多快？** (收敛速度)

要回答这些问题，我们必须先引入度量向量和矩阵“大小”的工具。

#### **7.1 向量范数与矩阵范数**

**1\. 向量范数 (Vector Norms):** 向量范数 $|\\cdot|$ 是一个从 $\\mathbb{R}^n$ 到 $\\mathbb{R}$ 的函数，用于衡量向量的“长度”或“大小”。它必须满足三个性质： (1) **正定性:** $|\\mathbf{x}| \\ge 0$，且 $|\\mathbf{x}|=0 \\iff \\mathbf{x}=\\mathbf{0}$。 (2) **齐次性:** $|\\alpha\\mathbf{x}| = |\\alpha||\\mathbf{x}|$。 (3) **三角不等式:** $|\\mathbf{x}+\\mathbf{y}| \\le |\\mathbf{x}| + |\\mathbf{y}|$。

**常用向量范数 ($l\_p$-norm):**

*   **$l\_1$-范数 (Manhattan Norm):** $|\\mathbf{x}|\_1 = \\sum\_{i=1}^n |x\_i|$
*   **$l\_2$-范数 (Euclidean Norm):** $|\\mathbf{x}|\_2 = \\left(\\sum\_{i=1}^n x\_i^2\\right)^{1/2}$
*   **$l\_\\infty$-范数 (Maximum Norm):** $|\\mathbf{x}|\_\\infty = \\max\_{1 \\le i \\le n} |x\_i|$

**向量序列的收敛：** 我们说向量序列 ${\\mathbf{x}^{(k)}}$ 收敛到 $\\mathbf{x}$，是指它们的差向量的范数趋于0： $$\\lim\_{k \\to \\infty} |\\mathbf{x}^{(k)} - \\mathbf{x}| = 0$$ 一个重要的定理是，在有限维空间 $\\mathbb{R}^n$ 中，**所有范数都是等价的**。这意味着，如果一个序列在一个范数下收敛，那么它在所有范数下都收敛。因此，我们可以选择最方便计算的范数（通常是 $l\_\\infty$ 范数）来判断收敛。

**2\. 矩阵范数 (Matrix Norms):** 矩阵范数是衡量矩阵“大小”或“放大能力”的工具。除了满足类似向量范数的三个性质外，通常还要求第四个性质： (4) **相容性 (Submultiplicative):** $|AB| \\le |A||B|$

**自然范数 (Natural or Operator Norm):** 与向量范数相关联，矩阵 $A$ 的自然 $p$-范数定义为它对单位 $p$-球上向量的最大“拉伸”： $|A|\_p = \\max\_{|\\mathbf{x}|\_p=1} |A\\mathbf{x}|\_p$ 这种范数自动满足一个非常重要的性质：$|A\\mathbf{x}|\_p \\le |A|\_p |\\mathbf{x}|\_p$。

**可计算的矩阵范数：**

*   **$|A|\_\\infty$ (最大行和范数):** $|A|\_\\infty = \\max\_{1 \\le i \\le n} \\sum\\limits\_{j=1}^n |a\_{ij}|$ (找到各行元素绝对值之和的最大值)
*   **$|A|\_1$ (最大列和范数):** $|A|\_1 = \\max\_{1 \\le j \\le n} \\sum\\limits\_{i=1}^n |a\_{ij}|$ (找到各列元素绝对值之和的最大值)
*   **$|A|\_2$ (谱范数):** $|A|\_2 = \\sqrt{\\lambda\_{\\max}(A^T A)}$，其中 $\\lambda\_{\\max}$ 是矩阵 $A^T A$ 的最大特征值。这个范数理论上重要，但计算困难。

#### **7.2 迭代法的收敛性分析**

现在我们可以回答收敛性问题了。 对于迭代 $\\mathbf{x}^{(k+1)} = T\\mathbf{x}^{(k)} + \\mathbf{c}$，真实解 $\\mathbf{x}$ 满足 $\\mathbf{x} = T\\mathbf{x} + \\mathbf{c}$。 两式相减得到误差的传播关系： $$\\mathbf{x}^{(k+1)} - \\mathbf{x} = T(\\mathbf{x}^{(k)} - \\mathbf{x})$$ 令误差向量 $\\mathbf{e}^{(k)} = \\mathbf{x}^{(k)} - \\mathbf{x}$，则 $\\mathbf{e}^{(k+1)} = T \\mathbf{e}^{(k)}$。 反复迭代得到：$\\mathbf{e}^{(k)} = T^k \\mathbf{e}^{(0)}$。

要使序列收敛，即 $\\lim\_{k \\to \\infty} \\mathbf{e}^{(k)} = \\mathbf{0}$，我们必须要求 $\\lim\_{k \\to \\infty} T^k = O$ (零矩阵)。

**收敛的充分条件：** 取任意一种自然矩阵范数，我们有： $$|\\mathbf{e}^{(k+1)}| = |T \\mathbf{e}^{(k)}| \\le |T| |\\mathbf{e}^{(k)}|$$ 如果**迭代矩阵的某个自然范数 $|T| < 1$**，那么： $$|\\mathbf{e}^{(k)}| \\le |T|^k |\\mathbf{e}^{(0)}|$$ 由于 $|T|<1$，当 $k \\to \\infty$ 时，$|T|^k \\to 0$，因此 $|\\mathbf{e}^{(k)}| \\to 0$，序列收敛。

**收敛的充要条件 (更深刻的)** **谱半径 (Spectral Radius):** 一个矩阵 $T$ 的谱半径 $\\rho(T)$ 定义为其所有特征值绝对值的最大值： $$\\rho(T) = \\max\_i |\\lambda\_i|$$

**定理：** 迭代 $\\mathbf{x}^{(k+1)} = T\\mathbf{x}^{(k)} + \\mathbf{c}$ 对于**任意**初始向量 $\\mathbf{x}^{(0)}$ 都收敛的**充分必要条件**是迭代矩阵的**谱半径小于1**，即 $\\rho(T) < 1$。

由于任何自然范数都大于等于谱半径 ($\\rho(T) \\le |T|$)，所以 $|T|<1$ 是一个比 $\\rho(T)<1$ 更强的（但更容易计算的）充分条件。

#### **7.3 经典迭代法：Jacobi 和 Gauss-Seidel**

如何从 $A\\mathbf{x}=\\mathbf{b}$ 构造出 $T$ 和 $\\mathbf{c}$？ 关键在于将矩阵 $A$ 分解为 $A=D-L-U$，其中：

*   $D$ 是 $A$ 的对角部分。
*   $-L$ 是 $A$ 的严格下三角部分。
*   $-U$ 是 $A$ 的严格上三角部分。

$$A\\mathbf{x}=\\mathbf{b} \\implies (D-L-U)\\mathbf{x}=\\mathbf{b} \\implies D\\mathbf{x} = (L+U)\\mathbf{x} + \\mathbf{b}$$

**1\. Jacobi 迭代法:** 从上式解出 $\\mathbf{x}$ (假设 $D$ 可逆，即对角元非零)： $$\\mathbf{x} = D^{-1}(L+U)\\mathbf{x} + D^{-1}\\mathbf{b}$$ 由此得到 Jacobi 迭代格式： $$\\mathbf{x}^{(k+1)} = D^{-1}(L+U)\\mathbf{x}^{(k)} + D^{-1}\\mathbf{b}$$

*   **迭代矩阵:** $T\_J = D^{-1}(L+U)$
*   **分量形式:** $x\_i^{(k+1)} = \\frac{1}{a\_{ii}} \\left( b\_i - \\sum\_{j=1, j\\neq i}^{n} a\_{ij}x\_j^{(k)} \\right)$ Jacobi 法在计算 $\\mathbf{x}^{(k+1)}$ 的所有分量时，只使用上一步的向量 $\\mathbf{x}^{(k)}$。这使得它非常容易**并行化**。

**2\. Gauss-Seidel 迭代法:** 观察 Jacobi 法的分量形式，当我们在计算 $x\_i^{(k+1)}$ 时，其实我们已经计算出了 $x\_1^{(k+1)}, \\dots, x\_{i-1}^{(k+1)}$。为什么不立即使用这些最新的信息呢？ $$(D-L)\\mathbf{x} = U\\mathbf{x} + \\mathbf{b}$$ $$\\mathbf{x}^{(k+1)} = (D-L)^{-1}U\\mathbf{x}^{(k)} + (D-L)^{-1}\\mathbf{b}$$

*   **迭代矩阵:** $T\_{GS} = (D-L)^{-1}U$
*   **分量形式:** $x\_i^{(k+1)} = \\frac{1}{a\_{ii}} \\left( b\_i - \\sum\_{j=1}^{i-1} a\_{ij}x\_j^{(k+1)} - \\sum\_{j=i+1}^{n} a\_{ij}x\_j^{(k)} \\right)$ Gauss-Seidel 法利用了最新的可用信息，通常比 Jacobi 法**收敛更快**（但不总是）。但由于计算 $x\_i^{(k+1)}$ 依赖于 $x\_{i-1}^{(k+1)}$，它是**串行**的。

**收敛性保证：** 一个简单但实用的判据是：如果原矩阵 $A$ 是**严格对角占优**的，那么 Jacobi 和 Gauss-Seidel 迭代法**都保证收敛**。

### **课程总结**

**本讲核心要点：**

1.  **LU分解**是高斯消元的矩阵形式，它将计算解耦，特别适合处理多右端项问题。
2.  针对**特殊矩阵**（如对称正定、三对角）有更高效的分解算法（Cholesky、Crout），能极大节省计算和存储资源。
3.  当面临**大规模稀疏**线性系统时，**迭代法**是比直接法更优的选择。
4.  **范数**是分析向量序列收敛性的基础工具。迭代法 $\\mathbf{x}^{(k+1)} = T\\mathbf{x}^{(k)} + \\mathbf{c}$ 收敛的充要条件是迭代矩阵的**谱半径 $\\rho(T) < 1$**。
5.  **Jacobi** 和 **Gauss-Seidel** 是两种经典的迭代方法，它们通过分裂矩阵 $A$ 来构造迭代格式，各有优劣（并行性 vs 收敛速度）。