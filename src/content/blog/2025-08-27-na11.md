---
title: "数值分析11:复合求积、收敛加速与自适应积分"
description: ""
pubDate: "2025-08-27"
heroImage: ""
---

# 数值分析11:复合求积、收敛加速与自适应积分

### **引言：从基本公式到实用算法**

在上一讲中，我们开启了数值微积分的探索之旅，学习了如何通过对插值多项式进行积分来构造数值求积（Quadrature）公式。我们推导了两种最基本的 **Newton-Cotes** 公式：**梯形法则**和**辛普森法则**。

我们看到，这些低阶公式为我们提供了一种近似计算定积分的简单方法。然而，它们本身的应用是有限的。为什么？

1.  **精度与区间：** 梯形法则的误差是 $O(h^3)$，辛普森法则是 $O(h^5)$，其中 $h=b-a$ 是整个积分区间的长度。如果积分区间很大，即使是辛普森法则，误差也可能大到无法接受。
2.  **高阶公式的陷阱：** 我们可能会想，是否可以通过使用更高阶的 Newton-Cotes 公式（即在整个区间上使用更高次的插值多项式）来提高精度？答案是否定的。我们从插值理论中得知，高次多项式插值在等距节点上会产生剧烈的**龙格振荡现象 (Runge's Phenomenon)**。同样，高阶的 Newton-Cotes 公式会出现**负权**，导致数值不稳定，实际应用中几乎从不使用。

**那么，如何在保证稳定性的前提下，获得高精度的积分结果呢？**

今天的课程将围绕这个问题，介绍三种将简单求积公式转化为强大实用算法的核心技术：

1.  **复合求积法 (Composite Integration):** 这是最直观、最常用的方法。其思想是“分而治之”——将大区间切分成许多小区间，在每个小区间上应用低阶的、稳定的求积公式，然后将结果累加。
2.  **收敛加速技术 (Acceleration Techniques):** 我们会发现复合梯形法则的误差具有一个非常规则的结构。利用这一结构，我们可以通过一种名为**理查森外推 (Richardson's Extrapolation)** 的“事后处理”技术，从低精度结果中“提炼”出高精度的结果。这一思想的系统性应用便构成了**龙贝格积分 (Romberg Integration)**。
3.  **自适应求积法 (Adaptive Quadrature):** 现实中的被积函数在不同区域的“复杂程度”可能差异巨大。在函数平缓的区域使用过密的分割是一种浪费，在函数剧烈变化的区域使用过疏的分割则会导致精度不足。自适应求积通过**动态调整**步长，将计算资源智能地分配到最需要的地方。

### **第一部分：复合数值积分**

#### **4.4.1 核心思想：分而治之**

"Due to the oscillatory nature of high-degree polynomials, piecewise interpolation is applied..."这正是复合求积的根本动机。我们放弃在整个 $\[a,b\]$ 区间上使用单一高次插值多项式的想法，转而采用更稳健的**分段低次插值**。

**通用策略：**

1.  将积分区间 $\[a,b\]$ 分割成 $n$ 个等宽的子区间 $\[x\_{k-1}, x\_k\]$，其中 $x\_k = a+kh$，$h=(b-a)/n$。
2.  在**每一个**子区间上，应用一个简单的低阶 Newton-Cotes 公式（如梯形或辛普森法则）。
3.  将所有子区间上的积分近似值相加，得到整个区间上的积分近似值。

#### **4.4.2 复合梯形法则 (Composite Trapezoidal Rule)**

在每个子区间 $\[x\_{k-1}, x\_k\]$ 上应用梯形法则： $$\\int\_{x\_{k-1}}^{x\_k} f(x)dx \\approx \\frac{h}{2}\[f(x\_{k-1}) + f(x\_k)\]$$

将所有子区间的结果相加：

$$ \\begin{aligned} \\int\_a^b f(x)dx &= \\sum\_{k=1}^n \\int\_{x\_{k-1}}^{x\_k} f(x)dx \\approx \\sum\_{k=1}^n \\frac{h}{2}\[f(x\_{k-1}) + f(x\_k)\]\\\\ &= \\frac{h}{2} \[ (f(x\_0)+f(x\_1)) + (f(x\_1)+f(x\_2)) + \\dots + (f(x\_{n-1})+f(x\_n)) \] \\end{aligned} $$

观察到，除了首尾两个端点 $f(x\_0)=f(a)$ 和 $f(x\_n)=f(b)$ 只出现了一次外，所有的内部节点 $f(x\_k)$ ($k=1, \\dots, n-1$) 都被加了两次。

**复合梯形法则公式：** $$\\int\_a^b f(x)dx \\approx T\_n(h) = \\frac{h}{2} \\left\[ f(a) + 2\\sum\_{k=1}^{n-1} f(x\_k) + f(b) \\right\]$$

**误差分析：** 总误差是每个子区间误差之和。第 $k$ 个子区间的误差为 $E\_k = -\\frac{h^3}{12}f''(\\xi\_k)$。 $$R\[f\] = \\sum\_{k=1}^n E\_k = -\\frac{h^3}{12} \\sum\_{k=1}^n f''(\\xi\_k)$$ 根据推广的**中值定理 (MVT)**，存在一个 $\\xi \\in (a,b)$，使得 $\\sum\_{k=1}^n f''(\\xi\_k) = n \\cdot f''(\\xi)$。 $$R\[f\] = -\\frac{h^3}{12} n f''(\\xi) = -\\frac{h^2}{12} (nh) f''(\\xi)$$ 因为 $nh = b-a$，我们得到： **复合梯形法则误差：** $E\_T(h) = -\\frac{b-a}{12} h^2 f''(\\xi) = O(h^2)$ 这是一个**二阶方法**。步长 $h$ 减半，误差减为原来的 $1/4$。

#### **4.4.3 复合辛普森法则 (Composite Simpson's Rule)**

**注意：** 辛普森法则需要3个点，因此它作用在一个“大”区间 $\[x\_k, x\_{k+2}\]$ 上，这个大区间的宽度是 $2h$。为了应用复合辛普森法则，总的分割数 $n$ **必须是偶数**。

我们将 $\[a,b\]$ 分成 $n$ 个子区间（$n$为偶数），然后成对地应用辛普森法则在 $\[x\_{2k-2}, x\_{2k}\]$ 上，共 $n/2$ 次。 在区间 $\[x\_{2k-2}, x\_{2k}\]$ 上应用辛普森法则（步长仍为 $h$）： $$\\int\_{x\_{2k-2}}^{x\_{2k}} f(x)dx \\approx \\frac{h}{3}\[f(x\_{2k-2}) + 4f(x\_{2k-1}) + f(x\_{2k})\]$$ 将所有这些成对区间的结果相加，会发现：

*   偶数下标的内部节点 $f(x\_{2k})$ 被加了两次。
*   奇数下标的内部节点 $f(x\_{2k-1})$ 的系数总是4。

**复合辛普森法则公式：** $$\\int\_a^b f(x)dx \\approx S\_n(h) = \\frac{h}{3} \\left\[ f(a) + 4\\sum\_{k=1}^{n/2} f(x\_{2k-1}) + 2\\sum\_{k=1}^{n/2-1} f(x\_{2k}) + f(b) \\right\]$$

**误差分析：** 单个辛普森法则作用在宽度为 $2h$ 的区间上，误差为 $-\\frac{(2h)^5}{2880}f^{(4)}(\\xi\_k)$。总误差为 $n/2$ 个这样的误差之和。 **复合辛普森法则误差：** $E\_S(h) = -\\frac{b-a}{180} h^4 f^{(4)}(\\xi) = O(h^4)$ 这是一个**四阶方法**，精度非常高。

#### **4.4.4 数值稳定性分析**

"Composite integration techniques are all stable."为什么？ 考虑在计算函数值时存在舍入误差，即我们用 $f^\*(x\_i) = f(x\_i) + \\epsilon\_i$ 代替 $f(x\_i)$，其中 $|\\epsilon\_i| \\le \\epsilon$。 以复合辛普森法则为例，累积的舍入误差为： $$e(h) = \\frac{h}{3} \\left\[ \\epsilon\_0 + 4\\sum\_{\\text{odd}} \\epsilon\_k + 2\\sum\_{\\text{even}} \\epsilon\_k + \\epsilon\_n \\right\]$$ 其绝对值的上界为： $$|e(h)| \\le \\frac{h}{3} \\left\[ \\epsilon + 4\\frac{n}{2}\\epsilon + 2(\\frac{n}{2}-1)\\epsilon + \\epsilon \\right\] = \\frac{h}{3} \[ \\epsilon + 2n\\epsilon + (n-2)\\epsilon + \\epsilon \] = \\frac{h}{3} \[3n\\epsilon\] = nh\\epsilon = (b-a)\\epsilon$$

**关键结论：** 总的舍入误差上界 $(b-a)\\epsilon$ **与分割数 $n$ (或步长 $h$) 无关**！这意味着，即使我们为了减小截断误差而疯狂地增加分割数 $n$，累积的舍入误差也**不会被放大**。这与数值微分中舍入误差 $\\propto 1/h$ 的灾难性行为形成了鲜明对比。这就是数值积分的**稳定性**所在。

### **第二部分：收敛加速：理查森外推与龙贝格积分**

#### **4.2 理查森外推 (Richardson's Extrapolation)**

**核心思想：** 假设我们有一个计算方法 $N(h)$，它近似于真值 $M$，并且其误差可以表示为一个关于步长 $h$ 的幂级数： $M = N(h) + K\_1 h^{\\alpha\_1} + K\_2 h^{\\alpha\_2} + \\dots$ ($\\alpha\_1 < \\alpha\_2 < \\dots$)

现在，我们用两个不同的步长，比如 $h$ 和 $h/2$，进行两次计算： $$M = N(h) + K\_1 h^{\\alpha\_1} + O(h^{\\alpha\_2})$$ $$M = N(h/2) + K\_1 (h/2)^{\\alpha\_1} + O(h^{\\alpha\_2}) = N(h/2) + K\_1 \\frac{h^{\\alpha\_1}}{2^{\\alpha\_1}} + O(h^{\\alpha\_2})$$

这是一个关于未知数 $M$ 和 $K\_1 h^{\\alpha\_1}$ 的二元线性方程组！我们可以解出 $M$，消去主要的误差项 $O(h^{\\alpha\_1})$： $$N\_1(h) = \\frac{2^{\\alpha\_1} N(h/2) - N(h)}{2^{\\alpha\_1} - 1}$$ 这个新的近似值 $N\_1(h)$ 的误差是 $O(h^{\\alpha\_2})$，精度比原来的 $N(h)$ 更高！

这个过程被称为**理查森外推**。它是一种通用的**事后处理**技术，可以从一系列低精度计算中提取出高精度的结果，只要误差结构是已知的。

#### **4.5 龙贝格积分 (Romberg Integration)**

龙贝格积分就是将理查森外推**系统地、反复地**应用于**复合梯形法则**。

**为什么是梯形法则？** 一个非常深刻的数学结果（**欧拉-麦克劳林公式**）指出，复合梯形法则的误差，如果被积函数足够光滑，可以表示为一个关于 $h^2$ 的偶次幂级数： $$I = T(h) + K\_1 h^2 + K\_2 h^4 + K\_3 h^6 + \\dots$$

这正是应用理查森外推的完美场景！这里的 $\\alpha\_1=2, \\alpha\_2=4, \\dots$。

**龙贝格算法步骤：**

1.  **第一列 (梯形法则计算):**
    
    *   选择一个初始步长 $h\_0 = b-a$。计算 $R\_{1,1} = T(h\_0) = \\frac{h\_0}{2}\[f(a)+f(b)\]$。
    *   步长减半 $h\_1 = h\_0/2$。计算 $R\_{2,1} = T(h\_1) = \\frac{1}{2}R\_{1,1} + h\_1 \\sum f(x\_{\\text{new}})$。
    *   继续步长减半 $h\_k = h\_{k-1}/2$，计算 $R\_{k+1, 1} = T(h\_k)$。
2.  **后续列 (外推):** 应用理查森外推公式（这里 $\\alpha$ 每次都不同，是 $2j$）： $$R\_{k, j} = R\_{k, j-1} + \\frac{R\_{k, j-1} - R\_{k-1, j-1}}{4^{j-1}-1}$$
    

我们可以构造一个**龙贝格表**： $R\_{1,1} = T\_1^{(0)}$ $R\_{2,1} = T\_2^{(0)} \\quad R\_{2,2} = T\_1^{(1)}$ $R\_{3,1} = T\_4^{(0)} \\quad R\_{3,2} = T\_2^{(1)} \\quad R\_{3,3} = T\_1^{(2)}$ $R\_{4,1} = T\_8^{(0)} \\quad R\_{4,2} = T\_4^{(1)} \\quad R\_{4,3} = T\_2^{(2)} \\quad R\_{4,4} = T\_1^{(3)}$

**表中元素的含义：**

*   **第一列 ($R\_{k,1}$):** 复合梯形法则的结果，精度为 $O(h^{2})$。
*   **第二列 ($R\_{k,2}$):** 误差为 $O(h^{4})$。可以证明，这一列的结果与**复合辛普森法则**完全等价！
*   **第三列 ($R\_{k,3}$):** 误差为 $O(h^{6})$。这等价于更高阶的复合 Newton-Cotes 公式（Boole's Rule）。
*   **沿对角线** $R\_{k,k}$ 的收敛速度最快。

龙贝格积分是一种非常强大和流行的积分方法，它结合了梯形法则的简单性、理查森外推的加速能力，并且通过观察对角线元素的收敛情况，可以自动判断何时停止计算。

### **第三部分：自适应求积**

**动机：** 对于像 $\\int\_1^3 \\frac{100}{x^2}\\sin(\\frac{10}{x})dx$ 这样的积分，被积函数在 $x$ 较小的时候剧烈振荡，在 $x$ 较大的时候非常平滑。

*   **标准复合方法：** 为了捕捉振荡区域的细节，必须在整个积分区间上都使用非常小的步长 $h$，这在平滑区域造成了巨大的计算浪费。
*   **自适应思想：** "Predict the amount of functional variation and adapt the step size."我们希望算法能“智能”地在振荡区域加密采样点，在平滑区域使用稀疏的采样点，同时保证总误差在给定的容差 $\\epsilon$ 之内。

#### **4.6.1 核心策略：误差估计与递归**

**如何在没有真值的情况下估计误差？** 以辛普森法则为例。

1.  在区间 $\[a,b\]$ 上，用步长 $h=(b-a)/2$ 应用一次辛普森法则，得到一个“粗略”的近似值 $S(a,b)$。 $\\int\_a^b f(x)dx \\approx S(a,b)$, 其误差约为 $-\\frac{h^5}{90}f^{(4)}(\\xi\_1)$。
    
2.  将区间一分为二 $\[a, (a+b)/2\]$ 和 $\[(a+b)/2, b\]$。在每个子区间上应用辛普森法则（步长变为 $h/2$），然后相加，得到一个“精细”的近似值 $S(a, \\frac{a+b}{2}) + S(\\frac{a+b}{2}, b)$。 $\\int\_a^b f(x)dx \\approx S\_{\\text{fine}}$, 其误差约为 $2 \\times \\left( -\\frac{(h/2)^5}{90}f^{(4)}(\\xi\_2) \\right) = -\\frac{1}{16} \\frac{h^5}{90}f^{(4)}(\\xi\_2)$。
    
3.  假设 $f^{(4)}(x)$ 在区间内变化不大，则 $\\int\_a^b f(x)dx \\approx S(a,b) - 16E\_{\\text{fine}}$ 且 $\\int\_a^b f(x)dx \\approx S\_{\\text{fine}} - E\_{\\text{fine}}$。 联立解出误差的**可计算估计**： $$|E\_{\\text{fine}}| = \\left| \\int\_a^b f(x)dx - S\_{\\text{fine}} \\right| \\approx \\frac{1}{15} |S\_{\\text{fine}} - S(a,b)|$$
    

**自适应算法 (基于递归):** `FUNCTION AdaptiveQuadrature(f, a, b, TOL):`

1.  计算粗略积分 $S\_{coarse} = S(a,b)$。
2.  计算精细积分 $S\_{fine} = S(a, (a+b)/2) + S((a+b)/2, b)$。
3.  **估计误差** $Error \\approx \\frac{1}{15}|S\_{fine} - S\_{coarse}|$。
4.  **IF** $Error < TOL$: **RETURN** $S\_{fine}$ (当前区间的精度足够，返回结果)
5.  **ELSE**: // 精度不足，将容差减半，递归地处理左右两个子区间 `mid = (a+b)/2` `left_integral = AdaptiveQuadrature(f, a, mid, TOL/2)` `right_integral = AdaptiveQuadrature(f, mid, b, TOL/2)` **RETURN** `left_integral + right_integral`

自适应求积通过这种递归的“分治”策略，确保了计算量被有效地用在最需要的地方，是一种非常高效和智能的数值积分方法。

### **课程总结**

**本讲核心要点：**

1.  **复合求积**通过在小区间上重复使用低阶稳定公式（梯形、辛普森）来获得高精度，是数值积分最基本和可靠的方法。复合梯形法则是 $O(h^2)$，复合辛普森法则是 $O(h^4)$。
2.  数值积分是**稳定**的，增加计算点数不会放大舍入误差。
3.  **理查森外推**是一种强大的通用技术，能从具有规则误差结构的低精度结果中消除主误差项，从而“凭空”获得更高精度的结果。
4.  **龙贝格积分**是理查森外推在复合梯形法则上的系统应用，它能高效地生成一系列精度越来越高的积分近似值，并且可以自动判断收敛。
5.  **自适应求积**是一种更智能的方法，它通过局部误差估计来动态调整采样密度，将计算力集中在被积函数变化剧烈的区域，从而在满足总体精度要求的前提下，最大限度地节省计算量。