---
title: "ads04: 左式堆（Leftist Heaps） 和 斜堆（Skew Heaps）"
description: ""
pubDate: "2025-08-21"
heroImage: ""
---

# ads04: 左式堆（Leftist Heaps） 和 斜堆（Skew Heaps）

### 第一部分：左式堆 (Leftist Heaps)

#### 1.1 核心目标与思想

我们的核心目标非常明确：

**Target: 将合并操作的速度提升到 O(log N)。**

为了实现这个目标，我们必须对传统堆的结构进行一些改造。我们知道，一个标准的堆需要满足两个性质：

1.  **结构性 (Structure Property):** 它必须是一棵完全二叉树。
2.  **有序性 (Order Property):** 父节点的值必须小于（或大于）其所有子节点的值（以小顶堆为例）。

完全二叉树的结构保证了树的高度为 O(log N)，从而保证了 `insert` 和 `deleteMin` 的效率。但正是这个严格的结构限制，使得高效合并变得困难。

左式堆的思想就是：**放宽对结构性的要求，但引入一个新的规则来保证效率。**

*   **有序性 (Order Property):** 保持不变，父节点依然小于子节点。
*   **结构性 (Structure Property):** 不再是完全二叉树，只是一棵普通的二叉树，但是它必须是**不平衡**的，而且是**有目的地不平衡**。

#### 1.2 问题导入：传统堆合并的效率

在深入左式堆之前，让我们先来回答一个问题：

**【讨论 】: 如果我们坚持使用原始的（基于数组的）二叉堆结构，合并两个堆最快能做到多快？**

**答案：** 正如我们刚才提到的，最快可以做到 **O(N)**，其中 N 是两个堆的节点总数。具体方法是：

1.  将两个堆的底层数组简单地拼接在一起。
2.  对这个新的、无序的数组执行一次 `buildHeap` 操作。 `buildHeap` 算法通过自下而上地对每个非叶子节点执行 "下沉"（percolate down）操作，可以在线性时间 O(N) 内构建一个合法的堆。

虽然 O(N) 是线性的，但我们的目标是 O(log N)，这是一个巨大的飞跃。现在，让我们看看左式堆是如何通过引入一个巧妙的概念来实现这一点的。

#### 1.3 关键概念：零路径长 (Null Path Length, Npl)

为了控制树的“不平衡”，左式堆引入了一个核心概念——**零路径长**。

**【定义】零路径长 (Null Path Length, Npl)**

> 对于任意节点 $X$，它的零路径长 $\\text{Npl}(X)$ 指的是从 $X$ 出发，到达一个**缺少某个儿子**（即只有一个儿子或没有儿子）的节点所经过的最短路径的长度。
> 
> 为了方便计算，我们定义 $\\text{Npl}(\\text{NULL}) = -1$。

一个节点的两个子节点都不为 NULL，那么这个节点就不是我们寻找的终点。如果一个节点是叶子节点（左右子都为 NULL），或者它只有一个子节点，那么从它自己到它自己的路径长度是 0，它就满足“缺少某个儿子”的条件。

根据这个定义，我们可以推导出 `Npl` 的计算公式：

**【注意】计算 Npl(X):** `Npl(X) = 1 + min( Npl(X->left), Npl(X->right) )`

如果一个节点 X 是叶子节点，它的左右子节点都是 NULL。那么 `Npl(X) = 1 + min(Npl(NULL), Npl(NULL)) = 1 + min(-1, -1) = 0`。 如果一个节点 X 只有一个左孩子 L，右孩子为 NULL。那么 `Npl(X) = 1 + min(Npl(L), Npl(NULL)) = 1 + min(Npl(L), -1) = 0`。

这个 `Npl` 值衡量了距离“不完整”节点有多远。`Npl` 越大，说明从该节点向下，树的结构在“短期内”越完整。

#### 1.4 左式堆性质 (Leftist Heap Property)

有了 Npl 的概念，我们就可以定义左式堆的核心性质了。

**【定义】左式堆性质 (Leftist Heap Property)**

> 对于堆中的**每一个**节点 X，其**左孩子**的零路径长必须**大于或等于**其**右孩子**的零路径长。 `Npl(X->left) >= Npl(X->right)`

这个性质意味着什么？它强制要求树向左边“倾斜”和“加深”。任何节点的最短路径（即通向 NULL 的路径）必须出现在右子树中。因此，从根节点出发，一直沿着**右路径**(right path)走，是我们能最快到达一个 NULL 节点的方式。

让我们来看两个例子：

graph TD subgraph "合法的左式堆 (Valid Leftist Heap)" A(1) --> B(1); A --> C(0); B --> D(0); B --> E(0); D --> F(0); style A fill:#f9f,stroke:#333,stroke-width:2px style B fill:#ccf,stroke:#333,stroke-width:2px style C fill:#ccf,stroke:#333,stroke-width:2px style D fill:#ccf,stroke:#333,stroke-width:2px style E fill:#ccf,stroke:#333,stroke-width:2px style F fill:#ccf,stroke:#333,stroke-width:2px %% Node labels are Npl values end subgraph "非法的左式堆 (Invalid Leftist Heap)" A2(1) --> B2(0); A2 --> C2(1); C2 --> D2(0); C2 --> E2(0); D2 --> F2(0); style A2 fill:#f9f,stroke:#333,stroke-width:2px style B2 fill:#ccf,stroke:#333,stroke-width:2px style C2 fill:#f99,stroke:#333,stroke-width:2px style D2 fill:#ccf,stroke:#333,stroke-width:2px style E2 fill:#ccf,stroke:#333,stroke-width:2px style F2 fill:#ccf,stroke:#333,stroke-width:2px end

*   **左图 (合法)**:
    
    *   根节点(Npl=1): 左孩子(Npl=1) >= 右孩子(Npl=0)。合法。
    *   所有其他节点的子节点都是叶子(Npl=0)，满足 0 >= 0 或 0 >= -1。合法。
    *   这棵树明显是向左边倾斜的，**树被偏置成朝左边更深**。
*   **右图 (非法)**:
    
    *   根节点(Npl=1): 左孩子(Npl=0) < 右孩子(Npl=1)。**不合法**。这违反了左式堆的性质。

#### 1.5 右路径的长度分析

左式堆的核心优势，就在于它保证了**右路径非常短**。有多短呢？下面这个定理给出了答案。

**【定理】一棵右路径上有 $r$ 个节点的左式堆，至少拥有 $2^r - 1$ 个节点。**

**证明 (数学归纳法):**

*   **基础情况:** 当 $r = 1$ 时，右路径上只有1个节点（根节点）。这棵树至少要有 2¹ - 1 = 1 个节点。显然成立。
    
*   **归纳假设:** 假设对于所有右路径节点数小于 $r$ 的左式堆，定理成立。即，一棵右路径上有 $k < r$ 个节点的左式堆，至少有 $2^k - 1$ 个节点。
    
*   **归纳证明:** 考虑一棵右路径上有 $r$ 个节点的左式堆 $T$。设根节点为 $X$。它的右子树 $T\_R$ 的右路径上有 $r-1$ 个节点。根据归纳假设，$T\_R$ 至少有 $2^{r-1} - 1$ 个节点。 根据左式堆性质，`Npl(X->left) >= Npl(X->right)`。 我们知道，一个节点的 Npl 值等于其右路径的长度。所以，根的右孩子的 Npl，即 `Npl(T_R)`，就是 $T\_R$ 的右路径长度，即 $r-1$。 因此，`Npl(T_L) >= r-1`。这意味着 $T\_L$ 的右路径长度至少是 $r-1$。再次使用归纳假设，$T\_L$ 至少拥有 $2^{r-1} - 1$ 个节点。
    
    所以，整棵树 T 的总节点数 `N >= (T_L 的节点数) + (T_R 的节点数) + 1` $N \\geq (2^{r-1} - 1) + (2^{r-1} - 1) + 1$ $N \\geq 2 \* 2^{r-1} - 1$ $N \\geq 2^r - 1$
    
    证明完毕。
    

这个定理非常强大。它反过来告诉我们什么呢？

**【讨论 】: 对于一个有 $N$ 个节点的左式堆，它的右路径有多长？这个结论对我们意味着什么？**

**答案：** 根据定理，$N \\geq 2^r - 1$。 两边加 1，$N + 1 >= 2^r$。 两边取对数，$\\log\_2 (N+1) \\geq r$。 所以，**右路径的长度 $r \\leq \\log\_2 (N+1)$**，即 **$r = O(\\log N)$**。

**这个结论是左式堆所有高效操作的理论基石！** 它告诉我们，尽管左式堆整体可能非常不平衡，甚至深度可能达到 O(N)，但它最关键的操作路径——**右路径——的长度被严格限制在 $O(\\log N)$**。我们的所有核心操作，尤其是合并，都将沿着这条短路径进行。

#### 1.6 左式堆的核心操作：合并 (Merge)

现在，我们来看看万众期待的合并操作。这也是 `Insert` 和 `DeleteMin` 等操作的基础。

**核心思想：** 递归地合并两棵树的**右路径**，然后通过**交换子节点**来维护左式堆的性质。

假设我们要合并两个左式堆 H₁ 和 H₂。

**步骤分解 (以 H₁ 的根小于 H₂ 的根为例):**

1.  **Step 1: 递归合并。** 将 H₁ 的**右子树**与整个 H₂ 进行合并。由于 H₁ 的根是最小的，它将成为新堆的根。
2.  **Step 2: 连接。** 将 Step 1 合并得到的新树，作为 H₁ 新的**右子树**。
3.  **Step 3: 维护性质。** 检查 H₁ 的左右子树的 Npl 值。如果左子树的 Npl 小于右子树的 Npl，则违反了左式堆性质。此时，**交换 H₁ 的左右子树**。
4.  **更新 Npl。** 更新 H₁ 根节点的 Npl 值。新的 Npl 是其新右子树的 Npl + 1。

**图解合并过程：**

假设我们要合并下面两个堆 H₁ 和 H₂ (节点中的数字是元素值，红色代表在合并过程中被修改的节点)。

graph TD subgraph H1 A1(3) --> B1(10); A1 --> C1(8); B1 --> D1(21); B1 --> E1(14); C1 --> F1(17); E1 --> G1(23); F1 --> H1\_node(26); end subgraph H2 A2(6) --> B2(12); A2 --> C2(7); B2 --> D2(18); B2 --> E2(24); C2 --> F2(37); E2 --> G2(33); F2 --> H2\_node(18); end

**Merge(H₁, H₂):**

1.  H₁ 的根(3) < H₂ 的根(6)。所以 3 是最终的根。
2.  递归调用 `Merge(H₁->right, H₂)`，也就是 `Merge(树根为8的子树, H₂)`。
3.  在 `Merge(树根为8, 树根为6)` 中，6 < 8，所以 6 是这个子合并的根。
4.  递归调用 `Merge(树根为8, H₂->right)`，也就是 `Merge(树根为8, 树根为7)`。
5.  ... 这个过程会沿着两条原始的右路径 (3-8 和 6-7) 进行下去，直到其中一个为空。

**最终结果的可视化过程：**

*   **Step 1: Merge(H₁->Right, H₂)**
    
    *   这会递归地沿着 H₁ 和 H₂ 的右路径（3-8-... 和 6-7-...）进行合并。
    *   合并后的结果是，原来 H₁ 和 H₂ 的右路径上的节点，以及它们的左子树，会被重新组织成一棵新的、满足堆有序性的树。
*   **Step 2: Attach(..., H₁->Right)**
    
    *   将上面合并的结果挂在 H₁ 的根节点(3)下面，作为新的右子树。
    
    graph TD N3(3) --> N10(10); N3 --> N6(6); N10 --> N21(21); N10 --> N23(23); N6 --> N12(12); N6 --> N7(7); N12 --> N18a(18); N12 --> N24(24); N24 --> N33(33); N7 --> N8(8); N7 --> N37(37); N8 --> N17(17); N17 --> N26(26); N37 --> N18b(18); style N6 fill:#f99,stroke:#333,stroke-width:2px style N7 fill:#f99,stroke:#333,stroke-width:2px style N8 fill:#f99,stroke:#333,stroke-width:2px style N17 fill:#f99,stroke:#333,stroke-width:2px style N26 fill:#f99,stroke:#333,stroke-width:2px
    
*   **Step 3: Swap if necessary**
    
    *   在合并完成后，从下往上回溯。在每个节点，检查 `Npl(left) < Npl(right)` 是否成立。如果成立，就交换左右子树。
    *   例如，在上面的图中，节点3的左子树(根为10)的 Npl 肯定大于新形成的右子树(根为6)的 Npl，所以不需要交换。但在子合并的过程中，可能会发生交换。

#### 1.7 实现：伪代码与 C++ 代码

首先是数据结构定义：

```cpp
// C++
struct TreeNode {
    int element;
    TreeNode* left;
    TreeNode* right;
    int npl; // Null Path Length

    TreeNode(int val) : element(val), left(nullptr), right(nullptr), npl(0) {}
};
```

**Merge 伪代码与 C++ 实现:**

```cpp
// 伪代码
function Merge(H1, H2):
    if H1 is null: return H2
    if H2 is null: return H1

    if H1.element < H2.element:
        return Merge1(H1, H2)
    else:
        return Merge1(H2, H1)

function Merge1(H1, H2): // 假设 H1.element < H2.element
    // 如果 H1 没有左孩子，这是个优化。
    // 因为 H1 是单节点，它的右孩子也必然为 NULL。
    // 直接把 H2 挂到左边即可（因为右边必须最短）。
    if H1.left is null:
        H1.left = H2
    else:
        // 核心递归步骤
        H1.right = Merge(H1.right, H2)

        // 维护左式堆性质
        if H1.left.npl < H1.right.npl:
            swap(H1.left, H1.right)

        // 更新 Npl
        H1.npl = H1.right.npl + 1
    
    return H1
```

```cpp
// C++ 实现
#include <iostream>
#include <algorithm>

struct TreeNode {
    int element;
    TreeNode* left;
    TreeNode* right;
    int npl;

    TreeNode(int val) : element(val), left(nullptr), right(nullptr), npl(0) {}
};

// 安全获取 Npl 的辅助函数
int getNpl(TreeNode* node) {
    return node == nullptr ? -1 : node->npl;
}

// 合并主函数（内部调用）
TreeNode* merge1(TreeNode* h1, TreeNode* h2) {
    if (h1->left == nullptr) { // 特殊情况: h1 只有根节点
        h1->left = h2;
    } else {
        // 递归地合并 h1 的右子树和 h2
        h1->right = merge(h1->right, h2);

        // 检查并维护左式堆性质
        if (getNpl(h1->left) < getNpl(h1->right)) {
            std::swap(h1->left, h1->right);
        }

        // 更新 h1 的 npl
        h1->npl = getNpl(h1->right) + 1;
    }
    return h1;
}

// 对外暴露的合并接口
TreeNode* merge(TreeNode* h1, TreeNode* h2) {
    if (h1 == nullptr) return h2;
    if (h2 == nullptr) return h1;

    if (h1->element < h2->element) {
        return merge1(h1, h2);
    } else {
        return merge1(h2, h1);
    }
}
```

**思考: 如果 Npl 不更新会怎样？** 如果我们忘记更新 Npl，那么在后续的合并操作中，用于维护左式堆性质的 `if (Npl(left) < Npl(right))` 判断就会基于过时的、错误的信息。这将导致无法正确地维护左式堆性质，树的右路径长度将不再有 $O(\\log N)$ 的保证，最坏情况下可能退化成 $O(N)$，从而失去所有性能优势。

#### 1.8 其他操作

有了高效的 `merge`，其他操作就变得非常简单：

*   **Insert (插入):** 插入一个新元素 `x`，等价于将原始堆与一个只包含 `x` 的单节点堆进行合并。 `heap = merge(heap, new TreeNode(x));`
*   **DeleteMin (删除最小):** 最小元素就是根节点。删除它，然后将其左右子树合并即可。 `TreeNode* minNode = heap;` `heap = merge(heap->left, heap->right);` `delete minNode;`

由于这些操作都基于 `merge`，而 `merge` 的时间复杂度由右路径长度决定，是 O(log N)，所以 **`Insert` 和 `DeleteMin` 的时间复杂度也都是 $O(\\log N)$**。

* * *

### 第二部分：斜堆 (Skew Heaps)

左式堆非常高效，但它有一个小小的“缺点”：需要额外存储和维护 `npl` 这个值。这不仅增加了空间开销，也让代码逻辑稍微复杂了一点。

有没有一种“懒人版”的左式堆，不需要 `npl` 也能达到类似的效果呢？答案就是**斜堆**。

#### 2.1 核心思想：无条件的交换

斜堆是左式堆的一种自适应（self-adjusting）变体。它的核心思想非常激进和简单：

**Merge 法则:** 在递归地合并右路径之后，**总是 (always) 交换**根节点的左右子节点。

就是这样！没有 `npl`，没有判断 `if (Npl(left) < Npl(right))`，只有简单粗暴的“**合并右路，然后交换**”。

这个无条件的交换操作，就是“斜堆”名字的由来。它不断地“扭曲”这棵树，将原本在右边的长路径“扭”到左边去，从而在长期看来，摊平了操作成本。

**一个小的例外:** 在某些描述中，会提到“最深路径上的最后一个节点不交换”。这其实不是一个特殊的规则，而是递归算法自然结束的结果。当递归到最底层进行合并时，其中一个子树是 NULL，合并后挂上去，再交换，效果上和直接挂上去是一样的。所以我们只需要记住核心规则：**合并右路，然后交换**。

#### 2.2 性能目标：摊销分析 (Amortized Analysis)

斜堆放弃了左式堆那种严格的、每次操作都保证的 O(log N) 性能。取而代之的是一个**摊销 (Amortized)** 的 $O(\\log N)$ 复杂度。

**Target: 任意 $M$ 次连续操作的总时间最多为 $O(M \\log N)$。**

这意味着，虽然单次操作可能很慢（最坏 $O(N)$），但这种情况很少见。一次昂贵的操作会“整理”树的结构，为后续的廉价操作“付费”，从而使得平均下来每次操作的成本是 $O(\\log N)$。

#### 2.3 斜堆的合并操作

让我们用图来展示一下斜堆的合并。还是 $H\_1$ 和 $H\_2$。

graph TD subgraph H1 A1(3) --> B1(10); A1 --> C1(8); B1 --> D1(21); B1 --> E1(14); C1 --> F1(17); E1 --> G1(23); F1 --> H1\_node(26); end subgraph H2 A2(6) --> B2(12); A2 --> C2(7); B2 --> D2(18); B2 --> E2(24); C2 --> F2(37); E2 --> G2(33); %% A slight change for clarity F2 --> H2\_node(35); end

**Merge(H₁, H₂):**

1.  H₁ 的根(3) < H₂ 的根(6)。所以 3 是最终的根。
2.  递归调用 `Merge(H₁->right, H₂)`，即 `Merge(树根为8, H₂)`。
3.  **注意：** 在递归返回后，将 H₁ 的新右子树（即第2步的结果）与它的旧左子树（根为10）**进行交换**。

这个过程会一路向下，每次递归返回时都执行一次交换。

合并 H₁ 的右子树(8)和 H₂ 的过程。合并 8 和 6，6 成为根，递归合并 8 和 7。合并 8 和 7，7 成为根，递归合并 8 和 37... 在每次递归返回时，比如 7 这个节点，它的左右孩子（合并后的 8 和 null）会被交换。然后 6 这个节点，它的左右孩子（12 和合并后的 7）也会被交换。这个交换链会一直传递到顶层。

#### 2.4 实现：伪代码与 C++

斜堆的实现比左式堆更简洁。

```cpp
// C++ TreeNode 结构 (无需 npl)
struct SkewNode {
    int element;
    SkewNode* left;
    SkewNode* right;

    SkewNode(int val) : element(val), left(nullptr), right(nullptr) {}
};

// C++ 实现
#include <iostream>
#include <algorithm>

SkewNode* merge(SkewNode* h1, SkewNode* h2) {
    if (h1 == nullptr) return h2;
    if (h2 == nullptr) return h1;

    // 保证 h1 的根是较小值
    if (h1->element > h2->element) {
        std::swap(h1, h2);
    }

    // 递归合并 h1 的右子树和 h2
    h1->right = merge(h1->right, h2);

    // 无条件交换 h1 的左右子节点
    std::swap(h1->left, h1->right);

    return h1;
}

// Insert 和 DeleteMin 的实现与左式堆完全相同，只是调用的是斜堆的 merge
```

#### 2.5 摊销分析 (Amortized Analysis)

现在到了最硬核的部分：如何证明斜堆的合并操作具有摊销 $O(\\log N)$ 的复杂度？我们将使用**势能法 (Potential Method)**。

1.  **定义“势”函数 (Potential Function):** 我们需要一个函数 $\\Phi(D)$，它能衡量堆 $D$ 的“结构混乱程度”。当 $\\Phi$ 值高时，表示结构较差，未来操作可能很快；当 $\\Phi$ 值低时，表示结构较好，未来操作可能较慢。
    
2.  **定义“重节点”与“轻节点” (Heavy/Light Nodes):** **【定义】** 对于一个节点 $p$，`size(p)` 表示以 $p$ 为根的子树中的节点总数（包括$p$）。 如果 `size(p->right) > size(p->left)`，我们称节点 $p$ 是**重节点 (heavy node)**。 否则，称 $p$ 是**轻节点 (light node)**。
    
    > _(注意：这个定义与某些教科书可能略有不同，比如用 `size(p->right) > 1/2 * size(p)`，但核心思想一致)_
    
3.  **势函数:** **$\\Phi(D)$ = 堆 $D$ 中所有重节点的数量。**
    
4.  **摊销成本公式:** **T\_amortized = T\_actual + $\\Delta \\Phi$ = T\_actual + ($\\Phi$\_final - $\\Phi$\_initial)** 其中 `T_actual` 是实际运行时间。我们的目标是证明 `T_amortized` 是 $O(\\log N)$。
    

**证明思路:** 合并操作的实际成本 `T_actual` 与两个堆右路径的长度成正比。我们将证明，在合并过程中，如果右路径很长，那么这条路径上一定有很多**重节点**。而斜堆的“交换”操作，会**将这些重节点变成轻节点**，从而导致势函数 $\\Phi$ 大幅下降。这个势能的下降，就“支付”了实际操作的高昂成本。

**详细分析 `merge(H1, H2)` (假设 H1 的根更小):**

*   **实际成本 `T_actual`:** 合并操作访问的节点都在 H1 和 H2 的初始右路径上。设 H1 的右路径长度为 `r1`，H2 的为 `r2`。`T_actual` 正比于 `r1 + r2`。
    
*   **势能变化 $\\Delta \\Phi$:**
    
    *   在合并路径上的节点，它们的重/轻状态可能会改变。
    *   考虑 H1 右路径上的一个**重节点** $p$。这意味着 `size(p->right) > size(p->left)`。在合并过程中，$p$ 的右子树会被一个新的、合并后的子树替换，然后 $p$ 的左右子树会**交换**。新的左子树是原来大的右子树，新的右子树是原来小的左子树。因此，这个重节点 $p$ **必然会变成一个轻节点**。
    *   考虑 H1 右路径上的一个**轻节点** $q$。它在交换后，可能会变成重节点，也可能仍然是轻节点。
    *   设 H1 和 H2 的右路径上，共有 $h$ 个重节点和 $l$ 个轻节点。`T_actual ≈ h + l`。
    *   在操作后，这 $h$ 个重节点全部变成了轻节点，导致势函数至少减少 $h$。
    *   这 $l$ 个轻节点中，最多有 $l$ 个可能会变成重节点，导致势函数最多增加 $l$。
    *   所以，势能变化 $\\Delta \\Phi \\leq l - h$。
*   **计算摊销成本:** `T_amortized = T_actual + ΔΦ <= (h + l) + (l - h) = 2l`
    
    摊销成本只与右路径上的**轻节点**数量有关！
    
*   **最后一步：证明轻节点路径的长度为 O(log N)** 如果从一个节点 $p$ 出发，沿着任意路径向下走，路径上连续有 $k$ 个轻节点。设路径为 $p\_1, p\_2, ..., p\_k$。 因为 $p\_i$ 是轻节点，所以 `size(p_i->right) <= size(p_i->left)`。 那么 `size(p_{i-1}) = size(p_i) + size(p_{i-1}->left) + 1`。由于 $p\_{i-1}$ 是轻节点，`size(p_{i-1}->right) <= size(p_{i-1}->left)`，而 $p\_i$ 就在右子树中，所以 `size(p_i) <= size(p_{i-1}->left)`。 因此，`size(p_{i-1}) >= 2 * size(p_i) + 1`。 这是一个指数增长关系！从根节点到任意节点的路径上，轻节点的数量不可能是无限的。具体来说，路径上轻节点的数量 $l$ 必须满足 $N \\geq 2^l$，即 **$l \\leq \\log N$**。
    
*   **结论:** `T_amortized = 2l = O(log N)`。
    
    证明完毕！斜堆的合并操作具有摊销 $O(\\log N)$ 的复杂度。
    

#### 2.6 左式堆 vs. 斜堆

特性

左式堆 (Leftist Heap)

斜堆 (Skew Heap)

**核心思想**

维护 Npl，强制右路径最短

无条件交换左右子节点

**空间开销**

每个节点需额外存储 Npl

无额外空间开销

**性能保证**

**最坏情况 (Worst-Case)** $O(\\log N)$

**摊销 (Amortized)** $O(\\log N)$

**实现复杂度**

稍高，需要计算和更新 Npl

非常低，代码简洁

**适用场景**

需要严格实时性保证的系统

对单次操作性能不敏感，但总体吞吐量要求高的场景

**补充说明:**

> *   **空间优势:** 斜堆不需要额外的空间来维护路径长度，也不需要额外的比较来决定是否交换。这使得它在实践中非常轻量和快速。
> *   **开放问题:** 精确计算左式堆和斜堆在随机数据下的**期望右路径长度**仍然是一个开放的理论问题。

* * *

### 总结

*   **左式堆** 通过引入**零路径长 (Npl)** 的概念，并强制维持“左倾”的结构，保证了其**右路径长度始终为 $O(\\log N)$**，从而为所有操作提供了**最坏情况下的 $O(\\log N)$ 性能保证**。
*   **斜堆** 则是左式堆的“懒惰”或“自适应”版本。它放弃了严格的结构维护，代之以一个简单粗暴的\*\*“无条件交换”**规则。虽然这牺牲了最坏情况的性能，但通过**摊销分析\*\*，我们证明了其长期平均性能同样是 **$O(\\log N)$**，且实现更简单，空间开销更小。

这两种数据结构完美地诠释了算法设计中的一种重要思想：**为了优化特定操作（这里是 Merge），我们可以牺牲一些其他方面的约束（如完全二叉树结构），并通过引入新的规则（Npl 或无条件交换）来重新获得性能保证。**