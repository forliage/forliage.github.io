---
title: "ads15:外部排序 (External Sorting)"
description: ""
pubDate: "2025-08-22"
heroImage: ""
---

# ads15:外部排序 (External Sorting)

### 1\. 为什么需要外部排序？

让我们从一个问题开始：**为什么我们不能直接在磁盘上运行像快速排序（Quicksort）这样的高效内部排序算法呢？**

我们知道，快速排序是一个非常优秀的算法，它的平均时间复杂度是 $O(N \\log N)$。这个复杂度分析是基于一个基本假设：访问任意一个元素 `a[i]` 的时间是常数时间，即 $O(1)$。

这个假设在\*\*内存（Internal Memory）**中是成立的。但在**硬盘（Hard Disk）\*\*这样的外部存储设备上，这个假设就完全失效了。

要从硬盘上获取一个数据 `a[i]`，计算机需要经历一个复杂且耗时的过程：

1.  **寻道（Find the track）**: 磁头需要移动到数据所在的磁道。这是机械运动，速度很慢，通常是毫秒级。
2.  **旋转延迟（Find the sector）**: 等待磁盘旋转，直到数据所在的扇区转到磁头下方。这同样是毫秒级的延迟。
3.  **传输（Transmit）**: 将数据从磁盘扇区读取并传输到内存。

这整个过程比内存访问慢了几个数量级。快速排序的特点是频繁地进行**随机访问**（例如，选择基准元，分区操作中的元素交换），如果每次访问都要经历一次完整的硬盘I/O，那性能将是灾难性的。我们可以说，这种I/O操作是**设备相关的（device-dependent）**，其成本远远超过了CPU的计算成本。

因此，外部排序算法设计的核心思想就是：**最小化磁盘I/O的次数**。

为了简化模型，便于我们分析，我们引入一个经典工具：**归并排序（Mergesort）**，并做出以下简化假设：

*   数据存储在**磁带（Tapes）**上，磁带只能进行**顺序读写**，这非常符合我们减少随机访问的目标。
*   我们至少有 **3** 个磁带机。

### 2\. 两阶段外部归并排序：一个实例

外部排序通常分两个阶段：

1.  **生成初始顺串（Run Generation）**: 在内存限制下，从输入数据中生成尽可能长的、已排序的子序列，我们称之为“顺串”（Run），并将这些顺串写到外部存储上。
2.  **合并顺串（Run Merging）**: 将生成的多个顺串通过多路归并，最终合并成一个完全有序的序列。

让我们通过一个例子来直观地理解这个过程。

**【例子】** 假设我们的输入数据在磁带 `T1` 上，内部存储器一次最多能处理 $M=3$ 条记录。输入数据共有 $N=13$ 条记录。

`T1`: `81 94 11 | 96 12 35 | 17 99 28 | 58 41 75 | 15`

#### **阶段一：生成初始顺串**

我们逐块读取数据，每块大小为 $M=3$。在内存中对它们进行内部排序，然后将排好序的顺串交替写入到两个磁带 `T2` 和 `T3` 上。

1.  读入 `81 94 11` -> 内存排序 -> `11 81 94` -> 写入 `T2`
2.  读入 `96 12 35` -> 内存排序 -> `12 35 96` -> 写入 `T3`
3.  读入 `17 99 28` -> 内存排序 -> `17 28 99` -> 写入 `T2`
4.  读入 `58 41 75` -> 内存排序 -> `41 58 75` -> 写入 `T3`
5.  读入 `15` -> 内存排序 -> `15` -> 写入 `T2`

这个过程被称为一次\*\*“遍”（Pass）\*\*，我们称之为 **Pass 0**。完成后，磁带状态如下：

`T2`: `[11 81 94] [17 28 99] [15]` (共3个顺串) `T3`: `[12 35 96] [41 58 75]` (共2个顺串)

这里每个方括号`[]`代表一个已排序的顺串。

#### **阶段二：合并顺串**

现在我们进行多趟（Passes）合并。每一趟合并都从 `T2` 和 `T3` 中各取一个顺串，将它们合并成一个两倍长的顺串，然后交替写入另外两个磁带（这里是 `T1` 和 `T4`）。

**Pass 1:**

*   合并 `T2` 的 `[11 81 94]` 和 `T3` 的 `[12 35 96]` -> `[11 12 35 81 94 96]` -> 写入 `T1`
*   合并 `T2` 的 `[17 28 99]` 和 `T3` 的 `[41 58 75]` -> `[17 28 41 58 75 99]` -> 写入 `T4`
*   `T2` 剩下 `[15]`，直接复制到 `T1`

完成后磁带状态： `T1`: `[11 12 35 81 94 96] [15]` `T4`: `[17 28 41 58 75 99]`

**Pass 2:**

*   合并 `T1` 的 `[11 12 35 81 94 96]` 和 `T4` 的 `[17 28 41 58 75 99]` -> `[11 12 17 28 35 41 58 75 81 94 96 99]` -> 写入 `T2`
*   `T1` 剩下 `[15]`，直接复制到 `T3`

完成后磁带状态： `T2`: `[11 12 17 28 35 41 58 75 81 94 96 99]` `T3`: `[15]`

**Pass 3:**

*   合并 `T2` 的长顺串和 `T3` 的 `[15]` -> 最终排好序的序列 -> 写入 `T1`

完成后磁带状态： `T1`: `[11 12 15 17 28 35 41 58 75 81 94 96 99]` (排序完成)

总共的遍数是多少？

*   **Pass 0**: 生成初始顺串，这是 **1** 遍。
*   **Pass 1, 2, 3**: 合并顺串，共 **3** 遍。
*   总遍数 = $1 + 3 = 4$ 遍。

我们来分析一下合并阶段的遍数。初始顺串的数量是 $\\lceil N/M \\rceil = \\lceil 13/3 \\rceil = 5$ 个。 每一次2-路归并，顺串数量大约减半。所以合并遍数大约是 $\\log\_2(\\text{顺串数量})$。 总遍数 = $1 (\\text{生成}) + \\lceil \\log\_2(\\lceil N/M \\rceil) \\rceil (\\text{合并}) = 1 + \\lceil \\log\_2(5) \\rceil = 1 + 3 = 4$ 遍。

这正是幻灯片中给出的公式： **总遍数 = $1 + \\lceil \\log\_2(N/M) \\rceil$**

### 3\. 性能考量与优化目标

通过上面的例子，我们可以总结出外部排序的主要时间开销在哪些方面：

*   **寻道时间 (Seek time)**: 每次开始读写一个新的顺串块（block）时都会发生。它的总开销与**总遍数**成正比。这是我们优化的首要目标。
*   **读写时间**: 传输数据的时间，与数据总量和读写遍数有关。
*   **内部排序时间**: 在Pass 0生成初始顺串时，对内存中的 $M$ 个记录进行排序的时间。
*   **内部合并时间**: 在合并阶段，从输入缓冲区向输出缓冲区合并记录的CPU时间。

通常情况下，I/O时间（寻道+读写）远大于CPU处理时间。一个好消息是，现代计算机可以**并行执行 I/O 和 CPU 处理**。例如，当CPU在处理当前内存中的数据时，可以预先将下一块数据从磁盘读入缓冲区。

基于以上分析，我们的优化目标（Targets）变得非常清晰：

1.  **减少总遍数（Reduction of the number of passes）**: 这是最核心的优化点。
2.  **优化顺串合并（Run merging）**: 提高合并效率，比如使用更少的磁带。
3.  **优化缓冲区管理（Buffer handling for parallel operation）**: 实现I/O和CPU的并行，隐藏I/O延迟。
4.  **优化初始顺串生成（Run generation）**: 生成更长的初始顺串，从源头上减少顺串数量。

接下来，我们将逐一探讨实现这些目标的策略。

### 4\. 优化策略一：k-路归并 (k-way Merge)

如何最直接地减少合并的遍数？答案是**增加每次合并的顺串数量**。之前的例子是2-路归并，如果我们能同时合并 $k$ 个顺串，即 **k-路归并**，那么顺串数量每次会减少为原来的 $1/k$。

这样，合并遍数的公式就从 $\\lceil \\log\_2(\\text{顺串数}) \\rceil$ 变为 $\\lceil \\log\_k(\\text{顺串数}) \\rceil$。

**总遍数 = $1 + \\lceil \\log\_k(N/M) \\rceil$**

`k` 越大，$\\log\_k$ 的值越小，遍数就越少。

让我们用一个图来形象地展示这个过程。假设我们有4个初始顺串，进行2-路归并和4-路归并的对比：

graph TD subgraph "2-路归并 (2 Passes)" direction TB A1\[Run 1\] --> M1((Merge)) A2\[Run 2\] --> M1 A3\[Run 3\] --> M2((Merge)) A4\[Run 4\] --> M2 M1 --> F1((Final Merge)) M2 --> F1 end subgraph "4-路归并 (1 Pass)" direction TB B1\[Run 1\] --> M\_Final((Merge)) B2\[Run 2\] --> M\_Final B3\[Run 3\] --> M\_Final B4\[Run 4\] --> M\_Final end

**【权衡与代价】**

k-路归并虽然减少了遍数，但也带来了新的挑战：

1.  **更多的磁带/文件句柄**: 一个简单的模型是，需要 $k$ 个输入磁带和 $k$ 个输出磁带，交替进行读写，总共需要 **2k 个磁带**。这在磁带是物理设备的年代是一个巨大的成本。在现代系统中，这意味着需要同时打开更多的文件。
2.  **更多的内存**：为了进行k-路归并，我们需要 $k$ 个输入缓冲区来存放每个顺串的当前数据块，以及至少1个输出缓冲区。

因此，`k` 的选择是一个权衡：它受到可用内存和磁带/文件句柄数量的限制。

### 5\. 优化策略二：多相归并 (Polyphase Merge)

2k个磁带的代价太高了。我们能否用更少的磁带完成k-路归并？比如，**用3个磁带完成2-路归并？**

让我们来分析一下。假设初始顺串都在 `T1` 上，我们需要把它们分配到 `T2` 和 `T3` 上，然后从 `T2`, `T3` 归并回 `T1`。

**传统方法：均匀分配** 假设有34个初始顺串。我们把它们均匀分配：

*   `T2`: 17个顺串
*   `T3`: 17个顺串

现在开始合并：从 `T2` 和 `T3` 各读一个，合并到 `T1`。

*   **Pass 1**: `T2` 和 `T3` 的17对顺串合并后，`T1` 上会得到17个新顺串。`T2` 和 `T3` 变空。
*   **问题来了**: 现在所有顺串都在 `T1` 上，我们无法继续归并。必须停下来，做一次\*\*拷贝（copy）\*\*操作，将 `T1` 上的17个顺串再重新分配到 `T2`(9个) 和 `T3`(8个) 上。然后才能继续下一轮归并。

这种频繁的拷贝操作非常低效，完全违背了我们最小化I/O的初衷。

**更聪明的方法：不均匀分配 (A smarter way – split unevenly)**

这正是**多相归并**的精髓。它的思想是，在每一轮归并后，都期望恰好有一个磁带变空，而其他磁带上仍有数据，这样就可以立即开始下一轮归并，形成一个完美的多相工作流，避免了任何拷贝。

这个完美的分配比例，恰好与\*\*斐波那契数（Fibonacci numbers）\*\*有关！

斐波那契数列：$F\_0=0, F\_1=1, F\_2=1, F\_3=2, F\_4=3, F\_5=5, F\_6=8, F\_7=13, F\_8=21, F\_9=34, ...$ 其中 $F\_N = F\_{N-1} + F\_{N-2}$。

**【声明】**: 如果初始顺串的总数是一个斐波那契数 $F\_N$，那么用3个磁带进行2-路归并的最佳分配方式是将其分配到两个磁带上，数量分别为 $F\_{N-1}$ 和 $F\_{N-2}$。

让我们用34个顺串 ($F\_9=34$) 来验证一下：

*   初始分配：`T2` 上放 $F\_8=21$ 个顺串，`T3` 上放 $F\_7=13$ 个顺串。`T1` 为空，作为输出磁带。

**归并过程:**

1.  **Merge 1**: 从 `T2` 和 `T3` 各取13个顺串进行归并，生成13个新顺串到 `T1`。
    
    *   `T1`: 13个顺串 (长度为2)
    *   `T2`: 剩下 $21-13=8$ 个顺串 (长度为1)
    *   `T3`: 变空 此时，`T1` 和 `T2` 上的顺串数量为13和8，恰好是 $F\_7$ 和 $F\_6$！`T3` 顺理成章地成为新的输出磁带。
2.  **Merge 2**: 从 `T1` 和 `T2` 各取8个顺串归并到 `T3`。
    
    *   `T1`: 剩下 $13-8=5$ 个顺串
    *   `T2`: 变空
    *   `T3`: 8个新顺串 此时，`T1` 和 `T3` 上的顺串数量为5和8，即 $F\_5$ 和 $F\_6$。

这个过程会一直持续下去，每次归并都会消耗掉一个磁带上的所有顺串，并且剩下两个磁带上的顺串数量恰好是相邻的两个斐波那契数。

graph TD A\["**初始状态 (34个顺串)**  
T1: (输出磁带)  
T2: 21个顺串 (F8)  
T3: 13个顺串 (F7)"\] --> B("**Pass 1**  
从T2和T3合并13个顺串到T1") --> C\["**状态 1 (21个顺串)**  
T1: 13个顺串 (F7)  
T2: 8个顺串 (F6)  
T3: (输出磁带)"\] --> D("**Pass 2**  
从T1和T2合并8个顺串到T3") --> E\["**状态 2 (13个顺串)**  
T1: 5个顺串 (F5)  
T2: (输出磁带)  
T3: 8个顺串 (F6)"\] --> F("...") --> G\["**最终状态 (1个顺串)**  
排序完成"\]

最终，经过 $N-1$ 次（这里是 $9-1=8$ 次）这样的合并阶段，所有数据都会被合并成一个单一的、完全排序的顺串，整个过程没有任何数据拷贝。

**【补充问题解答】**

1.  **如果22个顺串在T2，12个在T3会发生什么？**
    
    *   总顺串数是 34。$22$ 和 $12$ 并非相邻的斐波那契数 ($F\_8=21, F\_7=13$)。
    *   **第一步合并**: 从`T2`和`T3`各取12个顺串合并到`T1`。
        *   `T1`：12个新顺串
        *   `T2`：剩下 $22-12=10$ 个顺串
        *   `T3`：变空
    *   **问题出现**: 现在`T1`有12个，`T2`有10个。这个组合 (12, 10) 破坏了斐波那契的完美结构，下一轮合并后无法继续保持这种模式，最终会导致某个阶段需要进行额外的拷贝操作，效率降低。
2.  **如果初始顺串数量不是斐波那契数怎么办？**
    
    *   这是一个非常实际的问题。解决方法是添加**虚拟的空顺串（dummy runs）**。
    *   例如，如果我们有25个顺串。下一个斐波那契数是 $F\_9=34$。我们需要 $34-25=9$ 个虚拟顺串。
    *   我们假装有34个顺串，并按斐波那契分割方式分配它们，即在 `T2` 上分配 $F\_8=21$ 个，`T3` 上分配 $F\_7=13$ 个。
    *   这21和13个顺串中，包含了真实的25个和虚拟的9个。在合并时，如果遇到虚拟顺串，就相当于输入流为空，直接将另一个输入流的数据复制过去即可。这虽然会增加一些逻辑，但依然避免了大规模的磁盘数据拷贝。

**【推广到 k-路归并】**

多相归并可以推广到使用 **k+1 个磁带进行 k-路归并**。这时，完美的分配比例不再是斐波那契数，而是**广义斐波那契数**。 其递推关系为： $F\_N^{(k)} = F\_{N-1}^{(k)} + F\_{N-2}^{(k)} + \\dots + F\_{N-k}^{(k)}$ 初始条件为：$F\_N^{(k)} = 0 \\quad (0 \\le N \\le k-2)$, $F\_{k-1}^{(k)} = 1$。 当 k=2 时，这就是标准的斐波那契数列。

### 6\. 优化策略三：缓冲区与并行操作 (Buffer Handling)

为了实现I/O和CPU的并行，我们需要精心设计**缓冲区（Buffers）**。

核心思想是**双缓冲（Double Buffering）**。对于每个输入流和输出流，我们都使用两个缓冲区。

*   当CPU正在处理**缓冲区A**中的数据时，I/O系统可以同时将下一块数据读入**缓冲区B**。
*   当CPU处理完A，它立刻转向处理B。与此同时，I/O系统可以将A中处理过的数据写回磁盘（如果是输出缓冲），或者将新的数据读入A。

这样，CPU和I/O设备可以像流水线一样协同工作，只要I/O速度能跟上CPU处理速度，I/O的等待时间就可以被大部分隐藏。

**【k-路归并的缓冲需求】** 为了实现完全的并行操作，对于一个k-路归并：

*   我们需要 **k 个输入流**，每个流配备双缓冲，共需 **2k 个输入缓冲区**。
*   我们需要 **1 个输出流**，配备双缓冲，共需 **2 个输出缓冲区**。

总共需要 $2k+2$ 个缓冲区。

**【例子】**

*   一个文件包含 **3250** 条记录。
*   内存一次最多能排序 **750** 条记录 ($M=750$)。
*   磁盘块（block）大小为 **250** 条记录。

1.  **生成初始顺串 (Pass 0)**:
    
    *   总顺串数 = $\\lceil 3250 / 750 \\rceil = 5$ 个。
    *   每个顺串的平均长度为750。
2.  **合并阶段 (假设 k=2，即2-路归并)**:
    
    *   内存大小为750条记录。
    *   块大小为250条记录。
    *   我们需要2个输入流和1个输出流。为了并行，使用双缓冲。
    *   **输入缓冲**: $2 \\times k = 2 \\times 2 = 4$ 个。
    *   **输出缓冲**: $2 \\times 1 = 2$ 个。
    *   总共需要 $4+2=6$ 个缓冲区。
    *   每个缓冲区大小是多少？假设我们平均分配内存：$750 / 6 = 125$ 条记录/缓冲区。
    *   **问题**: 缓冲区大小（125）小于磁盘块大小（250）！这意味着我们无法一次读入一个完整的块，I/O效率会很低。

**【权衡与最优 k 的选择】**

这个例子揭示了一个重要的权衡关系：

*   **增加 `k` (路数)**:
    *   优点：减少合并遍数，从而减少总的寻道次数和数据读写总量。
    *   缺点：需要的缓冲区数量（$2k+2$）增加，导致在**总内存固定**的情况下，每个缓冲区的**尺寸变小**。
*   **减小缓冲区尺寸**:
    *   缺点：如果缓冲区尺寸小于磁盘块大小，会造成低效I/O。即使大于块大小，更小的缓冲区也意味着更频繁的I/O请求，可能增加总的寻道时间和旋转延迟。

如下图所示，存在一个最优的 `k` 值。当 `k` 太小时，总遍数太多，I/O时间长。当 `k` 太大时，虽然遍数少了，但单次I/O效率变低，导致总I/O时间反而增加。

```
k (路数)  <---> # of input buffers <---> buffer size
    ^                                       |
    |                                       v
seek time <---> block size on disk <---> I/O efficiency
```

最优的 `k` 值取决于磁盘的具体参数（寻道时间、传输速率）、块大小以及可用的总内存大小。

### 7\. 优化策略四：生成更长的初始顺串 (Replacement Selection)

到目前为止，我们生成的初始顺串长度都受限于内存大小 $M$。有没有办法生成**平均长度大于 $M$ 的顺串**呢？答案是肯定的，这就是\*\*替换选择（Replacement Selection）\*\*算法。

该算法使用一个大小为 $M$ 的\*\*最小堆（Min-Heap）\*\*作为核心数据结构。

**算法流程:**

1.  **初始化**: 将输入文件的前 $M$ 个记录读入内存，并建立一个最小堆。
2.  **循环生成顺串**: a. 从堆顶取出最小元素，将其写入当前的输出顺串。 b. 从输入文件中读取下一个记录。 c. **比较**: 将新读入的记录与刚输出的记录进行比较。 \* 如果新记录 **大于或等于** 刚输出的记录，说明它可以属于当前这个递增的顺串。将它加入堆中。 \* 如果新记录 **小于** 刚输出的记录，它就不能加入当前顺串了（否则会破坏有序性）。我们将它放入堆中一个**逻辑上分开**的“冻结区”，在下一轮新顺串生成前，它不会参与堆的操作。 d. 重复 a-c，直到堆中所有“活跃”元素都被输出。
3.  **结束当前顺串**: 当主堆变空时，当前顺串结束。将堆中“冻结区”的所有元素“解冻”，形成新的堆，开始生成下一个顺串。

**【图解与示例】** 让我们用一个例子来模拟。假设 $M=3$，输入序列为 `81, 94, 11, 96, 12, 35, ...`

graph TD Start("**开始**  
Input: 81, 94, 11, ...") --> FillHeap("**初始化 (M=3)**  
读入前3个元素  
**Heap:** \[11, 81, 94\]  
**Run:** \[\]  
**Frozen:** \[\]") FillHeap --> Step1\_Out("**1\. 输出最小值: 11**") Step1\_Out --> Step1\_In("**读入新元素: 96**  
因为 96 >= 11 (上次输出)  
加入Heap") Step1\_In --> State1("**状态**  
**Heap:** \[81, 94, 96\]  
**Run:** \[11\]  
**Frozen:** \[\]") State1 --> Step2\_Out("**2\. 输出最小值: 81**") Step2\_Out --> Step2\_In("**读入新元素: 12**  
因为 12 < 81 (上次输出)  
**放入冻结区**") Step2\_In --> State2("**状态**  
**Heap:** \[94, 96\]  
**Run:** \[11, 81\]  
**Frozen:** \[12\]") State2 --> Step3\_Out("**3\. 输出最小值: 94**") Step3\_Out --> Step3\_In("**读入新元素: 35**  
因为 35 < 94 (上次输出)  
**放入冻结区**") Step3\_In --> State3("**状态**  
**Heap:** \[96\]  
**Run:** \[11, 81, 94\]  
**Frozen:** \[12, 35\]") State3 --> Final("... (继续此过程直到Heap变空, 第一个Run结束)")

**【性能分析】**

替换选择算法的神奇之处在于，在随机输入的情况下，它生成的顺串的**平均长度是 $2M$**！是传统方法的两倍。

*   **直观理解**: 堆就像一个“蓄水池”，它能容纳那些暂时还“不够大”的元素，让那些“足够大”的元素先输出，从而延长了当前顺串的生命周期。
*   **最佳情况**: 如果输入数据本身就是**几乎有序的（nearly sorted）**，替换选择可以生成一个极长的、甚至可能是一个覆盖整个文件的顺串！这使得它在处理这类数据时极为强大。

通过将初始顺串数量减半（平均而言），替换选择能显著减少后续合并所需的遍数，是外部排序中非常关键的一项优化。

#### **伪代码**

```
function ReplacementSelection(inputFile, outputTapes, M):
    heap = new MinHeap(M)
    frozen_area = new Array()
    
    // Phase 1: Fill memory and build heap
    for i from 1 to M:
        record = inputFile.read()
        if record is not EOF:
            heap.insert(record)

    current_output_tape = outputTapes.next()

    while not heap.isEmpty():
        // Main loop to generate one run
        while not heap.isEmpty():
            min_record = heap.extractMin()
            current_output_tape.write(min_record)
            last_output = min_record
            
            new_record = inputFile.read()
            if new_record is EOF:
                continue // Just empty the heap

            if new_record >= last_output:
                heap.insert(new_record)
            else:
                frozen_area.add(new_record)
        
        // Current run is finished. Start a new one with frozen elements.
        current_output_tape = outputTapes.next()
        for record in frozen_area:
            heap.insert(record)
        frozen_area.clear()

    // Handle any remaining elements in the last run
    while not heap.isEmpty():
         min_record = heap.extractMin()
         current_output_tape.write(min_record)
```

#### **C++ 代码示例 (核心逻辑)**

```cpp
#include <iostream>
#include <vector>
#include <queue>
#include <algorithm>
#include <functional> // For std::greater

// Simulate input stream
struct InputStream {
    std::vector<int> data;
    size_t pos = 0;
    bool eof() { return pos >= data.size(); }
    int read() { return eof() ? -1 : data[pos++]; }
};

// Simulate output stream (runs)
using Run = std::vector<int>;

void replacementSelection(InputStream& input, std::vector<Run>& output_runs, size_t M) {
    if (M == 0) return;

    std::priority_queue<int, std::vector<int>, std::greater<int>> heap;
    std::vector<int> frozen_elements;

    // Initial fill
    for (size_t i = 0; i < M && !input.eof(); ++i) {
        heap.push(input.read());
    }

    if (heap.empty()) return;

    while (true) {
        Run current_run;
        int last_output = -1; // Assuming non-negative data

        // Generate one run
        while (!heap.empty()) {
            int min_val = heap.top();
            heap.pop();
            current_run.push_back(min_val);
            last_output = min_val;

            if (!input.eof()) {
                int new_val = input.read();
                if (new_val >= last_output) {
                    heap.push(new_val);
                } else {
                    frozen_elements.push_back(new_val);
                }
            }
        }
        
        output_runs.push_back(current_run);

        // Check if we are done
        if (frozen_elements.empty()) {
            break;
        }

        // Prepare for the next run
        for (int val : frozen_elements) {
            heap.push(val);
        }
        frozen_elements.clear();
    }
}

int main() {
    InputStream input;
    input.data = {81, 94, 11, 96, 12, 35, 17, 99, 28, 58, 41, 75, 15};
    std::vector<Run> runs;
    size_t M = 3;

    replacementSelection(input, runs, M);

    std::cout << "Generated Runs (avg length should be ~2M=" << 2*M << "):\n";
    for (size_t i = 0; i < runs.size(); ++i) {
        std::cout << "Run " << i + 1 << " (length " << runs[i].size() << "): ";
        for (int val : runs[i]) {
            std::cout << val << " ";
        }
        std::cout << std::endl;
    }
    // Expected output from the example:
    // Run 1: 11 12 17 28 35 41 58 75 81 94 96 99
    // Run 2: 15
    // Average length is (12+1)/2 = 6.5, which is approx 2*M=6
    return 0;
}
```

### 8\. 优化策略五：最小化合并时间 (Huffman Tree)

前面的优化都假设所有初始顺串长度相等。但如果使用替换选择，或者数据本身特性导致生成的顺串**长度不一**，我们又该如何安排合并顺序呢？

**【问题】** 假设我们有4个顺串，长度分别为 2, 4, 5, 15。我们每次只能做2-路归并。如何安排合并顺序，才能使得总的合并代价（可以理解为读写记录的总数）最小？

*   **合并代价**: 合并两个长度为 $L\_1$ 和 $L\_2$ 的顺串，需要读取 $L\_1+L\_2$ 个记录，并写入 $L\_1+L\_2$ 个记录。总代价可以认为是 $L\_1+L\_2$。
*   **总合并时间**: 所有合并步骤的代价之和。

让我们尝试两种合并策略：

**策略A：**

1.  合并 (2, 4) -> 6。代价 = 6。剩下 (6, 5, 15)
2.  合并 (6, 5) -> 11。代价 = 11。剩下 (11, 15)
3.  合并 (11, 15) -> 26。代价 = 26。 总代价 = $6 + 11 + 26 = 43$。

**策略B：**

1.  合并 (15, 5) -> 20。代价 = 20。剩下 (20, 2, 4)
2.  合并 (20, 4) -> 24。代价 = 24。剩下 (24, 2)
3.  合并 (24, 2) -> 26。代价 = 26。 总代价 = $20 + 24 + 26 = 70$。

显然，策略A远优于策略B。这背后的原则是：**应该优先合并那些最短的顺串**。

这个原则和构造\*\*霍夫曼树（Huffman Tree）\*\*的算法完全一致！

我们可以把每个顺串看作一个叶子节点，顺串的长度看作是节点的权重。构造霍夫曼树的过程就是不断选择权重最小的两个节点合并，生成一个父节点，其权重为两个子节点权重之和。这个过程持续下去，直到所有节点合并成一个根节点。

**【应用霍夫曼树】** 对于长度为 2, 4, 5, 15 的顺串：

graph TD subgraph Huffman Tree Construction R26(26) --> R11(11) R26 --> L15\[15\] R11 --> R6(6) R11 --> L5\[5\] R6 --> L2\[2\] R6 --> L4\[4\] end

这个树的构造过程就是最优的合并策略：

1.  合并 2 和 4 (最小的两个) -> 得到长度为 6 的顺串。
2.  现在有 (6, 5, 15)，合并 6 和 5 (最小的两个) -> 得到长度为 11 的顺串。
3.  现在有 (11, 15)，合并它们 -> 得到最终长度为 26 的顺串。

这正是我们的策略A！

总的合并代价可以表示为该霍夫曼树的**带权外部路径长度（Weighted External Path Length）**。

*   一个叶节点的路径长度，是它到根节点的边数。
*   带权外部路径长度 = $\\sum (\\text{叶节点权重} \\times \\text{路径长度})$

计算一下：

*   顺串 2: 权重2，路径长度3 (2->6->11->26)
*   顺串 4: 权重4，路径长度3 (4->6->11->26)
*   顺串 5: 权重5，路径长度2 (5->11->26)
*   顺串 15: 权重15，路径长度1 (15->26)

总代价 = $2 \\times 3 + 4 \\times 3 + 5 \\times 2 + 15 \\times 1 = 6 + 12 + 10 + 15 = 43$。

因此，当初始顺串长度不等时，我们可以利用霍夫曼树来制定最优的合并计划，从而最小化总的合并时间。

**总合并时间 = $O(\\text{带权外部路径长度})$**