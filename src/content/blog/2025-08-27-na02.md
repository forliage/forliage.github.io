---
title: "数值分析02:单变量非线性方程求解"
description: ""
pubDate: "2025-08-27"
heroImage: ""
---

# 数值分析02:单变量非线性方程求解

### **引言：从线性到非线性**

在上一讲中，我们深入探讨了数值计算的基石：误差的来源、度量和传播。我们认识到，由于计算机的有限性，近似和误差是不可避免的。一个好的数值算法，其核心目标就是在保证效率的同时，有效地控制误差的增长。

今天，我们将应用这些基础知识，来解决一个在科学与工程领域中极为常见的问题：**求解非线性方程 (Solving Nonlinear Equations)**。

我们在线性代数中学习过如何求解线性方程组 $A\\mathbf{x} = \\mathbf{b}$。线性问题之所以“简单”，是因为它们具有叠加原理等优良性质，存在着如高斯消元法这样直接、普适的解法。

然而，现实世界充满了非线性。例如：

*   一个物体在空气中下落，其运动方程会因为空气阻力而变得非线性。
*   电路中晶体管的伏安特性是非线性的。
*   在金融学中，计算债券的到期收益率（YTM）需要求解一个高次多项式方程。
*   甚至简单的几何问题，如计算 $\\cos(x) = x$ 的解，也是一个非线性问题。

这类问题都可以抽象为寻找一个函数 $f(x)$ 的**根 (Root)**，即求解方程 $f(x) = 0$。

与线性问题不同，非线性方程求解**不存在通用的直接解法**。除了极少数特例外（如一元二次方程），我们无法写出根的解析表达式。因此，我们必须依赖**迭代法 (Iterative Methods)**。

迭代法的思想非常直观：

1.  从一个对根的初始猜测 $p\_0$ 开始。
2.  通过一个特定的迭代规则，生成一个序列 $p\_1, p\_2, p\_3, \\dots$。
3.  如果算法设计得好，这个序列会越来越接近真实的根 $p$，即 $\\lim\_{n \\to \\infty} p\_n = p$。

今天，我们将学习几种最基本也是最重要的迭代求根算法：

1.  **二分法 (Bisection Method):** 最简单、最可靠，但收敛缓慢。
2.  **不动点迭代法 (Fixed-Point Iteration):** 一个更通用的框架，为后续方法提供理论基础。
3.  **牛顿法 (Newton's Method):** 强大、收敛快，但对初始值有要求。
4.  （拓展内容）**割线法 (Secant Method):** 牛顿法的一个实用变种。

对于每一种方法，我们不仅要学习其**如何操作**，更要深入分析其**为何有效**，以及它的**收敛速度**和**适用范围**。

### **第一部分：二分法**

#### **2.1 理论基础：介值定理**

二分法的理论根基是微积分中一个非常直观的定理。

**定理 (介值定理 - Intermediate Value Theorem):** 如果函数 $f(x)$ 在闭区间 $\[a, b\]$ 上连续，并且 $K$ 是介于 $f(a)$ 和 $f(b)$ 之间的任意一个数，那么在开区间 $(a, b)$ 内至少存在一个点 $p$，使得 $f(p) = K$。

对于求根问题 $f(x)=0$，我们可以得到一个更具体的推论：

**推论：** 如果 $f(x)$ 在 $\[a, b\]$ 上连续，且 $f(a)$ 和 $f(b)$ **异号**（即 $f(a) \\cdot f(b) < 0$），那么在 $(a, b)$ 内至少存在一个根。

这个推论为我们提供了一个**保证**：只要我们能找到这样一个区间，根就一定“藏”在里面。

#### **2.2 算法思想与步骤**

二分法的思想就是利用这个保证，不断地将包含根的区间**对半分割**，从而逼近根。

**算法步骤：** 假设我们已经找到了一个区间 $\[a\_1, b\_1\]$，满足 $f(a\_1) \\cdot f(b\_1) < 0$。

1.  **计算中点：** $p\_1 = a\_1 + \\frac{b\_1 - a\_1}{2} = \\frac{a\_1 + b\_1}{2}$。这个 $p\_1$ 是我们对根的第一次近似。
2.  **检查中点函数值：** 计算 $f(p\_1)$。
3.  **更新区间：**
    *   如果 $f(p\_1) = 0$，恭喜你，找到了根，算法结束。
    *   如果 $f(p\_1)$ 与 $f(a\_1)$ 同号（即 $f(a\_1) \\cdot f(p\_1) > 0$），说明根不在 $\[a\_1, p\_1\]$ 这一半，而在 $\[p\_1, b\_1\]$ 中。于是我们令新的区间为 $\[a\_2, b\_2\] = \[p\_1, b\_1\]$。
    *   如果 $f(p\_1)$ 与 $f(b\_1)$ 同号（即 $f(p\_1) \\cdot f(b\_1) > 0$），说明根在 $\[a\_1, p\_1\]$ 中。于是我们令新的区间为 $\[a\_2, b\_2\] = \[a\_1, p\_1\]$。
4.  **重复：** 回到第1步，对新的、更小的区间 $\[a\_2, b\_2\]$ 进行同样的操作，得到 $p\_2$ 和 $\[a\_3, b\_3\]$，以此类推。

每一次迭代，包含根的区间的长度都**减半**。

#### **2.3 停止准则 (Stopping Criteria)**

迭代法必须有停止的条件。**我们应该在什么时候停止？** (Discussion 4)

假设我们已经进行了 $N$ 次迭代，得到了近似根 $p\_N$。

1.  **绝对误差：** $|p\_N - p\_{N-1}| < \\epsilon$。这表示相邻两次迭代的结果足够接近。
2.  **相对误差：** $\\frac{|p\_N - p\_{N-1}|}{|p\_N|} < \\epsilon$ (当 $p\_N \\neq 0$)。这在根的量级很大或很小时更有意义。
3.  **残差 (Residual)：** $|f(p\_N)| < \\epsilon$。这表示我们找到的点足够接近于让函数值为零。

**警告：** 这三种准则都有其缺陷！

*   对于准则1和2，存在一些发散的序列，其相邻项之差也趋于0（例如 $p\_N = \\sum\\limits\_{k=1}^N \\frac{1}{k}$）。
*   对于准则3，如果函数在根附近非常平坦（即 $f'(p)$ 接近0），那么即使 $|f(p\_N)|$ 很小，$p\_N$ 也可能离真根 $p$ 很远。反之，如果函数非常陡峭，即使 $|f(p\_N)|$ 比较大，$p\_N$ 也可能已经非常接近真根了。

**二分法的独特优势：** 对于二分法，我们有一个**最可靠的停止准则**：**区间长度**。 经过 $n$ 次迭代后，根所在的区间 $\[a\_n, b\_n\]$ 的长度为： $$|b\_n - a\_n| = \\frac{|b\_1 - a\_1|}{2^{n-1}}$$ 在第 $n$ 次迭代中，我们计算出的中点 $p\_n$ 与真实根 $p$ 之间的误差满足： $$|p\_n - p| \\le \\frac{|b\_n - a\_n|}{2} = \\frac{|b\_1 - a\_1|}{2^n}$$

这个不等式非常强大：

*   它给出了一个**严格的误差上界**。
*   它**与函数 $f(x)$ 的具体形态无关**，只与初始区间长度和迭代次数有关。
*   它允许我们在**算法开始前就预测出需要迭代多少次**才能达到指定的精度。

例如，若要求绝对误差小于 $\\epsilon$，我们只需解不等式： $$\\frac{b\_1 - a\_1}{2^n} < \\epsilon \\implies 2^n > \\frac{b\_1 - a\_1}{\\epsilon} \\implies n > \\log\_2\\left(\\frac{b\_1 - a\_1}{\\epsilon}\\right)$$

#### **2.4 算法伪代码与分析**

**Algorithm: Bisection** **Input:** function `f`, endpoints `a`, `b`, tolerance `TOL`, max iterations `N_max` **Precondition:** `f` is continuous on `[a, b]` and `f(a) * f(b) < 0`.

```
1.  `i = 1`
2.  `FA = f(a)`
3.  **WHILE** `i <= N_max`:
4.      `p = a + (b - a) / 2`  // *使用这种方式计算中点，可以避免 a+b 溢出*
5.      `FP = f(p)`
6.      **IF** `FP == 0` **OR** `(b - a) / 2 < TOL`:
7.          **OUTPUT** `p`; **STOP** (Success)
8.      `i = i + 1`
9.      **IF** `FA * FP > 0`:
10.         `a = p`
11.         `FA = FP`
12.     **ELSE**:
13.         `b = p`
14. **END WHILE**
15. **OUTPUT** "Method failed after N_max iterations"; **STOP** (Failure)
```

**优点：**

1.  **简单直观**。
2.  **永远收敛 (Always Convergent):** 只要初始区间满足条件，二分法保证能找到一个根。这是它最强大的优点，使其成为一个可靠的“保底”方法。

**缺点：**

1.  **收敛缓慢：** 每次迭代，误差大约只减少一半。我们称之为**线性收敛 (Linear Convergence)**，其收敛速度是固定的，无法加速。
2.  **可能丢弃更好的近似：** 算法只关心区间端点和中点，可能会错过一个非常接近根的迭代点。
3.  **无法处理多重根或偶次根：** 如果根是偶数重根（如 $f(x)=x^2$ 的根 $p=0$），函数在根的两侧不变号，二分法的前提条件无法满足。
4.  **无法找到复数根**。

### **第二部分：不动点迭代**

二分法虽然可靠，但收敛速度慢。为了寻找更快的算法，我们需要一个更具一般性的理论框架，这就是**不动点迭代法**。

#### **2.5 不动点与方程求根的等价性**

**定义 (不动点 - Fixed Point):** 对于一个函数 $g(x)$，如果一个点 $p$ 满足 $p = g(p)$，则称 $p$ 是函数 $g(x)$ 的一个不动点。

从几何上看，函数 $y=g(x)$ 的不动点就是其图像与直线 $y=x$ 的交点的横坐标。

**核心思想：** 任何求根问题 $f(x)=0$ 都可以通过代数变形，转化为一个等价的**不动点问题 $x=g(x)$**。

**示例：** 求解 $f(x) = x^3 + 4x^2 - 10 = 0$。 我们可以构造出多种不同的 $g(x)$： a) $x = x - (x^3 + 4x^2 - 10) \\implies g\_1(x) = x - x^3 - 4x^2 + 10$ b) $4x^2 = 10 - x^3 \\implies x = \\pm \\frac{1}{2}\\sqrt{10-x^3} \\implies g\_2(x) = \\frac{1}{2}\\sqrt{10-x^3}$ c) $x^2(x+4) = 10 \\implies x = \\sqrt{\\frac{10}{x+4}} \\implies g\_3(x) = \\sqrt{\\frac{10}{x+4}}$ d) ... 还有很多种。

求 $f(x)=0$ 的根就等价于求这些 $g(x)$ 的不动点。

#### **2.6 不动点迭代算法**

一旦我们将问题转化为 $x=g(x)$，就可以构造一个简单的迭代格式：

**Algorithm: Fixed-Point Iteration**

1.  选择一个初始猜测值 $p\_0$。
2.  生成序列：$p\_n = g(p\_{n-1})$ for $n=1, 2, 3, \\dots$。

如果这个序列 ${p\_n}$ 收敛于某个值 $p$，并且 $g(x)$ 是连续的，那么： $$p = \\lim\_{n \\to \\infty} p\_n = \\lim\_{n \\to \\infty} g(p\_{n-1}) = g(\\lim\_{n \\to \\infty} p\_{n-1}) = g(p)$$ 这说明，序列的极限 $p$ 必然是 $g(x)$ 的一个不动点，也就是 $f(x)=0$ 的一个根。

**关键问题：** “Oh yeah? Who tells you that the method is convergent?” 对于一个给定的 $g(x)$，这个迭代过程**一定会收敛吗？**

#### **2.7 收敛性分析：不动点定理**

**收敛与发散的关键区别是什么？** 观察收敛的图像，在不动点附近，函数 $y=g(x)$ 的曲线都比直线 $y=x$ **更平缓**。这意味着在不动点附近，导数 $|g'(p)|$ 的绝对值小于1。而发散的图像中，曲线比 $y=x$ **更陡峭**，即 $|g'(p)| > 1$。

这引出了不动点迭代的收敛性核心定理。

**定理 (不动点定理 - Fixed-Point Theorem):** 假设函数 $g(x)$ 满足以下条件：

1.  $g(x)$ 在闭区间 $\[a, b\]$ 上连续，且对于任意 $x \\in \[a, b\]$，都有 $g(x) \\in \[a, b\]$。（这个条件保证了迭代过程不会“跑出”这个区间）
2.  $g(x)$ 在开区间 $(a, b)$ 上可导，并且存在一个常数 $k$ 满足 $0 < k < 1$，使得对于所有 $x \\in (a, b)$，都有 $|g'(x)| \\le k$。

**结论：** a) 在 $\[a, b\]$ 中， $g(x)$ 有**唯一**的不动点 $p$。 b) 对于**任意**的初始值 $p\_0 \\in \[a, b\]$，由 $p\_n = g(p\_{n-1})$ 生成的序列都将**收敛**于不动点 $p$。

**证明思路 (简述):**

*   **存在性:** 定义 $h(x) = g(x) - x$。由条件1， $h(a) = g(a) - a \\ge 0$ 且 $h(b) = g(b) - b \\le 0$。根据介值定理，必存在 $p \\in \[a, b\]$ 使得 $h(p)=0$，即 $g(p)=p$。
*   **唯一性:** (反证法) 假设存在两个不同的不动点 $p$ 和 $q$。根据中值定理，存在 $\\xi$ 介于 $p, q$ 之间，使得 $g'(\\xi) = \\frac{g(p)-g(q)}{p-q} = \\frac{p-q}{p-q} = 1$。但这与条件2中 $|g'(\\xi)| \\le k < 1$ 矛盾。所以不动点唯一。
*   **收敛性:** $$|p\_n - p| = |g(p\_{n-1}) - g(p)|$$ 根据中值定理，存在 $\\xi\_n$ 介于 $p\_{n-1}$ 和 $p$ 之间，使得： $$|p\_n - p| = |g'(\\xi\_n)| \\cdot |p\_{n-1} - p|$$ 由于 $|g'(\\xi\_n)| \\le k$，我们得到： $$|p\_n - p| \\le k \\cdot |p\_{n-1} - p|$$ 反复应用此不等式： $$|p\_n - p| \\le k \\cdot |p\_{n-1} - p| \\le k^2 \\cdot |p\_{n-2} - p| \\le \\dots \\le k^n \\cdot |p\_0 - p|$$ 因为 $0 < k < 1$，当 $n \\to \\infty$ 时，$k^n \\to 0$，所以 $\\lim\_{n \\to \\infty} |p\_n - p| = 0$。证毕。

#### **2.8 误差界与收敛速度**

从证明中我们得到了两个重要的推论（Corollary）：

1.  **误差上界:** $|p\_n - p| \\le k^n |p\_0 - p|$
2.  **可计算的误差界:** $|p\_n - p| \\le \\frac{k^n}{1-k}|p\_1 - p\_0|$

**收敛速度:** 我们称满足 $|p\_{n+1}-p| \\le C|p\_n-p|^\\alpha$ 的收敛为 **$\\alpha$ 阶收敛**。 不动点迭代的误差关系 $|p\_n - p| \\le k \\cdot |p\_{n-1} - p|$ 表明，它通常是**一阶收敛**或**线性收敛**。 常数 $k$ (即 $|g'(p)|$ 的上界) 越小，收敛得越快。当 $k$ 接近1时，收敛会非常缓慢。当 $k>1$ 时，算法发散。

**案例分析 (回到 $x^3+4x^2-10=0$):** 让我们来检验之前构造的几个 $g(x)$，根在区间 $\[1, 2\]$ 内，真实根 $p \\approx 1.365$。

*   $g\_3(x) = \\sqrt{10/(x+4)}$。 $g\_3'(x) = -\\frac{1}{2} \\left(\\frac{10}{x+4}\\right)^{-1/2} \\frac{10}{(x+4)^2} = -\\frac{\\sqrt{10}}{2(x+4)^{3/2}}$ 在区间 $\[1,2\]$ 内，$|g\_3'(x)|$ 的最大值在 $x=1$ 处取得：$|g\_3'(1)| = \\frac{\\sqrt{10}}{2(5)^{3/2}} \\approx 0.14 < 1$。**因此，这个迭代格式是收敛的。**
*   $g\_1(x) = x - x^3 - 4x^2 + 10$。 $g\_1'(x) = 1 - 3x^2 - 8x$。 在根 $p \\approx 1.365$ 附近，$|g\_1'(p)| \\approx |1 - 3(1.365)^2 - 8(1.365)| \\approx |-15.4| \\gg 1$。**因此，这个迭代格式是发散的。**

这解释了为什么对于同一个求根问题，选择不同的不动点形式会导致截然不同的结果。**成功的关键是构造一个在根附近导数绝对值小于1的迭代函数 $g(x)$。**

### **第三部分：牛顿法**

不动点迭代法为我们提供了理论基础，但如何系统性地构造一个收敛快（即 $|g'(p)|$ 小）的 $g(x)$ 呢？牛顿法给出了一个绝妙的答案。

#### **2.9 思想来源：泰勒展开与线性化**

牛顿法的核心思想是**线性化 (Linearization)**。在根的一个邻近点 $p\_0$ 附近，用函数 $f(x)$ 在该点的**切线**来近似函数本身。

将 $f(x)$ 在 $p\_0$ 处进行一阶泰勒展开： $$f(x) \\approx f(p\_0) + f'(p\_0)(x - p\_0)$$

我们要求解 $f(x)=0$，现在我们转而求解这个线性近似方程： $$f(p\_0) + f'(p\_0)(x - p\_0) = 0$$ 解出 $x$: $$x = p\_0 - \\frac{f(p\_0)}{f'(p\_0)}$$

这个解 $x$ 应该比 $p\_0$ 更接近真实的根。我们将其作为下一次迭代的值 $p\_1$。

**牛顿法迭代公式 (Newton-Raphson Method):** $$p\_n = p\_{n-1} - \\frac{f(p\_{n-1})}{f'(p\_{n-1})}, \\text{for } n=1, 2, 3, \\dots$$

**几何解释：** 从点 $(p\_n, f(p\_n))$ 出发，沿着函数曲线的切线走，直到与 x 轴相交，交点的横坐标就是 $p\_{n+1}$。

#### **2.10 收敛性分析**

我们可以将牛顿法看作是一种特殊的不动点迭代，其迭代函数为： $$g(x) = x - \\frac{f(x)}{f'(x)}$$

我们来分析它的导数 $g'(x)$： $$g'(x) = 1 - \\frac{f'(x)f'(x) - f(x)f''(x)}{\[f'(x)\]^2} = \\frac{f(x)f''(x)}{\[f'(x)\]^2}$$

现在，我们考察在真根 $p$ 处的情况（此时 $f(p)=0$）： $$g'(p) = \\frac{f(p)f''(p)}{\[f'(p)\]^2} = \\frac{0 \\cdot f''(p)}{\[f'(p)\]^2} = 0$$

**这是一个惊人的结果！** 根据不动点定理，收敛速度取决于 $|g'(p)|$ 的大小。$|g'(p)|=0$ 是我们能得到的**最好情况**！这意味着，只要初始猜测 $p\_0$ 足够接近根 $p$（使得 $|g'(x)|$ 在这个邻域内小于1），牛顿法就会收敛，并且**收敛得非常快**。

**收敛阶 (Order of Convergence):** 可以证明（通过更高阶的泰勒展开），如果 $f'(p) \\neq 0$（即 $p$ 是一个**单根**），牛顿法是**二阶收敛 (Quadratic Convergence)** 的。 $$|p\_{n+1} - p| \\approx C |p\_n - p|^2$$ 这意味着，每一次迭代，有效数字的位数大约会**翻倍**！

**示例：** 假设 $C=1$，误差序列可能是 $0.1 \\to 0.01 \\to 0.0001 \\to 0.00000001 \\to \\dots$。

#### **2.11 牛顿法的缺陷**

尽管牛顿法收敛速度极快，但它并非完美：

1.  **需要导数：** 必须能够计算并编程实现 $f'(x)$。对于复杂的函数，这可能很困难或代价高昂。
2.  **对初始值敏感：** 如果初始值 $p\_0$ 离真根太远，迭代序列可能发散，或收敛到另一个根。如果 $f'(p\_n)$ 恰好为0或接近0，算法会失败或产生巨大误差。
3.  **对于重根收敛退化：** 如果 $p$ 是一个 $m$ 重根（即 $f(p)=f'(p)=\\dots=f^{(m-1)}(p)=0$ 但 $f^{(m)}(p)\\neq 0$），则 $g'(p) = 1 - 1/m \\neq 0$。此时牛顿法会退化为**线性收敛**。

### **第四部分：拓展**

#### **2.12 研究课题 2：牛顿法求解非线性方程组**

将牛顿法推广到多维情况，求解方程组： $$\\begin{cases} f\_1(x\_1, x\_2, \\dots, x\_n) = 0 \\\\ f\_2(x\_1, x\_2, \\dots, x\_n) = 0 \\\\ \\vdots \\\\ f\_n(x\_1, x\_2, \\dots, x\_n) = 0 \\end{cases}$$

可以写成向量形式 $\\mathbf{F}(\\mathbf{x}) = \\mathbf{0}$。 一维情况下的导数 $f'(x)$ 对应于多维情况下的**雅可比矩阵 (Jacobian Matrix)** $J(\\mathbf{x})$，其中 $J\_{ij} = \\frac{\\partial f\_i}{\\partial x\_j}$。 一维的除法 $1/f'(x)$ 对应于多维的**矩阵求逆** $J^{-1}(\\mathbf{x})$。

**多维牛顿法迭代公式：** $$\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} - \[J(\\mathbf{x}^{(k)})\]^{-1} \\mathbf{F}(\\mathbf{x}^{(k)})$$

在实际计算中，我们不直接求逆，而是求解一个线性方程组： $$J(\\mathbf{x}^{(k)}) \\Delta\\mathbf{x}^{(k)} = -\\mathbf{F}(\\mathbf{x}^{(k)})$$ 然后更新： $$\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + \\Delta\\mathbf{x}^{(k)}$$

这是求解大型非线性系统（如在计算流体力学、结构分析中）的核心算法之一。

#### **2.13 研究课题 3：割线法 (Secant Method)**

牛顿法最大的不便是需要计算导数。割线法通过一个巧妙的近似来规避这个问题。

回顾导数的定义：$f'(x) = \\lim\_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$。 在迭代过程中，我们可以用上两点的函数值来近似导数： $$f'(p\_{n-1}) \\approx \\frac{f(p\_{n-1}) - f(p\_{n-2})}{p\_{n-1} - p\_{n-2}}$$

将这个近似代入牛顿法公式，得到**割线法迭代公式：** $$p\_n = p\_{n-1} - f(p\_{n-1}) \\frac{p\_{n-1} - p\_{n-2}}{f(p\_{n-1}) - f(p\_{n-2})}$$

**优点：**

*   **无需导数：** 这是它相对于牛顿法最大的优势。
*   **每次迭代只需计算一次函数值：** 牛顿法需要计算 $f(x)$ 和 $f'(x)$。

**缺点：**

*   **需要两个初始点** $p\_0$ 和 $p\_1$ 来启动。
*   **收敛速度稍慢：** 割线法的收敛阶约为 $\\alpha \\approx 1.618$ (黄金分割数)，介于线性收敛和二阶收敛之间，被称为**超线性收敛 (Superlinear Convergence)**。它仍然比线性收敛快得多。

在实际应用中，当导数难以获得时，割线法及其变种（如Broyden法）是非常受欢迎的选择。

### **课程总结**

**本讲核心方法对比：**

方法

核心思想

收敛速度

可靠性

成本 (每次迭代)

**二分法**

区间对分

线性 ($1$)

极高

1次函数求值

**不动点迭代**

$x=g(x)$

线性 ($1$)

依赖于$g'$

1次g求值

**牛顿法**

切线近似

二阶 ($2$)

依赖初始值

1次f, 1次f'求值

**割线法**

割线近似导数

超线性 ($\\approx 1.618$)

依赖初始值

1次函数求值

**Lab 02 作业预览：多项式求根** **任务：** 编写一个程序，找到给定区间内一个多项式 $p(x) = a\_n x^n + \\dots + a\_1 x + a\_0$ 的根。

**思考与实现建议：**

1.  **选择哪种方法？**
    *   **二分法** 是最安全的选择，只要你能找到一个包含根的初始区间。
    *   **牛顿法** 收敛更快。对于多项式，求导非常容易。$p'(x) = na\_n x^{n-1} + \\dots + a\_1$。
    *   **混合策略 (Hybrid Method)** 是最专业的做法：先用几步二分法，将根“框”在一个很小的区间内，确保初始值足够好，然后再切换到牛顿法进行快速收敛。
2.  **多项式求值：** 在你的代码中，记得使用我们在第一讲讨论过的**秦九韶算法 (Horner's Method)** 来高效、稳定地计算 $p(x)$ 和 $p'(x)$ 的值。
3.  **寻找初始区间：** 如何为二分法找到一个有效的初始区间 $\[a,b\]$？可以对给定的区间进行扫描，寻找函数值变号的点。

##### **1\. 问题重述与分析**

**目标：** 编写一个程序，输入一个 $n$ 次多项式 $p(x) = a\_n x^n + \\dots + a\_1 x + a\_0$ 的系数和一个区间 $\[a, b\]$，要求找到该区间内的一个根。

**核心挑战：**

1.  **算法选择：** 我们学习了二分法、牛顿法、割线法等。哪一种最适合这个问题？
2.  **鲁棒性 (Robustness):** 程序需要处理各种可能的情况，例如区间内没有根、有多个根、根是重根等，并且不能轻易因为不好的输入而崩溃。
3.  **效率与精度：** 算法应在合理的时间内（1秒）收敛到足够精确的解。
4.  **实现细节：** 如何高效且数值稳定地计算多项式及其导数的值？

##### **2\. 算法选择与权衡**

这是一个典型的“没有最好，只有最合适”的场景。

*   **纯二分法 (Pure Bisection Method):**
    
    *   **优点：** 绝对可靠。只要能在给定区间 $\[a, b\]$ 内找到一个子区间 $\[a\_k, b\_k\]$ 满足 $p(a\_k) \\cdot p(b\_k) < 0$，就一定能找到根。
    *   **缺点：** 收敛速度慢（线性收敛）。对于要求高精度的情况，迭代次数可能较多。
*   **纯牛顿法 (Pure Newton's Method):**
    
    *   **优点：** 收敛速度极快（二阶收敛），尤其是在接近单根时。多项式的导数很容易计算。
    *   **缺点：** 对初始值非常敏感。如果从区间 $\[a, b\]$ 中任意选择一个点作为初始值，很可能导致迭代发散或收敛到区间外的根。在导数值接近零的点（驻点）附近表现很差。
*   **纯割线法 (Pure Secant Method):**
    
    *   **优点：** 收敛速度快（超线性），且不需要计算导数。
    *   **缺点：** 与牛顿法类似，对初始值敏感。需要两个初始点。

**结论：** 单独使用任何一种方法都有明显的短板。纯牛顿法/割线法太“冒险”，纯二分法太“保守”。

**最佳策略：混合算法 (Hybrid Algorithm)**

这是数值计算中一种非常常见的、兼具鲁棒性和效率的策略。其思想是：

1.  **安全启动阶段 (Bracketing Phase):** 使用可靠但缓慢的方法（如二分法）来确保我们始终将根“包围”在一个不断缩小的区间内。
2.  **快速收敛阶段 (Acceleration Phase):** 当区间足够小，可以确信当前近似值已经进入牛顿法（或割线法）的“收敛盆地”时，切换到快速算法进行最后的精确打击。

我们将设计一个**结合了二分法和牛顿法的混合求解器**。这种方法通常被称为 **Newton-Bisection Method** 或类似的名称。

##### **3\. 核心实现细节：秦九韶算法 (Horner's Method)**

在第一讲中我们已经学过，评估多项式 $p(x)$ 最有效和数值稳定的方法是秦九韶算法。 $p(x) = a\_0 + x(a\_1 + x(a\_2 + \\dots + x(a\_{n-1} + xa\_n)\\dots))$

一个非常巧妙的扩展是，秦九韶算法可以**同时**计算出 $p(x)$ 和 $p'(x)$ 的值，而几乎不需要额外的计算量。

**算法：秦九韶法同时计算 p(x) 和 p'(x)** **Input:** 多项式系数数组 `coeffs` ($a\_n, a\_{n-1}, \\dots, a\_0$)，求值点 `x`。

```
1.  `n = degree of polynomial`
2.  `y = coeffs[n]` (初始化 $p(x)$ 的值)
3.  `z = coeffs[n]` (初始化 $p'(x)$ 的值，但这是不完全的)
4.  **FOR** `i` FROM `n-1` DOWNTO `1`:
5.      `y = x * y + coeffs[i]`
6.      `z = x * z + y`
7.  `y = x * y + coeffs[0]`
8.  **RETURN** `(y, z)`  // y is p(x), z is p'(x)
```

_(注：这个求导的技巧基于对秦九韶算法的综合除法解释，可以证明其正确性。)_ 这个工具将是我们的求解器中计算函数和导数值的核心引擎。

##### **4\. 最终算法设计：Newton-Bisection 混合求解器**

**Input:** 系数 `coeffs`, 区间 `[a, b]`, 容差 `TOL`, 最大迭代次数 `N_max`

1.  **初始化与预检查：**
    
    *   计算 `pa = p(a)` 和 `pb = p(b)` (使用秦九韶法)。
    *   **IF** `pa * pb > 0`:
        *   这表示在区间端点函数值同号。**可能没有根，也可能是有偶数个根**。
        *   **简单策略：** 报告“无法保证区间内有根”并退出。
        *   **高级策略：** 将区间 $\[a,b\]$ 细分成多个子区间，逐个检查是否存在变号。如果找到了变号的子区间，则在该子区间上继续。
    *   **IF** `abs(pa) < TOL`: **RETURN** `a`。
    *   **IF** `abs(pb) < TOL`: **RETURN** `b`。
    *   如果 `pa > pb`，交换 `a` 和 `b`（以及`pa`和`pb`），确保 `a` 始终是函数值为负的一端，`b` 是函数值为正的一端。这可以简化后续逻辑。
    *   初始化当前点 `x = (a+b)/2`， 上一步的点 `dx_old = abs(b-a)`。
2.  **主迭代循环：** **FOR** `i` FROM `1` TO `N_max`: a. 计算 `p(x)` 和 `p'(x)` (使用秦九韶法)。 b. **牛顿步长计算：** `dx_newton = -p(x) / p'(x)` c. **二分步长计算：** `dx_bisection = (b - x)` d. **决策：应该走哪一步？**
    
    *   **条件1 (界内检查):** 牛顿步长是否会将我们带出当前的安全区间 `[a, b]`？ `is_newton_safe = (x + dx_newton > a) AND (x + dx_newton < b)`
    *   **条件2 (收敛加速检查):** 牛顿步长是否比上一步的步长小得多（表明正在快速收敛）？ `is_newton_fast = abs(dx_newton) < 0.5 * abs(dx_old)`
    
    ```
        * **IF** `is_newton_safe` AND `is_newton_fast`:
            // **接受牛顿步**
            `dx_old = dx_newton`
            `x = x + dx_newton`
        * **ELSE**:
            // **拒绝牛顿步，执行二分步**
            `dx_old = dx_bisection`
            `x = x + dx_bisection`
    
    e.  **收敛检查：**
        **IF** `abs(dx_old) < TOL`: **RETURN** `x` (Success)。
    
    f.  **更新安全区间 [a, b]** (这是二分法的核心，确保鲁棒性)：
        * 计算新的 `p_at_x = p(x)`。
        * **IF** `p_at_x < 0`:
            `a = x`
        * **ELSE**:
            `b = x`
    ```
    
3.  **循环结束：** **RETURN** "未能收敛" (Failure)。
    

##### **5\. 伪代码实现**

```
FUNCTION find_poly_root(coeffs, a, b, TOL=1e-10, N_max=100):
    // Helper function to evaluate p(x) and p'(x) using Horner's method
    FUNCTION horner(coeffs, x):
        n = len(coeffs) - 1
        y = coeffs[n]
        z = coeffs[n]
        FOR i FROM n-1 DOWNTO 1:
            y = x * y + coeffs[i]
            z = x * z + y
        y = x * y + coeffs[0]
        RETURN (y, z) // (p(x), p'(x))

    pa, _ = horner(coeffs, a)
    pb, _ = horner(coeffs, b)

    IF pa * pb > 0:
        RAISE ERROR "Root is not bracketed in [a, b]"
    
    IF abs(pa) < TOL: RETURN a
    IF abs(pb) < TOL: RETURN b

    // Ensure a is the lower bound where p(a) < 0
    IF pa > 0:
        swap(a, b)

    x = 0.5 * (a + b)
    dx_old = abs(b - a)

    FOR i FROM 1 TO N_max:
        px, p_prime_x = horner(coeffs, x)

        // Check for convergence on residual or step size
        IF abs(px) < TOL OR dx_old < TOL:
            RETURN x

        // Candidate Newton step
        dx_newton = 0
        IF abs(p_prime_x) > 1e-12: // Avoid division by zero
            dx_newton = -px / p_prime_x
        
        // Decide whether to take Newton step or Bisection step
        // Newton step must be within the bracket and smaller than half the previous step
        IF (x + dx_newton > a) AND (x + dx_newton < b) AND (abs(dx_newton) < 0.5 * dx_old):
            // Accept Newton step
            dx = dx_newton
        ELSE:
            // Fallback to Bisection
            dx = 0.5 * (b - a)
            x = a + dx // Move x to the midpoint
        
        // Update point and track step size
        IF dx != dx_newton: // if we took a bisection step
            x = a + dx 
        else: // we took a newton step
            x = x + dx
        
        dx_old = abs(dx)

        // Update the bracket [a, b]
        px, _ = horner(coeffs, x)
        IF px < 0:
            a = x
        ELSE:
            b = x
            
    RAISE ERROR "Failed to converge within max iterations"
```

_(注：上述伪代码逻辑做了微调，使其更清晰。核心思想是优先考虑牛顿法，当牛顿法不安全或不高效时，立即退回至更保守的二分法。并且，无论走哪一步，都用二分法的思想更新安全区间。)_

##### **6\. 总结**

这个实验的解决方案向学生们传达了几个关键的数值分析实践原则：

1.  **没有银弹：** 理论上最优美的算法（牛顿法）在实践中可能很脆弱。最可靠的算法（二分法）可能效率不高。
2.  **组合的力量：** 将不同算法的优点结合起来，构建混合策略，是开发强大数值软件的常用技巧。
3.  **底层效率：** 算法的整体性能依赖于其核心计算（如多项式求值）的效率。选择像秦九韶法这样的最优子程序至关重要。
4.  **防御性编程：** 必须预见到并处理各种边缘情况，如端点就是根、区间内无根、导数为零等，以确保程序的鲁棒性。