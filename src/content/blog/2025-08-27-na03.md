---
title: "数值分析03:迭代收敛性分析与线性方程组求解"
description: ""
pubDate: "2025-08-27"
heroImage: ""
---

# 数值分析03:迭代收敛性分析与线性方程组求解

### **引言：从“能不能解”到“解得好不好”**

在上一讲中，我们学习了求解非线性方程的几种核心迭代算法：可靠的二分法、通用的不动点迭代以及高效的牛顿法。我们已经掌握了这些算法的“操作手册”。

然而，作为数值分析的探索者，我们不能仅仅满足于找到一个“能用”的算法。我们必须问自己更深层次的问题：

1.  **“多快？”**：一个算法收敛到解的速度有多快？我们如何精确地度量和比较不同算法的收敛效率？
2.  **“能不能更快？”**：对于那些收敛缓慢的算法，我们有没有办法对其进行“加速”？
3.  **“遇到特殊情况怎么办？”**：当算法的理想条件不被满足时（例如，牛顿法遇到重根），会发生什么？我们如何修正算法以应对这些挑战？

今天课程的前半部分，我们将聚焦于**迭代方法的误差分析与加速**，为我们上一讲学习的工具箱打上“性能标签”。

课程的后半部分，我们将切换到一个看似完全不同，但实际上在数值计算中更为基础和核心的领域：**求解线性方程组 $A\\mathbf{x} = \\mathbf{b}$**。大家可能会觉得奇怪，线性代数不是已经教过高斯消元法了吗？为什么还要在数值分析里重学一遍？

原因在于，我们在第一讲中反复强调的**舍入误差**。对于大型或某些“病态”的线性系统，经典的高斯消元法在计算机上执行时，微小的舍入误差可能会被急剧放大，导致最终结果与真实解谬以千里。我们将重新审视高斯消元法，从**数值稳定性**的角度出发，探讨如何通过**主元选择 (Pivoting)** 策略来驯服舍入误差，确保我们得到可靠的解。

让我们从衡量“快慢”的标准开始。

### **第一部分：迭代法的收敛阶**

#### **2.4.1 收敛速度的度量**

假设我们有一个迭代序列 ${p\_n}$ 收敛到真解 $p$。我们定义第 $n$ 步的误差为 $e\_n = |p\_n - p|$。我们关心的是，误差是如何随着迭代次数 $n$ 的增加而减小的。

**定义 (收敛阶 - Order of Convergence):** 设序列 ${p\_n}$ 收敛于 $p$，且对所有 $n$，$p\_n \\neq p$。如果存在正常数 $\\alpha$ 和 $\\lambda$ 使得： $$\\lim\_{n \\to \\infty} \\frac{|p\_{n+1} - p|}{|p\_n - p|^\\alpha} = \\lim\_{n \\to \\infty} \\frac{e\_{n+1}}{e\_n^\\alpha} = \\lambda$$ 则称该序列是 **$\\alpha$ 阶收敛**的。

*   $\\alpha$ 被称为**收敛阶 (Order of Convergence)**。
*   $\\lambda$ 被称为**渐进误差常数 (Asymptotic Error Constant)**。

**直观理解：** 这个定义告诉我们，当 $n$ 足够大时，误差之间近似满足关系 $e\_{n+1} \\approx \\lambda e\_n^\\alpha$。

*   **$\\alpha$ 越大，收敛速度越快。** 它决定了误差缩减的“模式”。
*   如果 $\\alpha$ 相同，**$\\lambda$ 越小，收敛速度越快。** 它决定了在同一种模式下的“效率”。

**两种重要的收敛类型：**

1.  **线性收敛 (Linear Convergence, $\\alpha=1$):** $$e\_{n+1} \\approx \\lambda e\_n$$ 要使序列收敛，必须有 $0 < \\lambda < 1$。 每次迭代，误差大约乘以一个固定的常数。这意味着**每经过固定次数的迭代，有效数字大约增加一位**。例如，如果 $\\lambda=0.1$，则每次迭代增加一位有效数字。二分法和一般的不动点迭代法都属于此类。
    
2.  **二次收敛 (Quadratic Convergence, $\\alpha=2$):** $$e\_{n+1} \\approx \\lambda e\_n^2$$ 这是一种极快的收敛。如果当前误差 $e\_n = 10^{-k}$，那么下一步误差 $e\_{n+1} \\approx \\lambda (10^{-k})^2 = \\lambda 10^{-2k}$。这意味着**有效数字的位数在每次迭代后大约翻倍**！牛顿法在求解单根时就是典型的二次收敛。
    

#### **2.4.2 不同方法的收敛阶分析**

**Q: 对于不动点迭代 $p\_n = g(p\_{n-1})$，如果 $g'(p) \\neq 0$，其收敛阶是多少？** **A: 线性收敛。** 回顾上一讲的推导： $$p\_{n+1} - p = g(p\_n) - g(p) = g'(\\xi\_n)(p\_n - p)$$其中 $\\xi\_n$ 在 $p\_n$ 和 $p$ 之间。 当 $n \\to \\infty$ 时，$p\_n \\to p$，因此 $\\xi\_n \\to p$。 $$\\lim\_{n \\to \\infty} \\frac{|p\_{n+1} - p|}{|p\_n - p|^1} = \\lim\_{n \\to \\infty} |g'(\\xi\_n)| = |g'(p)|$$ 所以，$\\alpha=1$，$\\lambda = |g'(p)|$。只要 $|g'(p)| < 1$ 且不为零，该方法就是线性收敛。

**Discussion 8: 牛顿法的收敛阶 (当 $g'(p) = 0$ 时)** **A: 二次收敛。** 牛顿法的迭代函数 $g(x) = x - f(x)/f'(x)$ 满足 $g'(p)=0$（对于单根）。我们需要更高阶的分析。 将 $g(p\_n)$ 在真根 $p$ 附近进行二阶泰勒展开： $$p\_{n+1} = g(p\_n) = g(p) + g'(p)(p\_n - p) + \\frac{g''(\\xi\_n)}{2!}(p\_n - p)^2$$ 因为 $p=g(p)$ 且 $g'(p)=0$，上式简化为： $$p\_{n+1} - p = \\frac{g''(\\xi\_n)}{2}(p\_n - p)^2$$ 取极限： $$\\lim\_{n \\to \\infty} \\frac{|p\_{n+1} - p|}{|p\_n - p|^2} = \\lim\_{n \\to \\infty} \\left|\\frac{g''(\\xi\_n)}{2}\\right| = \\left|\\frac{g''(p)}{2}\\right|$$ 所以，$\\alpha=2$，$\\lambda = |g''(p)|/2$。只要 $f'(p) \\neq 0$（即 $p$ 是单根），牛顿法至少是二次收敛的。

#### **2.4.3 牛顿法在重根情况下的表现**

**Discussion 9: 如果根不是单根，牛顿法的收敛阶是多少？** **A: 退化为线性收敛。** 假设 $p$ 是 $f(x)$ 的一个 **$m$ 重根**。这意味着 $f(x)$ 可以写作 $f(x) = (x-p)^m q(x)$，其中 $q(p) \\neq 0$。 在这种情况下，可以证明牛顿法的迭代函数 $g(x)=x-f(x)/f'(x)$ 在根 $p$ 处的导数为： $$g'(p) = 1 - \\frac{1}{m}$$ 由于 $m \\ge 2$（重根），我们有 $0 < g'(p) < 1$。 根据前面的分析，这正是**线性收敛**的特征，其渐进误差常数 $\\lambda = 1 - 1/m$。重数 $m$ 越大，$\\lambda$ 越接近1，收敛就越慢。

**Q: 如何加速牛顿法在重根情况下的收敛？** **A: 改造函数，将重根转化为单根。** 我们可以构造一个新函数 $\\mu(x) = \\frac{f(x)}{f'(x)}$。 如果 $f(x) = (x-p)^m q(x)$，那么可以计算出： $$f'(x) = m(x-p)^{m-1}q(x) + (x-p)^m q'(x)$$ $$\\mu(x) = \\frac{(x-p)^m q(x)}{m(x-p)^{m-1}q(x) + (x-p)^m q'(x)} = (x-p) \\frac{q(x)}{m q(x) + (x-p)q'(x)}$$ 令 $$H(x) = \\frac{q(x)}{m q(x) + (x-p)q'(x)}$$则 $$\\mu(x) = (x-p)H(x)$$ 由于 $q(p)\\neq 0$，所以 $H(p) = \\frac{q(p)}{m q(p)} = \\frac{1}{m} \\neq 0$。 这意味着 $p$ 是新函数 $\\mu(x)$ 的一个**单根**！

**修正的牛顿法 (Modified Newton's Method):** 我们可以对 $\\mu(x)=0$ 应用标准的牛顿法，迭代格式为 $p\_n = p\_{n-1} - \\frac{\\mu(p\_{n-1})}{\\mu'(p\_{n-1})}$。 将 $\\mu(x)$ 的表达式代入并化简，得到： $$p\_n = p\_{n-1} - \\frac{f(p\_{n-1})f'(p\_{n-1})}{\[f'(p\_{n-1})\]^2 - f(p\_{n-1})f''(p\_{n-1})}$$

**优点：** 恢复了二次收敛性。 **缺点：**

1.  需要计算二阶导数 $f''(x)$，计算成本更高。
2.  当 $p\_n$ 接近根 $p$ 时，分子和分母都趋近于0，可能导致严重的舍入误差（相近数相减）。
3.  需要预先知道根的重数 $m$。如果知道 $m$，一个更简单的修正是：$p\_n = p\_{n-1} - m \\frac{f(p\_{n-1})}{f'(p\_{n-1})}$。

### **第二部分：加速收敛技术**

#### **2.5.1 Aitken's $\\Delta^2$ 方法**

对于任何一个线性收敛的序列，我们有没有办法从中“榨取”出更多的信息，以更快地逼近极限？Aitken's $\\Delta^2$ 方法给出了一个肯定的答案。

**思想：** 假设有一个线性收敛序列 ${p\_n}$ 收敛到 $p$。当 $n$ 很大时，我们有： $\\frac{p\_{n+1}-p}{p\_n-p} \\approx \\lambda$ 和 $\\frac{p\_{n+2}-p}{p\_{n+1}-p} \\approx \\lambda$ 联立这两个近似式，消去 $\\lambda$，然后解出 $p$： $$p \\approx p\_n - \\frac{(p\_{n+1}-p\_n)^2}{p\_{n+2} - 2p\_{n+1} + p\_n}$$

这个公式利用序列中的连续三项 $(p\_n, p\_{n+1}, p\_{n+2})$ 来构造一个对极限 $p$ 的更好的估计，我们记为 $\\hat{p}\_n$。

**定义 (前向差分 - Forward Difference):** $$\\Delta p\_n = p\_{n+1} - p\_n$$ $$\\Delta^2 p\_n = \\Delta(p\_{n+1} - p\_n) = (p\_{n+2}-p\_{n+1}) - (p\_{n+1}-p\_n) = p\_{n+2} - 2p\_{n+1} + p\_n$$

**Aitken's $\\Delta^2$ 方法公式:** $$\\hat{p}\_n = p\_n - \\frac{(\\Delta p\_n)^2}{\\Delta^2 p\_n}$$

**定理：** 如果 ${p\_n}$ 是一个线性收敛序列，那么由Aitken方法构造的新序列 ${\\hat{p}\_n}$ 将**比 ${p\_n}$ 更快地收敛到 $p$**，即 $\\lim\_{n \\to \\infty} \\frac{\\hat{p}\_n - p}{p\_n - p} = 0$。

#### **2.5.2 Steffensen's 方法：将线性加速为二次**

Aitken方法是一个**后处理**技术：它利用一个已经生成的序列来构造一个更好的序列。 Steffensen's 方法则将Aitken加速的思想**直接嵌入到不动点迭代过程中**，创造出一个全新的、收敛更快的算法。

**Steffensen's 算法:**

1.  从一个初始值 $p\_0^{(0)}$ 开始。
2.  **在一个迭代步内，执行以下三步：** a) 从 $p\_0^{(i)}$ 出发，做两步标准的不动点迭代： $p\_1^{(i)} = g(p\_0^{(i)})$ $p\_2^{(i)} = g(p\_1^{(i)})$ b) 用 $(p\_0^{(i)}, p\_1^{(i)}, p\_2^{(i)})$ 这三点，应用Aitken's $\\Delta^2$ 公式来计算一个加速后的点： $p\_0^{(i+1)} = p\_0^{(i)} - \\frac{(p\_1^{(i)} - p\_0^{(i)})^2}{p\_2^{(i)} - 2p\_1^{(i)} + p\_0^{(i)}}$
3.  重复第2步，直到收敛。

**惊人的结果：** 如果标准的不动点迭代是线性收敛的（即 $g'(p) \\neq 0$），Steffensen's 方法通常是**二次收敛**的！它以每次迭代计算三次函数 $g$ 的代价，将一个线性收敛的方法提升到了二次收敛。这在很多情况下是非常划算的。

### **第三部分：求解线性方程组的直接法——高斯消元**

现在我们转向一个全新的，也是数值计算中无处不在的主题：求解 $A\\mathbf{x}=\\mathbf{b}$。

#### **6.1.1 算法回顾：朴素高斯消元法 (Naïve Gaussian Elimination)**

大家在线性代数中学习过，高斯消元法包含两个主要阶段：

1.  **消元 (Elimination):** 通过一系列的**行变换**，将增广矩阵 $\[A|\\mathbf{b}\]$ 化为 $\[U|\\mathbf{c}\]$ 的形式，其中 $U$ 是一个**上三角矩阵**。
    
    *   **Step k:** 在第 $k$ 步（$k=1, \\dots, n-1$），我们的目标是利用第 $k$ 行，将第 $k$ 列中对角线以下的元素 ($a\_{ik}$ for $i=k+1, \\dots, n$) 全部变为0。
    *   对于第 $i$ 行（$i>k$），我们计算乘数 $m\_{ik} = a\_{ik}^{(k)} / a\_{kk}^{(k)}$，然后执行行变换：`Row_i = Row_i - m_ik * Row_k`。
    *   元素 $a\_{kk}^{(k)}$ 在这个过程中被称为**主元 (Pivot Element)**。
2.  **回代 (Backward Substitution):** 对上三角方程组 $U\\mathbf{x} = \\mathbf{c}$ 进行求解。这是一个非常简单的过程：
    
    *   首先从最后一行解出 $x\_n = c\_n / u\_{nn}$。
    *   然后将 $x\_n$ 的值代入倒数第二行，解出 $x\_{n-1}$。
    *   以此类推，自下而上依次解出所有变量： $x\_i = \\frac{1}{u\_{ii}} \\left( c\_i - \\sum\_{j=i+1}^{n} u\_{ij}x\_j \\right)$, for $i = n-1, \\dots, 1$。

**计算量分析 (Operation Count):** 可以证明，对于一个 $n \\times n$ 的系统：

*   消元阶段的乘法/除法次数约为 $\\frac{n^3}{3}$。
*   回代阶段的乘法/除法次数约为 $\\frac{n^2}{2}$。 当 $n$ 很大时，总计算量由消元阶段主导，约为 $O(n^3)$。

#### **6.1.2 数值陷阱：主元为零或过小**

朴素高斯消元法有一个致命的假设：在第 $k$ 步，主元 $a\_{kk}^{(k)}$ 必须不为零。如果它为零，算法将因除零错误而失败。

**更隐蔽、更危险的问题是：如果主元 $a\_{kk}^{(k)}$ 不是零，但它是一个绝对值非常小的数呢？**

**研究课题 4: 一个灾难性的例子** 求解线性系统（使用4位四舍五入算术）： $$\\begin{cases} 0.003000 x\_1 + 59.14 x\_2 = 59.17 \\\\ 5.291 x\_1 - 6.130 x\_2 = 46.78 \\end{cases}$$

**精确解 (用高精度计算):** $x\_1 = 10.00, x\_2 = 1.000$。

**使用朴素高斯消元法（4位算术）：**

1.  **Step 1:** 主元是 $a\_{11} = 0.003000$。这是一个非常小的数！
2.  计算乘数：$m\_{21} = \\frac{5.291}{0.003000} = 1763.66... \\to 1764$ (四舍五入)。这是一个非常大的乘数！
3.  执行行变换 `Row2 = Row2 - 1764 * Row1`：
    *   新的 $a\_{22}$: $-6.130 - 1764 \\times 59.14 = -6.130 - 104300 \\approx -104300$ (在有限精度下，-6.130被完全“吃掉”了)。
    *   新的 $b\_2$: $46.78 - 1764 \\times 59.17 = 46.78 - 104400 \\approx -104400$。
4.  得到上三角系统： $$\\begin{cases} 0.003000 x\_1 + 59.14 x\_2 = 59.17 \\\\ -104300 x\_2 = -104400 \\end{cases}$$
5.  **回代求解：**
    *   $x\_2 = \\frac{-104400}{-104300} \\approx 1.001$。这个结果看起来还不错。
    *   $x\_1 = \\frac{59.17 - 59.14 \\times 1.001}{0.003000} = \\frac{59.17 - 59.20}{0.003000} = \\frac{-0.03}{0.003000} = -10.00$。**灾难！** 真实解是+10.00。

**问题出在哪里 (Who is the trouble maker)?**

*   **直接原因：** 小主元 $a\_{11}=0.003000$ 导致了巨大的乘数 $m\_{21}=1764$。
*   **根本原因：** 在执行 `Row2 - m21 * Row1` 时，乘数 $m\_{21}$ 将第一行中存在的微小舍入误差放大了1764倍，然后注入到第二行。这种巨大的误差传播彻底污染了方程组的信息。

#### **6.1.3 解决方案：部分主元法 (Partial Pivoting)**

**核心思想：** 在每一步消元前，**避免使用绝对值小的主元**。

**部分主元法策略 (Partial Pivoting):** 在第 $k$ 步消元开始时：

1.  在第 $k$ 列中，从对角线元素 $a\_{kk}^{(k)}$ 开始，向下扫描，找到绝对值最大的元素，即找到行号 $p$ 使得 $|a\_{pk}^{(k)}| = \\max\_{k \\le i \\le n} |a\_{ik}^{(k)}|$。
2.  **交换 (Swap)** 第 $k$ 行和第 $p$ 行。
3.  然后，以新的、绝对值最大的元素 $a\_{kk}^{(k)}$ 作为主元，继续进行标准的消元步骤。

**效果：** 通过这种策略，我们保证了所有的乘数 $m\_{ik} = a\_{ik}^{(k)}/a\_{kk}^{(k)}$ 的绝对值都**小于或等于1**。这有效地抑制了舍入误差在消元过程中的灾难性增长，极大地增强了算法的**数值稳定性 (Numerical Stability)**。

**用部分主元法再解刚才的例子：**

1.  **Step 1:**
    *   比较第一列的元素：$|a\_{11}|=0.003000, |a\_{21}|=5.291$。
    *   $|a\_{21}|$ 更大，所以交换第一行和第二行。 $\\begin{cases} 5.291 x\_1 - 6.130 x\_2 = 46.78 \\\\ 0.003000 x\_1 + 59.14 x\_2 = 59.17 \\end{cases}$
2.  现在，主元是 $a\_{11}=5.291$。
3.  计算乘数：$m\_{21} = \\frac{0.003000}{5.291} = 0.0005670... \\to 0.0005670$。这是一个非常小的乘数。
4.  执行行变换 `Row2 = Row2 - 0.0005670 * Row1`：
    *   新的 $a\_{22}$: $59.14 - 0.0005670 \\times (-6.130) = 59.14 + 0.003476 = 59.143476 \\to 59.14$。
    *   新的 $b\_2$: $59.17 - 0.0005670 \\times 46.78 = 59.17 - 0.02652 = 59.14348 \\to 59.14$。
5.  得到上三角系统： $\\begin{cases} 5.291 x\_1 - 6.130 x\_2 = 46.78 \\\\ 59.14 x\_2 = 59.14 \\end{cases}$
6.  **回代求解：**
    *   $x\_2 = \\frac{59.14}{59.14} = 1.000$。非常精确！
    *   $x\_1 = \\frac{46.78 - (-6.130) \\times 1.000}{5.291} = \\frac{46.78 + 6.130}{5.291} = \\frac{52.91}{5.291} = 10.00$。完美的结果！

**重要结论：** 在实践中，**永远不要使用没有主元选择策略的朴素高斯消元法**。部分主元法是工业标准，它以很小的额外计算成本（每一步需要一次比较）换来了算法的鲁棒性和解的可靠性。

### **课程总结**

**本讲核心要点：**

1.  **收敛阶是衡量迭代算法效率的关键指标。** 我们区分了线性收敛（误差按比例缩减）和二次收敛（有效数字位数翻倍），并分析了不动点迭代（线性）和牛顿法（二次）的收敛阶。
2.  **算法的性能是可以优化的。** 我们学习了如何通过函数变换来修复牛顿法在重根情况下的收敛性，以及如何使用Aitken/Steffensen方法将线性收敛加速到二次收敛。
3.  **直接法求解线性系统需要关注数值稳定性。** 朴素高斯消元法对主元大小敏感，小主元会导致舍入误差的灾难性放大。
4.  **部分主元法是高斯消元的标准配置。** 通过每一步选择列中绝对值最大的元素作为主元，可以有效控制误差传播，是保证算法稳定性的关键。

**连接与思考：** 今天我们讨论了两种截然不同的求解思路：求解非线性方程的**迭代法**和求解线性方程的**直接法**。

*   **直接法**（如高斯消元）在理论上经过有限步运算后能得到精确解（如果不考虑舍入误差）。
*   **迭代法**（如牛顿法）从一个初始猜测开始，产生一个逼近解的序列。

在后续课程中，我们还会学习求解线性方程组的**迭代法**（如Jacobi法、Gauss-Seidel法），这对于处理那些巨大且稀疏的线性系统（例如来自偏微分方程离散化）至关重要，因为直接法的 $O(n^3)$ 计算量和存储需求在这种情况下是无法承受的。