---
title: "计算机图形学14:人工智能在图形学中的应用"
description: ""
pubDate: "2025-08-27"
heroImage: ""
---

# 计算机图形学14:人工智能在图形学中的应用

### **1\. 什么是人工智能与机器学习？**

在深入探讨应用之前，我们首先需要建立对AI和机器学习的基本认知。

*   **人工智能 (AI):** 一个广阔的领域，其宏伟目标是创造能够像人类一样思考、学习和行动的智能体。它涵盖了自然语言处理、知识推理、机器感知、模式识别等多个子领域。
*   **机器学习 (Machine Learning, ML):** 实现人工智能的一种核心方法。它的精髓在于，我们**不再为计算机编写解决问题的具体、明确的规则**，而是让计算机**从大量的数据中自动学习**这些规则。

**传统编程 vs. 机器学习**

*   **传统编程:** `输入数据` + `程序员编写的规则` -> `输出结果`
*   **机器学习:** `输入数据` + `对应的正确结果(标签)` -> `机器学到的规则(模型)`

这种范式的转变是革命性的。它使得我们能够解决那些人类能做到、但却难以用语言精确描述其规则的复杂问题，比如“识别一张图片中的猫”或“判断一段文字的情感倾向”。

#### **机器学习的分类**

机器学习主要分为三类：

1.  **监督学习 (Supervised Learning):** 训练数据同时包含输入（如图片）和期望的输出（如标签“猫”）。
    *   **分类 (Classification):** 输出是离散的类别（猫、狗、车）。
    *   **回归 (Regression):** 输出是连续的数值（房价、股票价格）。
2.  **无监督学习 (Unsupervised Learning):** 训练数据只有输入，没有标签。算法需要自己发现数据中的结构和模式。
    *   **聚类 (Clustering):** 将相似的数据点分组。
    *   **降维 (Dimensionality Reduction):** 寻找数据的更紧凑表示。
3.  **强化学习 (Reinforcement Learning):** 智能体通过与环境交互，根据获得的奖励或惩罚来学习最优策略。AlphaGo就是强化学习的巅峰之作。

在图形学中，**监督学习**的应用最为广泛。

### **2\. 机器学习的核心引擎：人工神经网络 (ANN)**

**人工神经网络**是受人脑神经元结构启发而设计的数学模型，是当前深度学习革命的核心驱动力。

*   **基本单元：神经元 (Neuron):** 一个简单的计算单元，它接收多个输入，对它们进行加权求和，然后通过一个**激活函数 (Activation Function)**（如Sigmoid, ReLU）进行非线性变换，最终产生一个输出。
*   **网络结构：** 大量神经元组织成**层 (Layer)**。一个典型的网络包含一个**输入层**、一个或多个**隐藏层**和一个**输出层**。数据从输入层流入，经过隐藏层的逐层计算和变换，最终在输出层得到结果。
*   **深度学习：** 当神经网络包含非常多的隐藏层时，我们称之为**深度神经网络 (Deep Neural Network, DNN)**，而使用DNN进行学习的过程就是**深度学习**。

深度神经网络强大的**函数拟合能力**是其成功的关键。理论上，一个足够大的神经网络可以逼近任何复杂的连续函数。**训练 (Training)** 的过程，就是通过**反向传播算法 (Backpropagation)** 和**梯度下降 (Gradient Descent)**，不断调整网络中数以百万计的**权重 (Weights)**，使得网络对于给定的输入，其输出能越来越接近真实的标签，从而最小化**损失函数 (Loss Function)**。

### **3\. 应用案例：从单张图片重建三维人脸**

这是一个经典的图形学与AI结合的问题。传统方法通常需要复杂的多视图几何或结构光扫描。而基于深度学习的方法，试图训练一个神经网络，直接从**一张二维人脸图片**，回归出其对应的**三维人脸模型参数**。

*   **输入：** 一张RGB人脸图片。
*   **输出：** 一组控制**参数化人脸模型 (3DMM)** 的参数。
*   **核心网络：** 通常使用**卷积神经网络 (Convolutional Neural Network, CNN)**。CNN通过其**局部连接**和**权值共享**的特性，特别擅长从图像中提取空间特征。
*   **训练过程：**
    1.  用一个大型的三维人脸扫描数据库作为基础，构建一个参数化的3DMM模型。该模型能用一组参数（如身份参数$\\alpha\_{id}$，表情参数$\\alpha\_{exp}$）来表示各种人脸形状。
    2.  网络（CNN）学习从输入图片中预测出这组参数以及相机的姿态参数。
    3.  利用这些参数，生成一个三维人脸网格，并将其投影回二维平面。
    4.  定义**损失函数**，比较投影后的二维关键点与图片中真实的人脸关键点之间的误差，并通过反向传播来优化网络权重。
    5.  为了提升重建结果的**可识别性**，还可以引入一个预训练的**人脸识别网络**，将重建出的人脸参数输入该网络，计算**识别损失**，并加入到总的损失函数中，从而引导模型生成更具身份特征的人脸。

### **4\. 神经渲染 (Neural Rendering)：AI重塑渲染管线**

近年来，AI对图形学最颠覆性的影响体现在**神经渲染**领域。它不再将渲染管线视为一个固定的、基于物理规则的流程，而是将其中的一个或多个模块替换为**可学习的神经网络**。其中最引人注目的两项技术是 **NeRF** 和 **3D高斯溅射 (3DGS)**。

#### **4.1 NeRF (神经辐射场 - Neural Radiance Fields)**

NeRF是一种全新的**场景表示**方法。传统方法用三角形网格、体素等离散结构来表示场景，而NeRF用一个**连续的函数**——一个简单的**多层感知机 (MLP)** 神经网络——来表示整个三维场景。

*   **核心思想：** 这个神经网络 $F\_\\theta$ 学习的是一个映射关系： $$F\_\\theta : (x, y, z, d\_x, d\_y) \\rightarrow (\\text{color}, \\text{density})$$
    
    *   **输入：** 一个三维空间点坐标 $(x,y,z)$ 和一个观察方向 $(d\_x, d\_y)$。
    *   **输出：** 该空间点在该观察方向下的**颜色 (RGB)** 和**体密度 ($\\sigma$)**。体密度代表了该点有多大的可能性会阻挡光线。
*   **渲染过程（体渲染 - Volume Rendering）：**
    
    1.  对于屏幕上的一个像素，从相机出发，沿着穿过该像素的视线，在空间中采样一系列点。
    2.  将这些采样点的坐标和视线方向，**查询**已经训练好的NeRF网络，得到每个点的颜色和密度。
    3.  使用经典的**体渲染**积分公式，将这些采样点的颜色和密度沿光线进行**积分**，计算出最终穿过所有半透明粒子后到达相机的光线颜色，作为该像素的最终颜色。
*   **训练过程：**
    
    *   **输入：** 只需要一个场景的**多张、不同视角的二维图片**以及对应的**相机参数**。
    *   **损失函数：** 对于每个训练视角，用上述渲染过程生成一张图片，然后将其与真实的训练图片进行**逐像素的颜色对比**，计算损失。通过反向传播，优化神经网络的权重。

**NeRF的革命性在于：**

*   它用一个极小的神经网络（通常只有几MB）隐式地表示了极其复杂的、具有精细几何和光照细节的三维场景。
*   它能从稀疏的输入图像中，合成出任意新视角的、照片般真实感的图像，并能自然地处理半透明物体和复杂的视图依赖效果（如高光）。

#### **4.2 3D高斯溅射 (3D Gaussian Splatting, 3DGS)**

3DGS是2023年SIGGRAPH上提出的技术，它在保持NeRF高质量渲染的同时，实现了**极高的渲染速度**，达到了**实时**级别，引发了新一轮的轰动。

*   **核心思想：** 它不再使用连续的神经辐射场，而是用**大量的三维高斯分布**来显式地表示场景。
    
    *   每个高斯分布都有其**位置 (position)**、**协方差 (covariance)**（决定其形状和旋转）、**颜色 (color)** 和**不透明度 (opacity)** 等属性。
    *   可以把它们想象成一堆彩色的、半透明的、可拉伸变形的椭球云。
*   **渲染过程：**
    
    1.  将所有三维高斯分布**投影**到二维屏幕空间，它们会变成二维高斯分布。
    2.  这是一个高度可并行的操作，GPU通过专门设计的**光栅化器 (Splatting)**，高效地将这些二维高斯“溅射”到屏幕上。
    3.  对于每个像素，累加所有覆盖它的二维高斯的颜色（按不透明度加权），得到最终的像素颜色。
*   **训练过程：**
    
    *   与NeRF类似，从多视角图片和相机参数开始。
    *   但它优化的不再是神经网络权重，而是**所有三维高斯分布的属性**。
    *   训练过程中，算法会自动地**分裂**（将一个大的高斯分裂成多个小的）和**剪枝**（删除不重要的高斯），从而自适应地调整高斯分布来更好地拟合场景几何。

**3DGS的优势：**

*   **实时性能：** 由于其显式的表示和高度并行的光栅化流程，3DGS的渲染速度比NeRF快了几个数量级，可以轻松实现高质量的实时漫游。
*   **训练快速：** 训练速度也远快于NeRF。

**NeRF vs. 3DGS** NeRF像是用一个连续函数去**隐式**地描述一个场景，而3DGS则是用大量的、离散的基元（高斯）去**显式**地构建一个场景。3DGS牺牲了一定的模型紧凑性，换来了无与伦比的渲染和训练速度。