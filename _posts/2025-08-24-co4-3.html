<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>计算机组成4-3:RISC-V与流水线</title>
    
    <link rel="stylesheet" href="../style.css">
    
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
</head>
<body>
    <audio id="bg-music" src="../music.mp3" loop></audio>
    <button id="music-toggle" class="music-control">♪</button>
    <header>
        <h1>forliage的blog</h1>
        <nav>
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../posts.html">文章</a></li>
                <li><a href="../about.html">关于</a></li>
                <li><a href="../category.html?category=技术文章">技术文章</a></li>
                <li><a href="../category.html?category=生活随笔">生活随笔</a></li>
                <li><a href="../category.html?category=学习笔记">学习笔记</a></li>
                <li><a href="../category.html?category=心情日记">心情日记</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
        <div id="sidebar-container"></div>
        <main>
            <article>
                <h1 id="%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%904-3risc-v%E4%B8%8E%E6%B5%81%E6%B0%B4%E7%BA%BF">计算机组成4-3:RISC-V与流水线</h1>
                <p>我们将不再仅仅满足于“如何实现流水线”，而是要去探究一个更深层次的问题：<strong>为什么RISC-V这样的指令集天生就如此“适合”流水线化？而像x86这样的指令集，实现流水线却要困难得多？</strong></p>
                <p>这背后揭示了一个计算机体系结构中最核心的设计哲学：<strong>指令集体系结构（ISA）的设计与微架构（Microarchitecture，如流水线）的实现，并非独立，而是一场精心编排、互相成就的“双人舞”。</strong> 一个优雅的ISA能够让流水线的设计事半功倍，而一个高效的流水线实现则能最大化地发挥ISA的性能潜力。</p>
                <h3 id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86risc-v%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%BA%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%80%8C%E7%94%9F"><strong>第一部分：RISC-V的设计——为流水线而生</strong></h3>
                <p>RISC（精简指令集计算机）的崛起，其背后最重要的驱动力之一，就是为了简化和高效实现流水线。RISC-V作为现代RISC ISA的典范，其设计的每一个角落都闪耀着对流水线友好的光芒。</p>
                <h4 id="11-%E7%89%B9%E5%BE%81%E4%B8%80%E6%89%80%E6%9C%89%E6%8C%87%E4%BB%A4%E7%AD%89%E9%95%BF32%E4%BD%8D"><strong>1.1 特征一：所有指令等长（32位）</strong></h4>
                <ul>
                <li>
                <p><strong>硬件实现上的巨大优势</strong>：</p>
                <ol>
                <li><strong>取指（IF）阶段极大简化</strong>：处理器无需知道当前指令是什么，就可以确定下一条指令的地址——永远是<code>PC+4</code>。取指单元可以被设计成一个非常简单、高速的“傻瓜式”取货机器。</li>
                <li><strong>译码（ID）阶段可以提前进行</strong>：由于指令长度固定，指令中的关键字段（如<code>opcode</code>, <code>rs1</code>, <code>rs2</code>, <code>rd</code>）总是在<strong>固定的位置</strong>。这意味着，我们可以在指令被完整取出的<strong>同一个周期内</strong>，并行地将<code>rs1</code>和<code>rs2</code>的地址送入寄存器堆进行读取。不需要先译码判断指令长度和格式，再回头找操作数字段。这使得IF和ID阶段可以干净利落地在一个时钟周期内完成，极大地帮助了流水线阶段的平衡。</li>
                </ol>
                </li>
                <li>
                <p><strong>反例：CISC（如x86）的挑战</strong>：</p>
                <ul>
                <li>x86指令长度从1字节到17字节不等。</li>
                <li><strong>取指梦魇</strong>：处理器在没有完全译码当前指令之前，根本<strong>无法知道</strong>下一条指令从哪里开始。取指和译码过程高度耦合，难以拆分成独立的流水线阶段。</li>
                <li><strong>现代x86处理器的解决方案</strong>：它们在硬件内部，会将复杂、变长的x86指令，动态地翻译成定长、简单的、类似RISC的<strong>微操作（micro-ops）</strong>。然后，真正进入后端执行流水线的，是这些微操作。这相当于在硬件里内置了一个“编译器”，代价是极大的复杂度和功耗。</li>
                </ul>
                </li>
                </ul>
                <h4 id="12-%E7%89%B9%E5%BE%81%E4%BA%8C%E8%A7%84%E6%95%B4%E5%B0%91%E9%87%8F%E7%9A%84%E6%8C%87%E4%BB%A4%E6%A0%BC%E5%BC%8F"><strong>1.2 特征二：规整、少量的指令格式</strong></h4>
                <ul>
                <li>
                <p><strong>硬件实现上的优势</strong>：</p>
                <ul>
                <li>RISC-V只有少数几种（R, I, S, B, U, J）高度规整的格式。</li>
                <li><strong>源寄存器（rs1, rs2）和目标寄存器（rd）的位置相对固定</strong>。观察RISC-V指令格式图，你会发现<code>rs1</code>和<code>rd</code>总是在几乎相同的位置，<code>rs2</code>的位置也有限。</li>
                <li><strong>译码与寄存器读取并行化</strong>：这种规整性使得控制单元的译码逻辑和寄存器堆的读取操作可以<strong>并行进行</strong>。在ID阶段，硬件可以“推测性”地将<code>bits[19:15]</code>和<code>bits[24:20]</code>直接送去读寄存器堆，同时控制单元根据<code>opcode</code>进行译码。无论最终是什么指令，这种“提前读取”的操作要么是有用的（如R-Type, S-Type, B-Type），要么是无害的（如J-Type，读出的值不用即可）。这大大缩短了ID阶段的关键路径。</li>
                </ul>
                </li>
                <li>
                <p><strong>反例：CISC的复杂性</strong>：</p>
                <ul>
                <li>某些CISC指令集（如VAX）有几十种指令格式，操作数可能在内存，也可能在寄存器，寻址方式五花八门。</li>
                <li>这使得译码成为一个多周期的、串行的复杂过程，极大地阻碍了流水线的流畅运行。</li>
                </ul>
                </li>
                </ul>
                <h4 id="13-%E7%89%B9%E5%BE%81%E4%B8%89loadstore%E6%9E%B6%E6%9E%84"><strong>1.3 特征三：Load/Store架构</strong></h4>
                <ul>
                <li>
                <p><strong>定义</strong>：只有<code>load</code>和<code>store</code>指令可以访问内存。所有的计算指令（如<code>add</code>, <code>sub</code>）的操作数都必须来自寄存器，结果也必须写入寄存器。</p>
                </li>
                <li>
                <p><strong>对流水线的巨大贡献</strong>：</p>
                <ol>
                <li><strong>流水线阶段的清晰划分</strong>：这个设计哲学，天然地将指令执行过程分成了“计算”和“访存”两个互不干扰的阶段。这使得我们的五级流水线（IF-ID-EX-MEM-WB）划分变得异常自然和高效。
                <ul>
                <li>ALU指令的生命周期是：IF -&gt; ID -&gt; EX -&gt; (跳过MEM) -&gt; WB。</li>
                <li>访存指令的生命周期是：IF -&gt; ID -&gt; EX (计算地址) -&gt; MEM (访问数据) -&gt; WB (仅<code>ld</code>)。</li>
                </ul>
                </li>
                <li><strong>简化了EX阶段</strong>：EX阶段的任务变得非常单一：要么执行一次ALU计算，要么计算一个内存地址。不需要处理“操作数一半在寄存器一半在内存”的复杂情况。这有助于保持EX阶段的延迟相对稳定和可控。</li>
                <li><strong>简化了数据冒险的处理</strong>：由于计算和访存分离，数据冒险只发生在寄存器之间，处理逻辑（前递）相对统一和简单。</li>
                </ol>
                </li>
                <li>
                <p><strong>反例：CISC的内存操作数</strong>：</p>
                <ul>
                <li>x86允许这样的指令：<code>add eax, [memory_address]</code>。</li>
                <li><strong>流水线阶段的混乱</strong>：这条指令既需要ALU计算，又需要访问内存，它同时染指了EX和MEM两个阶段的核心功能。这使得设计一个干净、平衡的流水线变得极其困难。你需要一个超长的阶段来处理它，或者设计更复杂的流水线来分解这种操作，无论哪种都增加了设计的复杂性。</li>
                </ul>
                </li>
                </ul>
                <p><strong>小结</strong>：RISC-V的简洁优雅并非偶然，它是为了迎合高效流水线实现而精心设计的产物。汇编语言程序员（或编译器）所看到的简洁指令，直接映射到了硬件设计者所期望的简单、高速的逻辑通路。</p>
                <h3 id="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%B9%B6%E8%A1%8Cilp%E6%A6%A8%E5%B9%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E6%BB%B4%E6%80%A7%E8%83%BD"><strong>第二部分：指令级并行（ILP）——榨干流水线的最后一滴性能</strong></h3>
                <p>我们已经构建了每个周期理想情况下能完成一条指令（IPC=1）的流水线。但这还不是性能的终点。真正的性能野兽，追求的是<strong>IPC &gt; 1</strong>。这就是**指令级并行（Instruction-Level Parallelism, ILP）**的范畴。其核心思想是：在一个时钟周期内，启动多条指令的执行。</p>
                <h4 id="21-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0ilp%E4%B8%A4%E7%A7%8D%E5%93%B2%E5%AD%A6%E8%B7%AF%E5%BE%84"><strong>2.1 如何实现ILP：两种哲学路径</strong></h4>
                <p>有两种主流方法来挖掘和利用ILP：</p>
                <ol>
                <li>
                <p><strong>更深的流水线（Super-pipelining）</strong>：</p>
                <ul>
                <li><strong>思想</strong>：将原有的5级流水线切分得更细。比如，将EX阶段切分为EX1, EX2；将IF阶段切分为IF1(取地址), IF2(访问I-Cache)。</li>
                <li><strong>优势</strong>：每个阶段的逻辑更少，关键路径更短，因此可以实现<strong>更高的时钟频率</strong>。奔腾4处理器曾经将流水线做到了惊人的31级，追求的就是极致的时钟频率。</li>
                <li><strong>劣势</strong>：
                <ul>
                <li><strong>分支预测惩罚剧增</strong>：一次分支预测错误，需要冲刷掉的指令数量大大增加，性能损失惨重。</li>
                <li><strong>数据冒险延迟增加</strong>：数据前递可能需要跨越更多的阶段，导致某些情况下暂停无法避免。</li>
                <li><strong>流水线寄存器开销</strong>：更多的寄存器带来了额外的延迟和功耗。</li>
                </ul>
                </li>
                </ul>
                </li>
                <li>
                <p><strong>多发射（Multiple Issue）</strong>：</p>
                <ul>
                <li><strong>思想</strong>：在一个时钟周期内，同时取指、译码、发射多条指令到不同的执行单元。这需要处理器在硬件层面进行“扩容”。</li>
                <li><strong>实现方式</strong>：
                <ul>
                <li><strong>静态多发射（VLIW）</strong>：由<strong>编译器</strong>负责挖掘并行性。编译器将多条没有依赖关系的指令打包成一个“超长指令包（VLIW）”，硬件则简单地、机械地执行这个指令包中的所有操作。硬件设计简单，但极度依赖编译器的能力，且代码兼容性差。</li>
                <li><strong>动态多发射（超标量 Superscalar）</strong>：这是现代主流高性能处理器的选择。由<strong>硬件</strong>在运行时动态地检查指令流，寻找可以并行执行的指令，然后将它们发射到空闲的执行单元。</li>
                </ul>
                </li>
                </ul>
                </li>
                </ol>
                <h4 id="22-%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%A1%AC%E4%BB%B6%E7%9A%84%E6%99%BA%E6%85%A7"><strong>2.2 超标量处理器：硬件的智慧</strong></h4>
                <p>超标量处理器是当今高性能计算的基石。它的核心是<strong>乱序执行（Out-of-Order Execution）</strong>。</p>
                <p><img src="../images/imagec45.png" alt="figure 45"></p>
                <p><strong>乱序执行的核心思想</strong>：指令的执行顺序不必严格遵守程序中的顺序（即取指顺序），只要<strong>数据依赖关系</strong>得到满足即可。</p>
                <p><strong>经典例子</strong>：</p>
                <pre class="hljs"><code><div>ld   x31, 20(x21)   // 1. load, 可能需要很长时间 (cache miss)
                add  x1, x31, x2    // 2. add, 依赖于指令1
                sub  x23, x23, x3   // 3. sub, 与1,2无关
                andi x5, x23, 20   // 4. andi, 依赖于指令3
                </div></code></pre>
                <ul>
                <li><strong>顺序流水线（In-Order）</strong>：当指令1因为Cache Miss而卡在MEM阶段时，指令2因为等待<code>x31</code>而暂停在ID阶段，整个流水线都被阻塞了。指令3和4明明可以先执行，却也只能傻等。</li>
                <li><strong>乱序执行（Out-of-Order）</strong>：硬件会发现指令3不依赖于指令1和2，并且其操作数<code>x23</code>和<code>x3</code>都已就绪。于是，硬件会<strong>绕过</strong>被阻塞的指令2，<strong>提前执行</strong>指令3和4。</li>
                </ul>
                <p><strong>实现乱序执行的关键硬件部件</strong>：</p>
                <ul>
                <li><strong>保留站（Reservation Stations）</strong>：取代了简单的流水线寄存器。每条译码后的指令被送到一个保留站。保留站会监视所有执行单元的输出，等待其所需的操作数。一旦操作数就绪，指令就可以被发射到执行单元。</li>
                <li><strong>重排序缓冲（Reorder Buffer, ROB）</strong>：指令虽然是乱序执行的，但它们的执行结果**必须按程序顺序提交（Commit）**到寄存器堆和内存中，以保证程序的正确性（特别是为了精确异常）。ROB就是负责缓存乱序执行的结果，并按原始顺序进行提交的部件。</li>
                <li><strong>寄存器重命名（Register Renaming）</strong>：为了打破“假”的数据依赖（如写后写、写后读依赖），硬件会动态地将指令中的架构寄存器（如<code>x1</code>, <code>x2</code>）映射到一组更大的物理寄存器。这使得原本因为寄存器名相同而不能并行的指令，可以被并行执行。</li>
                </ul>
                <h4 id="23-%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E7%A1%AC%E4%BB%B6%E7%9A%84%E5%8D%8F%E5%90%8C%E6%8C%87%E4%BB%A4%E8%B0%83%E5%BA%A6%E4%B8%8E%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80"><strong>2.3 编译器与硬件的协同：指令调度与循环展开</strong></h4>
                <p>即使在强大的超标量处理器中，编译器依然扮演着至关重要的角色。</p>
                <ul>
                <li><strong>指令调度（Instruction Scheduling）</strong>：编译器通过重新排列指令顺序，可以更好地向硬件暴露并行性，减少硬件在运行时动态寻找并行指令的压力。</li>
                <li><strong>循环展开（Loop Unrolling）</strong>：
                <ul>
                <li><strong>思想</strong>：将循环体复制多次，并减少循环控制指令（如<code>addi</code>, <code>blt</code>）的比例。</li>
                <li><strong>好处</strong>：
                <ol>
                <li><strong>减少循环开销</strong>：分支指令是性能杀手，展开后分支次数减少。</li>
                <li><strong>暴露更多ILP</strong>：展开后的多个循环体之间，如果使用了不同的寄存器（通过<strong>寄存器重命名</strong>实现），就可能存在大量的并行性，可以被超标量处理器或VLIW编译器利用。</li>
                </ol>
                </li>
                </ul>
                </li>
                </ul>
                <p><strong>例子</strong>：
                一个简单的循环，经过编译器精心调度后，在双发射处理器上，IPC可以从1提升到1.25。如果再进行循环展开，IPC可以进一步提升到1.75，逼近理论峰值2。这是编译器和硬件协同优化的完美体现。</p>
                <h3 id="%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E7%8E%B0%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8cortex-a53%E4%B8%8Eintel-core-i7%E7%9A%84%E5%AF%B9%E6%AF%94"><strong>第三部分：现实世界的处理器——Cortex-A53与Intel Core i7的对比</strong></h3>
                <p>理论学习最终要回归到现实。让我们看看两款真实的、具有代表性的处理器，是如何应用我们今天所学的知识的。</p>
                <p><img src="../images/imagec46.png" alt="figure 46"></p>
                <ul>
                <li>
                <p><strong>ARM Cortex-A53 (典型的移动端、高能效核心)</strong></p>
                <ul>
                <li><strong>设计哲学</strong>：追求能效比，控制复杂度。</li>
                <li><strong>流水线</strong>：相对较短（8级），静态顺序双发射（In-order）。这意味着它每个周期最多发射两条指令，但严格按照程序顺序执行。</li>
                <li><strong>权衡</strong>：放弃了乱序执行带来的极致性能，换取了更低的功耗和更小的芯片面积。编译器调度对其性能至关重要。</li>
                </ul>
                </li>
                <li>
                <p><strong>Intel Core i7 920 (典型的高性能桌面/服务器核心)</strong></p>
                <ul>
                <li><strong>设计哲学</strong>：不惜一切代价追求单核性能。</li>
                <li><strong>流水线</strong>：非常深（14级），动态乱序多发射（Out-of-order），带推测执行。</li>
                <li><strong>权衡</strong>：通过极度复杂的硬件（乱序执行引擎、深度分支预测、推测执行等）来榨取ILP，带来了强大的性能，但也付出了巨大的功耗和芯片面积代价。</li>
                </ul>
                </li>
                </ul>
                <p><img src="../images/imagec47.png" alt="figure 47">
                <img src="../images/imagec48.png" alt="figure 48"></p>
                <p><strong>性能对比</strong>：</p>
                <ul>
                <li>A53的理想CPI很低，但更容易受到流水线暂停的影响。</li>
                <li>i7的CPI图中，“Stalls, misspeculation”占据了相当大的比例，这正是其复杂乱序和推测执行机制所付出的代价。但即使如此，其最终的有效CPI仍然非常低。</li>
                </ul>
                <p><strong>总结：</strong></p>
                <p>我们从ISA与流水线的协同设计出发，深入探讨了指令级并行的两大路径——超流水线与多发射，并解构了现代高性能处理器的核心——超标量乱序执行。</p>
                <p>我们必须深刻理解：</p>
                <ol>
                <li><strong>ISA是硬件的API</strong>：一个为流水线精心设计的ISA（如RISC-V），是构建高效处理器的基石。</li>
                <li><strong>ILP是性能的源泉</strong>：通过流水线、多发射、乱序执行等技术，处理器实现了从串行到并行的飞跃。</li>
                <li><strong>复杂性是永恒的敌人</strong>：更高的性能往往伴随着指数级增长的硬件复杂度和功耗。Cortex-A53和Core i7的选择，完美地诠释了在不同设计目标（能效 vs. 性能）下的不同权衡。</li>
                </ol>
            </article>
        </main>
    </div>
    
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
    <script src="../script.js"></script>
</body>
</html>