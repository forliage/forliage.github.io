<!DOCTYPE html>

<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<title>ads14:并行算法 (Parallel Algorithms)</title>
<link href="../style.css" rel="stylesheet"/>
<link href="../modal.css" rel="stylesheet"/>
<script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" type="text/javascript">
</script>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FPDBQB4LZD"></script>
<script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FPDBQB4LZD');
    </script>
</head>
<body>
<audio id="bg-music" loop="" src="../music.mp3"></audio>
<button class="music-control" id="music-toggle">♪</button><button class="dark-mode-control" id="dark-mode-toggle">🌙</button>
<header>
<h1>forliage的blog</h1>
<nav>
<ul>
<li><a href="../index.html">首页</a></li>
<li><a href="../posts.html">文章</a></li>
<li><a href="../about.html">关于</a></li>
<li><a href="../category.html?category=技术文章">技术文章</a></li>
<li><a href="../category.html?category=生活随笔">生活随笔</a></li>
<li><a href="../category.html?category=学习笔记">学习笔记</a></li>
<li><a href="../category.html?category=心情日记">心情日记</a></li>
<li><a href="#" id="about-me-btn">ABOUT ME</a></li>
</ul>
</nav>
</header>
<div class="container">
<div id="sidebar-container"></div>
<main>
<article>
<h1 id="ads14%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95-parallel-algorithms">ads14:并行算法 (Parallel Algorithms)</h1>
<h3 id="1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%B6%E8%A1%8C">1. 什么是并行？</h3>
<p>首先，我们要明确“并行”这个概念。它可以在不同的层面上体现。</p>
<ul>
<li>
<p><strong>机器并行 (Machine Parallelism)</strong>: 这是硬件层面实现的并行，对程序员来说通常是透明的。</p>
<ul>
<li><strong>处理器并行 (Processor parallelism)</strong>: 最直观的，就是在一台机器上放置多个CPU核心。</li>
<li><strong>流水线 (Pipelining)</strong>: 将一条指令的执行过程（如取指、译码、执行、写回）分解成多个阶段，让不同指令的不同阶段重叠执行，就像工厂里的流水线一样。</li>
<li><strong>超长指令字 (VLIW)</strong>: 在一条指令中打包多个可以同时执行的独立操作，交给硬件的不同功能单元去并行处理。</li>
</ul>
</li>
<li>
<p><strong>并行算法 (Parallel Algorithms)</strong>: 这是我们今天关注的重点，即在算法设计层面，主动地将一个大问题分解成多个可以同时执行的子任务，并设计它们之间的协作方式。</p>
</li>
</ul>
<p>为了能够严谨地设计和分析并行算法，我们需要一个理论模型，就像串行算法有RAM（随机存取机）模型一样。</p>
<h3 id="2-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B">2. 并行计算模型</h3>
<p>我们需要一个简洁而强大的抽象模型来描述并行算法，而不必陷入具体硬件（如缓存、网络拓扑）的泥潭。</p>
<h4 id="21-pram-%E6%A8%A1%E5%9E%8B%E7%90%86%E6%83%B3%E5%8C%96%E7%9A%84%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA">2.1 PRAM 模型：理想化的并行计算机</h4>
<p><strong>并行随机存取机 (Parallel Random Access Machine, PRAM)</strong> 是并行算法理论中最经典、最重要的模型。它描绘了一个理想化的并行计算环境。</p>
<p><strong>PRAM模型的构成</strong>：</p>
<ol>
<li><strong>多个同步处理器</strong>: 拥有 $P_1, P_2, \ldots, P_n$ 等多个处理器。它们共享同一个全局时钟，在每个时钟周期同步执行指令。</li>
<li><strong>一个共享内存</strong>: 所有处理器都可以访问一个无限大的共享内存空间。</li>
<li><strong>单位时间访问</strong>: 任何处理器对共享内存的任何位置进行一次读、写或进行一次本地计算，都只花费<strong>一个单位时间</strong>。</li>
</ol>
<div class="mermaid">
                graph TD
                    subgraph PRAM Model
                        P1(P₁) --- M(Shared Memory);
                        P2(P₂) --- M;
                        D[...] --- M;
                        Pn(Pₙ) --- M;
                        subgraph Processors
                            P1; P2; D; Pn;
                        end
                    end
                    
                    %% Create a separate node for the note and link it with a dotted line
                    NoteBox["Unit time access<br/>(read/write/computation)"];
                    M -.- NoteBox;
                    
                    style M fill:#9f9,stroke:#333,stroke-width:2px
                    style NoteBox fill:#fefefe,stroke:#333,stroke-width:1px,stroke-dasharray: 5 5
                </div>
<p>在PRAM模型中，我们经常使用一个特殊的关键字 <code>pardo</code> (parallel do) 来表示一个并行循环。例如：</p>
<p><code>for Pᵢ, 1 ≤ i ≤ n pardo A(i) := B(i)</code></p>
<p>这行代码表示，处理器 $P_1$ 执行 <code>A(1) := B(1)</code>，处理器 $P_2$ 执行 <code>A(2) := B(2)</code>，...，$P_n$ 执行 <code>A(n) := B(n)</code>，并且所有这些赋值操作都在<strong>同一个时间步</strong>内同时完成。</p>
<h4 id="22-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%86%B2%E7%AA%81%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">2.2 内存访问冲突及其解决方案</h4>
<p>PRAM模型的美妙之处在于它的简洁，但也带来了一个核心问题：如果多个处理器在同一时间步试图访问<strong>同一个内存单元</strong>，会发生什么？这就是<strong>访问冲突</strong>。</p>
<p>根据如何处理读和写的冲突，PRAM模型可以分为几类：</p>
<ol>
<li>
<p><strong>EREW (Exclusive-Read Exclusive-Write)</strong>: <strong>独占读，独占写</strong>。</p>
<ul>
<li>最严格的模型。在任何时间步，一个内存单元最多只能被一个处理器读取，也最多只能被一个处理器写入。</li>
<li>这是最容易在硬件上实现的模型，但对算法设计限制最大。</li>
</ul>
</li>
<li>
<p><strong>CREW (Concurrent-Read Exclusive-Write)</strong>: <strong>并发读，独占写</strong>。</p>
<ul>
<li>允许多个处理器在同一时间步读取同一个内存单元。</li>
<li>但仍然只允许一个处理器写入一个内存单元。</li>
<li>这是一个非常常用且实用的模型。</li>
</ul>
</li>
<li>
<p><strong>CRCW (Concurrent-Read Concurrent-Write)</strong>: <strong>并发读，并发写</strong>。</p>
<ul>
<li>最强大的模型。允许多个处理器同时读，也允许多个处理器同时写同一个内存单元。</li>
<li>并发写会带来一个新问题：如果多个处理器写入不同的值，最终写入的值是什么？为此，CRCW模型又分为几个子类来定义冲突解决规则：
                <ul>
<li><strong>任意 (Arbitrary) 规则</strong>: 任意一个处理器成功写入，我们不知道是哪一个。</li>
<li><strong>优先级 (Priority) 规则</strong>: 处理器ID最小（或最大）的那个成功写入。</li>
<li><strong>公共 (Common) 规则</strong>: 只有当所有试图写入的处理器都写入<strong>相同的值</strong>时，写入才成功。否则行为未定义或失败。</li>
<li><strong>求和 (Sum) 规则</strong>: 将所有试图写入的值相加，结果写入。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>这些模型的强大程度关系是：
                <strong>CRCW &gt; CREW &gt; EREW</strong>
                也就是说，为一个较弱模型（如EREW）设计的算法，可以直接在更强的模型（如CRCW）上运行。反之则不一定。</p>
<h3 id="3-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%80%E5%B9%B6%E8%A1%8C%E6%B1%82%E5%92%8C-parallel-summation">3. 案例分析一：并行求和 (Parallel Summation)</h3>
<p>让我们用一个简单的问题来感受并行算法的威力：计算一个数组 $A$ 中 $n$ 个元素的总和。</p>
<p><strong>问题</strong>:</p>
<ul>
<li>输入: $A(1), A(2), \ldots, A(n)$</li>
<li>输出: $S = \sum\limits_{i=1}^{n} A(i)$</li>
</ul>
<p>串行算法很简单，一个循环，需要 $O(n)$ 的时间。我们能用并行做得更快吗？</p>
<p><strong>并行思路：归约 (Reduction)</strong>
                我们可以利用一棵二叉树的结构来进行归约。</p>
<ul>
<li><strong>第0层</strong>: 原始数据。</li>
<li><strong>第1层</strong>: 每两个相邻的元素相加，结果存起来。</li>
<li><strong>第2层</strong>: 对上一层的结果，每两个相邻的再相加。</li>
<li>...依此类推，直到最后只剩下一个数，即总和。</li>
</ul>
<p>假设 $n=8$，这个过程如下：</p>
<div class="mermaid">
                graph TD
                    subgraph Reduction Tree for Summation
                        %% Define all nodes first with their text content
                        A1("A(1)"); A2("A(2)"); A3("A(3)"); A4("A(4)");
                        A5("A(5)"); A6("A(6)"); A7("A(7)"); A8("A(8)");
                        B11("1~2"); B12("3~4"); B13("5~6"); B14("7~8");
                        B21("1~4"); B22("5~8");
                        B31("1~8");

                        %% Define connections
                        A1 --&gt; B11; A2 --&gt; B11;
                        A3 --&gt; B12; A4 --&gt; B12;
                        A5 --&gt; B13; A6 --&gt; B13;
                        A7 --&gt; B14; A8 --&gt; B14;
                        B11 --&gt; B21; B12 --&gt; B21;
                        B13 --&gt; B22; B14 --&gt; B22;
                        B21 --&gt; B31; B22 --&gt; B31;
                    end
                    
                    %% Apply styles separately to make them circles
                    %% The 'rx' and 'ry' properties create circles/ellipses
                    style A1,A2,A3,A4,A5,A6,A7,A8 fill:#fff,stroke:#333,rx:20,ry:20
                    style B11,B12,B13,B14,B21,B22,B31 fill:#fff,stroke:#333,rx:20,ry:20
                </div>
<p>我们用 $B(h, i)$ 表示在第 $h$ 层，第 $i$ 个节点的值。
                $$B(h, i) = B(h-1, 2i-1) + B(h-1, 2i)$$</p>
<p><strong>PRAM 伪代码</strong>:
                (假设 $n=2^k$)</p>
<ol>
<li><strong>初始化 (1步)</strong>:
                <code>for Pᵢ, 1 ≤ i ≤ n pardo B(0, i) := A(i)</code></li>
<li><strong>归约循环 (log n 步)</strong>:
                <code>for h = 1 to log n</code>
<code>for Pᵢ, 1 ≤ i ≤ n/2ʰ pardo</code>
<code>B(h, i) := B(h-1, 2i-1) + B(h-1, 2i)</code></li>
<li><strong>输出 (1步)</strong>:
                <code>output B(log n, 1)</code></li>
</ol>
<p><strong>性能分析</strong>:</p>
<ul>
<li><strong>时间 (Time/Depth)</strong>: 初始化需要1步，归约循环执行 $\log n$ 次，每次循环体内的 <code>pardo</code> 都是一步。所以总时间是 $$T(n) = 1 + \log n + 1 = \log n + 2 = O(\log n)$$
                <ul>
<li>这里的 $T(n)$ 实际上是算法的<strong>深度 (Depth)</strong> 或 <strong>跨度 (Span)</strong>，代表了最长依赖链的长度。</li>
</ul>
</li>
<li><strong>总操作数 (Work)</strong>: 我们总共执行了多少次加法？
                <ul>
<li>第1层: $n/2$ 次</li>
<li>第2层: $n/4$ 次</li>
<li>...</li>
<li>第 $\log n$ 层: 1 次</li>
<li>总工作量 $$W(n) = n/2 + n/4 + \ldots + 1 = n-1$$加上初始化的 $n$ 次赋值，总工作量是 $$W(n) = 2n-1 = O(n)$$</li>
</ul>
</li>
</ul>
<p>我们用 $O(\log n)$ 的时间完成了 $O(n)$ 的工作！这是一个巨大的飞跃。</p>
<h4 id="31-%E4%BB%8E-pram-%E5%88%B0-work-depth-%E6%A8%A1%E5%9E%8B">3.1 从 PRAM 到 Work-Depth 模型</h4>
<p>PRAM 模型有一个问题：它总是假设我们有足够多的处理器（比如 $n$ 个）。如果处理器数量 $p &lt; n$ 怎么办？PRAM 的描述方式不够灵活。</p>
<p>因此，我们引入一个更抽象的模型：<strong>工作-深度 (Work-Depth, WD) 模型</strong>。
                我们只关心两个核心指标：</p>
<ul>
<li><strong>工作量 (Work) $W(n)$</strong>: 算法执行的总操作数。</li>
<li><strong>深度 (Depth) $T(n)$</strong>: 算法的并行时间，即最长依赖路径的长度。（在之前的幻灯片里，为了简化，也记为 $T(n)$，但含义是深度）</li>
</ul>
<p>WD 模型的好处是它<strong>将算法与机器解耦</strong>。一个算法的 $W(n)$ 和 $T(n)$ 是固定的，与你有多少处理器无关。</p>
<p><strong>布伦特定理 (Brent's Theorem)</strong> 给出了WD模型和PRAM模型之间的关系：
                一个具有 $W(n)$ 工作量和 $T(n)$ 深度的算法，可以在一个有 $p$ 个处理器的PRAM上，于 $O(W(n)/p + T(n))$ 时间内完成。</p>
<p><strong>直观理解</strong>:</p>
<ul>
<li>$W(n)/p$: 这是将所有工作平均分配给 $p$ 个处理器所需要的理想时间。</li>
<li>$T(n)$: 这是算法固有的串行瓶颈，即使有无限多的处理器也无法逾越。</li>
<li>实际运行时间由这两者共同决定。</li>
</ul>
<p>对于我们的求和算法：$W(n) = O(n)$, $T(n) = O(\log n)$。
                在有 $p$ 个处理器的机器上，运行时间为 $O(n/p + \log n)$。
                这个结果告诉我们，即使我们只有很少的处理器，我们依然可以通过并行获得加速。当 $p = n/\log n$ 时，时间为 $O(\log n)$，我们获得了最优的加速效果。</p>
<h3 id="4-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%BA%8C%E5%89%8D%E7%BC%80%E5%92%8C-prefix-sums--scan">4. 案例分析二：前缀和 (Prefix-Sums / Scan)</h3>
<p>前缀和是一个更强大、更通用的并行计算原语。</p>
<p><strong>问题</strong>:</p>
<ul>
<li>输入: $A(1), A(2), \ldots, A(n)$</li>
<li>输出: 一个数组 $C$，其中 $C(i) = \sum\limits_{k=1}^{i} A(k)$</li>
</ul>
<p>例如，输入 <code>[1, 1, 2, 3, 6, 2, 0, 1]</code>，输出 <code>[1, 2, 4, 7, 13, 15, 15, 16]</code>。</p>
<p>串行算法很简单，一个循环，$O(n)$ 时间。并行算法则需要更精巧的设计，通常使用<strong>平衡二叉树</strong>分两步完成。</p>
<p><strong>算法步骤</strong>:</p>
<p><strong>第一步：上行归约 (Up-Sweep / Reduction)</strong></p>
<ul>
<li>和并行求和完全一样。我们从叶子节点开始，向上计算每个内部节点所代表的子树的<strong>总和</strong>。我们将这些子树和存储在节点中（即 $B(h,i)$）。</li>
<li>这一步结束后，树的每个节点都知道它“管辖”范围内的所有叶子节点的和。</li>
<li>$$W(n) = O(n)$$ $$T(n) = O(\log n)$$</li>
</ul>
<p><strong>第二步：下行传递 (Down-Sweep / Scan)</strong></p>
<ul>
<li>现在我们从根节点开始向下传递信息，计算每个节点的前缀和。</li>
<li>我们给根节点一个初始前缀和 0。</li>
<li>对于树中的任意一个节点，当它从父节点接收到一个前缀和 <code>prefix_from_parent</code> 时：
                <ul>
<li>它将 <code>prefix_from_parent</code> 传递给它的<strong>左孩子</strong>。</li>
<li>它将 <code>prefix_from_parent</code> <strong>加上</strong> 它左孩子子树的总和（这在第一步已经算好了），然后将这个新值传递给它的<strong>右孩子</strong>。</li>
</ul>
</li>
<li>叶子节点 $A(i)$ 接收到父节点传来的前缀和后，将其与自身的值相加，就得到了最终的前缀和 $C(i)$。</li>
</ul>
<p><strong>图解 (n=8)</strong>:</p>
<div class="mermaid">
                graph TD
                    subgraph Prefix Sum Tree
                        direction TB
                        
                        %% Node Format: "p: prefix_from_parent | s: subtree_sum"
                        R("p: 0<br/>s: 16") --&gt; N21("p: 0<br/>s: 7") &amp; N22("p: 7<br/>s: 9");

                        N21 --&gt; N11("p: 0<br/>s: 2") &amp; N12("p: 2<br/>s: 5");
                        N22 --&gt; N13("p: 7<br/>s: 8") &amp; N14("p: 15<br/>s: 1");
                        
                        N11 --&gt; L1("A(1)=1<br/>C(1)=1");
                        N11 --&gt; L2("A(2)=1<br/>C(2)=2");
                        N12 --&gt; L3("A(3)=2<br/>C(3)=4");
                        N12 --&gt; L4("A(4)=3<br/>C(4)=7");
                        N13 --&gt; L5("A(5)=6<br/>C(5)=13");
                        N13 --&gt; L6("A(6)=2<br/>C(6)=15");
                        N14 --&gt; L7("A(7)=0<br/>C(7)=15");
                        N14 --&gt; L8("A(8)=1<br/>C(8)=16");
                    end
                    
                    style R,N21,N22,N11,N12,N13,N14 fill:#f99,stroke:#333
                </div>
<ul>
<li><strong>上行</strong>: 计算所有节点的 <code>s</code> 值 (subtree_sum)。</li>
<li><strong>下行</strong>:
                <ul>
<li>根节点 R 的 <code>p</code> (prefix_from_parent) 是 0。</li>
<li>R 把 <code>p=0</code> 传给左孩子 N21。</li>
<li>R 把 <code>p=0 + s(N21) = 0 + 7 = 7</code> 传给右孩子 N22。</li>
<li>N21 把 <code>p=0</code> 传给左孩子 N11。</li>
<li>N21 把 <code>p=0 + s(N11) = 0 + 2 = 2</code> 传给右孩子 N12。</li>
<li>...以此类推。</li>
<li>叶子节点 L1(A(1)) 从 N11 收到 <code>p=0</code>，最终结果是 <code>p + A(1) = 0+1=1</code>。</li>
<li>叶子节点 L3(A(3)) 从 N12 收到 <code>p=2</code>，最终结果是 <code>p + A(3) = 2+2=4</code>。</li>
</ul>
</li>
</ul>
<p><strong>性能分析</strong>:</p>
<ul>
<li>两步都是在平衡二叉树上进行，每一步的深度都是 $O(\log n)$。</li>
<li>总深度: $T(n) = O(\log n)$。</li>
<li>每一步都在树的 $O(n)$ 个节点上执行常数次操作。</li>
<li>总工作量: $W(n) = O(n)$。</li>
</ul>
<p>前缀和是一个极其有用的构建模块，可以用来解决很多问题，如数组打包、多项式求值等。</p>
<h3 id="5-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%89%E5%B9%B6%E8%A1%8C%E5%BD%92%E5%B9%B6-parallel-merging">5. 案例分析三：并行归并 (Parallel Merging)</h3>
<p><strong>问题</strong>: 将两个已排序的非递减数组 $A$ (大小为 $n$) 和 $B$ (大小为 $m$) 合并成一个有序数组 $C$。</p>
<p>串行归并算法是 $O(n+m)$ 的。我们可以做得更快吗？</p>
<p><strong>核心技术：划分 (Partitioning) 与 排序 (Ranking)</strong></p>
<p>并行归并的关键思想是，对于 $A$ 中的每个元素 $A(i)$，如果我们知道它在最终数组 $C$ 中的正确位置，我们就可以用一个 <code>pardo</code> 循环，一步到位地把它放到那个位置。</p>
<p>$A(i)$ 在 $C$ 中的位置是多少？是它自己的索引 $i$ 加上<strong>在数组 $B$ 中有多少个元素比它小</strong>。
                我们把“在数组 $X$ 中比值 $v$ 小的元素个数”定义为 <strong>RANK($v$, X)</strong>。</p>
<p>那么，$A(i)$ 在 $C$ 中的最终位置是 <code>i + RANK(A(i), B)</code>。
                同理，$B(j)$ 在 $C$ 中的最终位置是 <code>j + RANK(B(j), A)</code>。</p>
<p><strong>所以，归并问题被转化为了一个Ranking问题</strong>。</p>
<p><strong>Ranking问题</strong>:</p>
<ol>
<li>对每个 $A(i)$，计算 <code>RANK(A(i), B)</code>。</li>
<li>对每个 $B(j)$，计算 <code>RANK(B(j), A)</code>。</li>
</ol>
<p>一旦我们解决了Ranking问题，归并只需要 $O(1)$ 的并行时间：
                <code>for Pᵢ, 1 ≤ i ≤ n pardo C(i + RANK(A(i), B)) := A(i)</code>
<code>for Pᵢ, 1 ≤ i ≤ m pardo C(j + RANK(B(j), A)) := B(j)</code></p>
<p><strong>如何并行计算RANK？</strong></p>
<ul>
<li>
<p><strong>方法一: 并行二分查找</strong>
                对于每个 $A(i)$，我们可以在有序数组 $B$ 中使用二分查找来找到比它小的元素个数。</p>
<ul>
<li>一次二分查找需要 $O(\log m)$ 时间。</li>
<li>我们可以并行地为所有 $n$ 个 $A$ 的元素执行二分查找。</li>
<li><strong>深度</strong>: $T(n) = O(\log m)$。</li>
<li><strong>工作量</strong>: $W(n) = O(n \log m)$。</li>
<li>同样，计算 $B$ 在 $A$ 中的RANK，工作量是 $O(m \log n)$。</li>
<li>总工作量是 $O((n+m)\log(n+m))$。这比串行的 $O(n+m)$ 要差，我们称之为<strong>工作非效率 (work-inefficient)</strong>。</li>
</ul>
</li>
<li>
<p><strong>方法二: 划分思想 (更优)</strong>
                为了达到工作效率，我们需要更聪明的方法。</p>
<ol>
<li><strong>划分(Partitioning)</strong>:
                <ul>
<li>我们不为每个元素计算RANK，而是只为一些“代表”元素（pivots）计算。</li>
<li>假设 $n=m$，我们从 $A$ 中每隔 $\log n$ 个元素选一个，共选出 $p=n/\log n$ 个代表。</li>
<li>我们用并行二分查找，计算这 $p$ 个代表在 $B$ 中的RANK。</li>
<li>这些代表将数组 $B$ 也划分成了 $p$ 个块。</li>
</ul>
</li>
<li><strong>并发工作(Actual Work)</strong>:
                <ul>
<li>现在，原问题被分解成了 $2p$ 个更小的、独立的归并子问题。例如，$A$ 的第一个块和 $B$ 的第一个块进行归并，等等。</li>
<li>这些小的子问题可以并行地用串行归并算法解决。</li>
<li>通过精心选择块的大小，可以保证每个子问题的大小都是 $O(\log n)$。</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><strong>性能分析 (方法二)</strong>:</p>
<ul>
<li><strong>阶段1 (划分)</strong>: $p=n/\log n$ 次二分查找，并行执行。
                <ul>
<li>$T(n) = O(\log n)$</li>
<li>$W(n) = p \cdot O(\log n) = (n/\log n) \cdot O(\log n) = O(n)$</li>
</ul>
</li>
<li><strong>阶段2 (实际归并)</strong>: $2p$ 个 $O(\log n)$ 大小的子问题。
                <ul>
<li>$T(n) = O(\log n)$ (因为每个子问题串行解决)</li>
<li>$W(n) = 2p \cdot O(\log n) = 2(n/\log n) \cdot O(\log n) = O(n)$</li>
</ul>
</li>
<li><strong>总计</strong>: $T(n) = O(\log n)$, $W(n) = O(n)$。这是一个<strong>工作效率</strong>的并行归并算法！</li>
</ul>
<h3 id="6-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E5%9B%9B%E5%B9%B6%E8%A1%8C%E6%89%BE%E6%9C%80%E5%A4%A7%E5%80%BC-maximum-finding">6. 案例分析四：并行找最大值 (Maximum Finding)</h3>
<p><strong>问题</strong>: 在 $n$ 个元素中找到最大值。</p>
<h4 id="%E6%96%B9%E6%B3%95%E4%B8%80%E7%B1%BB%E4%BC%BC%E6%B1%82%E5%92%8C%E7%9A%84%E5%BD%92%E7%BA%A6">方法一：类似求和的归约</h4>
<ul>
<li>将求和算法中的 <code>+</code> 操作符换成 <code>max</code> 操作符。</li>
<li>性能完全相同：$T(n) = O(\log n)$, $W(n) = O(n)$。</li>
<li>这是一个非常好的、实用的算法。</li>
</ul>
<h4 id="%E6%96%B9%E6%B3%95%E4%BA%8C%E5%85%A8%E5%AF%B9%E6%AF%94%E8%BE%83-all-pairs-comparison">方法二：全对比较 (All-pairs comparison)</h4>
<ul>
<li>这是一个更激进的并行思路。</li>
<li>我们用 $n^2$ 个处理器，比较所有可能的元素对 $(A(i), A(j))$。</li>
<li>我们用一个辅助布尔数组 <code>is_max</code>，初始都为 <code>true</code>。</li>
<li><code>for i and j, 1 ≤ i, j ≤ n pardo</code>
<code>if A(i) &lt; A(j) then is_max[i] := false</code></li>
<li>最后，<code>is_max</code> 数组中唯一为 <code>true</code> 的那个位置对应的元素就是最大值。</li>
</ul>
<p><strong>性能分析</strong>:</p>
<ul>
<li><strong>深度</strong>: $T(n) = O(1)$。所有比较和赋值都在一步内完成！</li>
<li><strong>工作量</strong>: $W(n) = O(n^2)$。</li>
<li>这个算法速度极快，但工作量巨大，非常浪费资源。</li>
</ul>
<p><strong>Discussion 21: 如何解决访问冲突？</strong>
                在上面的 <code>is_max[i] := false</code> 步骤中，可能会发生并发写。例如，如果 $A(k)$ 不是最大值，那么所有比 $A(k)$ 大的 $A(j)$ 都会试图同时将 <code>is_max[k]</code> 设置为 <code>false</code>。</p>
<ul>
<li>这是一个典型的<strong>并发写</strong>场景，需要 <strong>CRCW PRAM</strong> 模型。</li>
<li>由于所有处理器都试图写入相同的值 (<code>false</code>)，<strong>公共 (Common) CRCW</strong> 规则就足够了。只要有一个处理器想写 <code>false</code>，结果就是 <code>false</code>，这符合我们的算法逻辑。</li>
<li>因此，这个 $O(1)$ 的算法需要在 CRCW PRAM 上才能正确运行。</li>
</ul>
<h4 id="%E6%96%B9%E6%B3%95%E4%B8%89%E5%8F%8C%E5%AF%B9%E6%95%B0%E8%8C%83%E5%BC%8F-doubly-logarithmic-paradigm">方法三：双对数范式 (Doubly-logarithmic Paradigm)</h4>
<p>这是一个更高级的递归思想，旨在进一步降低并行时间。</p>
<ul>
<li><strong>思路</strong>: 将大小为 $n$ 的问题，分解为 $\sqrt{n}$ 个大小为 $\sqrt{n}$ 的子问题。</li>
<li>
<ol>
<li>把数组 $A$ 划分成 $\sqrt{n}$ 个块，每块大小为 $\sqrt{n}$。</li>
</ol>
</li>
<li>
<ol start="2">
<li><strong>递归地</strong>在每个块中并行找到最大值。</li>
</ol>
</li>
<li>
<ol start="3">
<li>现在我们有了 $\sqrt{n}$ 个候选最大值，再在这些值中找到最终的最大值。</li>
</ol>
</li>
</ul>
<p><strong>性能分析</strong>:</p>
<ul>
<li>时间递推关系: $T(n) = T(\sqrt{n}) + O(1)$ (递归调用 + 找 $\sqrt{n}$ 个元素的最大值)
                <ul>
<li>解这个递推方程，得到 $T(n) = O(\log \log n)$。这是一个非常慢增长的函数！</li>
</ul>
</li>
<li>工作量递推关系: $W(n) = \sqrt{n} \cdot W(\sqrt{n}) + O(n)$ (递归调用 + 收集结果)
                <ul>
<li>解这个递推方程，得到 $W(n) = O(n \log \log n)$。工作量略有增加，但时间大大减少。</li>
</ul>
</li>
</ul>
<h4 id="%E6%96%B9%E6%B3%95%E5%9B%9B%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7-random-sampling">方法四：随机采样 (Random Sampling)</h4>
<p>这是并行算法与我们上一讲随机算法的完美结合，可以获得惊人的理论性能。</p>
<ul>
<li><strong>思路</strong>:
                <ol>
<li>从 $n$ 个元素中随机选出 $n^{1/8}$ 个元素作为一个样本。</li>
<li>在样本中并行找到最大值 $M$。</li>
<li>用这个样本最大值 $M$ 作为“过滤器”，遍历整个数组，找出所有比 $M$ 大的元素，形成一个“候选集”。</li>
<li>可以证明， باحتمال عالٍ جدًا (with very high probability)，这个候选集的大小会急剧缩小。</li>
<li>对这个小得多的候选集，重复此过程或使用其他算法找到最终最大值。</li>
</ol>
</li>
</ul>
<p><strong>性能分析</strong>:</p>
<ul>
<li>在<strong>任意 (Arbitrary) CRCW PRAM</strong> 模型上，可以设计出一种随机采样算法，它能<strong>以极高的概率</strong>在以下复杂度内找到最大值：
                <ul>
<li><strong>深度</strong>: $T(n) = O(1)$</li>
<li><strong>工作量</strong>: $W(n) = O(n)$</li>
</ul>
</li>
<li>这是理论上能达到的最佳结果：常数时间，线性工作量！它结合了并行、并发写和随机化的力量。</li>
</ul>
<h3 id="7-%E6%8B%93%E5%B1%95mapreduce-%E6%A8%A1%E5%9E%8B">7. 拓展：MapReduce 模型</h3>
<p>到目前为止，我们讨论的都是理论上的 PRAM 模型。在工业界，处理大规模数据最成功的并行编程模型之一是 Google 提出的 <strong>MapReduce</strong>。</p>
<p>MapReduce 将复杂的并行程序抽象为两个简单的函数：<code>Map</code> 和 <code>Reduce</code>。</p>
<ul>
<li><strong>Map 阶段</strong>:
                <ul>
<li>输入是 (key, value) 对。</li>
<li>Mapper 对每个输入对应用一个函数，产生零个或多个中间的 (key', value') 对。</li>
<li>所有的 Map 操作是<strong>完全并行</strong>的。</li>
</ul>
</li>
<li><strong>Shuffle &amp; Sort 阶段 (框架负责)</strong>:
                <ul>
<li>框架将所有 Map 的输出收集起来，并按照中间键 <code>key'</code>进行分组。</li>
<li>所有具有相同 <code>key'</code> 的 <code>value'</code> 被合并到一个列表中。</li>
</ul>
</li>
<li><strong>Reduce 阶段</strong>:
                <ul>
<li>输入是 (key', list of values')。</li>
<li>Reducer 对每个键的列表应用一个函数，产生最终的输出。</li>
<li>所有的 Reduce 操作也是<strong>并行</strong>的（不同键的 Reduce 任务可以并行）。</li>
</ul>
</li>
</ul>
<p><strong>示例：词频统计 (Word Count)</strong></p>
<div class="mermaid">
                graph TD
                    subgraph Map Phase
                        D1("doc1: 'hello world'") --&gt; M1(Map);
                        D2("doc2: 'hello class'") --&gt; M2(Map);
                    end

                    M1 --&gt; S1("('hello', 1)");
                    M1 --&gt; S2("('world', 1)");
                    M2 --&gt; S3("('hello', 1)");
                    M2 --&gt; S4("('class', 1)");

                    subgraph Shuffle &amp; Sort Phase
                        S1 &amp; S3 --&gt; G1("('hello', [1, 1])");
                        S2 --&gt; G2("('world', [1])");
                        S4 --&gt; G3("('class', [1])");
                    end

                    subgraph Reduce Phase
                        G1 --&gt; R1(Reduce) --&gt; O1("('hello', 2)");
                        G2 --&gt; R2(Reduce) --&gt; O2("('world', 1)");
                        G3 --&gt; R3(Reduce) --&gt; O3("('class', 1)");
                    end
                </div>
<p>MapReduce 的巨大成功在于它提供了一个简单的高层抽象，将程序员从并行编程的复杂细节（如同步、通信、容错）中解放出来，让他们可以专注于业务逻辑本身。</p>
</article><div class="share-buttons">
<p>分享到：</p>
<a class="share-btn weibo" href="#" onclick="sharePost(event, 'weibo')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Sina Weibo</title><path d="M10.098 20.323c-3.977.391-7.414-1.406-7.672-4.02-.259-2.609 2.759-5.047 6.74-5.441 3.979-.394 7.413 1.404 7.671 4.018.259 2.6-2.759 5.049-6.737 5.439l-.002.004zM9.05 17.219c-.384.616-1.208.884-1.829.602-.612-.279-.793-.991-.406-1.593.379-.595 1.176-.861 1.793-.601.622.263.82.972.442 1.592zm1.27-1.627c-.141.237-.449.353-.689.253-.236-.09-.313-.361-.177-.586.138-.227.436-.346.672-.24.239.09.315.36.18.601l.014-.028zm.176-2.719c-1.893-.493-4.033.45-4.857 2.118-.836 1.704-.026 3.591 1.886 4.21 1.983.64 4.318-.341 5.132-2.179.8-1.793-.201-3.642-2.161-4.149zm7.563-1.224c-.346-.105-.57-.18-.405-.615.375-.977.42-1.804 0-2.404-.781-1.112-2.915-1.053-5.364-.03 0 0-.766.331-.571-.271.376-1.217.315-2.224-.27-2.809-1.338-1.337-4.869.045-7.888 3.08C1.309 10.87 0 13.273 0 15.348c0 3.981 5.099 6.395 10.086 6.395 6.536 0 10.888-3.801 10.888-6.82 0-1.822-1.547-2.854-2.915-3.284v.01zm1.908-5.092c-.766-.856-1.908-1.187-2.96-.962-.436.09-.706.511-.616.932.09.42.511.691.932.602.511-.105 1.067.044 1.442.465.376.421.466.977.316 1.473-.136.406.089.856.51.992.405.119.857-.105.992-.512.33-1.021.12-2.178-.646-3.035l.03.045zm2.418-2.195c-1.576-1.757-3.905-2.419-6.054-1.968-.496.104-.812.587-.706 1.081.104.496.586.813 1.082.707 1.532-.331 3.185.15 4.296 1.383 1.112 1.246 1.429 2.943.947 4.416-.165.48.106 1.007.586 1.157.479.165.991-.104 1.157-.586.675-2.088.241-4.478-1.338-6.235l.03.045z"></path></svg>
<span>微博</span>
</a>
<a class="share-btn twitter" href="#" onclick="sharePost(event, 'twitter')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M21.543 7.104c.015.211.015.423.015.636 0 6.507-4.954 14.01-14.01 14.01v-.003A13.94 13.94 0 0 1 0 19.539a9.88 9.88 0 0 0 7.287-2.041 4.93 4.93 0 0 1-4.6-3.42 4.916 4.916 0 0 0 2.223-.084A4.926 4.926 0 0 1 .96 9.167v-.062a4.887 4.887 0 0 0 2.235.616A4.928 4.928 0 0 1 1.67 3.148 13.98 13.98 0 0 0 11.82 8.292a4.929 4.929 0 0 1 8.39-4.49 9.868 9.868 0 0 0 3.128-1.196 4.941 4.941 0 0 1-2.165 2.724A9.828 9.828 0 0 0 24 4.555a10.019 10.019 0 0 1-2.457 2.549z"></path></svg>
<span>Twitter</span>
</a>
<a class="share-btn linkedin" href="#" onclick="sharePost(event, 'linkedin')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg>
<span>LinkedIn</span>
</a>
<a class="share-btn wechat" href="#" onclick="sharePost(event, 'wechat')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>WeChat</title><path d="M8.691 2.188C3.891 2.188 0 5.476 0 9.53c0 2.212 1.17 4.203 3.002 5.55a.59.59 0 0 1 .213.665l-.39 1.48c-.019.07-.048.141-.048.213 0 .163.13.295.29.295a.326.326 0 0 0 .167-.054l1.903-1.114a.864.864 0 0 1 .717-.098 10.16 10.16 0 0 0 2.837.403c.276 0 .543-.027.811-.05-.857-2.578.157-4.972 1.932-6.446 1.703-1.415 3.882-1.98 5.853-1.838-.576-3.583-4.196-6.348-8.596-6.348zM5.785 5.991c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178A1.17 1.17 0 0 1 4.623 7.17c0-.651.52-1.18 1.162-1.18zm5.813 0c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178 1.17 1.17 0 0 1-1.162-1.178c0-.651.52-1.18 1.162-1.18zm5.34 2.867c-1.797-.052-3.746.512-5.28 1.786-1.72 1.428-2.687 3.72-1.78 6.22.942 2.453 3.666 4.229 6.884 4.229.826 0 1.622-.12 2.361-.336a.722.722 0 0 1 .598.082l1.584.926a.272.272 0 0 0 .14.047c.134 0 .24-.111.24-.247 0-.06-.023-.12-.038-.177l-.327-1.233a.582.582 0 0 1-.023-.156.49.49 0 0 1 .201-.398C23.024 18.48 24 16.82 24 14.98c0-3.21-2.931-5.837-6.656-6.088V8.89c-.135-.01-.27-.027-.407-.03zm-2.53 3.274c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.97-.982zm4.844 0c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.969-.982z"></path></svg>
<span>微信</span>
</a>
<a class="share-btn qq" href="#" onclick="sharePost(event, 'qq')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Tencent QQ</title><path d="M21.395 15.035a40 40 0 0 0-.803-2.264l-1.079-2.695c.001-.032.014-.562.014-.836C19.526 4.632 17.351 0 12 0S4.474 4.632 4.474 9.241c0 .274.013.804.014.836l-1.08 2.695a39 39 0 0 0-.802 2.264c-1.021 3.283-.69 4.643-.438 4.673.54.065 2.103-2.472 2.103-2.472 0 1.469.756 3.387 2.394 4.771-.612.188-1.363.479-1.845.835-.434.32-.379.646-.301.778.343.578 5.883.369 7.482.189 1.6.18 7.14.389 7.483-.189.078-.132.132-.458-.301-.778-.483-.356-1.233-.646-1.846-.836 1.637-1.384 2.393-3.302 2.393-4.771 0 0 1.563 2.537 2.103 2.472.251-.03.581-1.39-.438-4.673"></path></svg>
<span>QQ</span>
</a>
<a class="share-btn facebook" href="#" onclick="sharePost(event, 'facebook')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M9.101 23.691v-7.98H6.627v-3.667h2.474v-1.58c0-4.085 1.848-5.978 5.858-5.978.401 0 .955.042 1.468.103a8.68 8.68 0 0 1 1.141.195v3.325a8.623 8.623 0 0 0-.653-.036 26.805 26.805 0 0 0-.733-.009c-.707 0-1.259.096-1.675.309a1.686 1.686 0 0 0-.679.622c-.258.42-.374.995-.374 1.752v1.297h3.919l-.386 2.103-.287 1.564h-3.246v8.245C19.396 23.238 24 18.179 24 12.044c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.628 3.874 10.35 9.101 11.647Z"></path></svg>
<span>Facebook</span>
</a>
</div>
</main>
</div>
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
<script src="../script.js"></script>
<!-- The Modal -->
<div class="modal" id="about-me-modal">
<!-- Modal content -->
<div class="modal-content">
<span class="close-button">×</span>
<h2>About Me</h2>
<p>This is forliage, an undergraduate student of computer science and technology at Zhejiang University.</p>
<p><strong>Motto:</strong> People always say that time heals all wounds, but I don't believe that. Time doen't heal the pain, it just makes us get used to pain. When you lose someone, you don't really forget them; you just learn how to live on without them.</p>
<p><strong>Interests:</strong> Computer Graphics, Computer Version, Computer Animation, HPC, AIGC</p>
<p><strong>Favorite Movie:</strong> The Shawshank Redemption, Dead Poets Society, Zootopia</p>
<p><strong>Favorite Music:</strong> Blank Space, Sorega Daiji, Counting Stars, Whataya Want from Me</p>
<p><strong>Contact Information:</strong>masterforliage@gmail.com</p>
<hr/>
<h3>订阅我的博客</h3>
<p>订阅功能正在建设中，敬请期待！</p>
</div>
</div>
<script src="../modal.js"></script>
</body>
</html>