<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>ads14:并行算法 (Parallel Algorithms)</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../modal.css">
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FPDBQB4LZD"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FPDBQB4LZD');
    </script>
</head>
<body>
    <audio id="bg-music" src="../music.mp3" loop></audio>
    <button id="music-toggle" class="music-control">♪</button>
    <header>
        <h1>forliage的blog</h1>
        <nav>
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../posts.html">文章</a></li>
                <li><a href="../about.html">关于</a></li>
                <li><a href="../category.html?category=技术文章">技术文章</a></li>
                <li><a href="../category.html?category=生活随笔">生活随笔</a></li>
                <li><a href="../category.html?category=学习笔记">学习笔记</a></li>
                <li><a href="../category.html?category=心情日记">心情日记</a></li>
                <li><a href="#" id="about-me-btn">ABOUT ME</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
        <div id="sidebar-container"></div>
        <main>
            <article>
                <h1 id="ads14%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95-parallel-algorithms">ads14:并行算法 (Parallel Algorithms)</h1>
                <h3 id="1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%B6%E8%A1%8C">1. 什么是并行？</h3>
                <p>首先，我们要明确“并行”这个概念。它可以在不同的层面上体现。</p>
                <ul>
                <li>
                <p><strong>机器并行 (Machine Parallelism)</strong>: 这是硬件层面实现的并行，对程序员来说通常是透明的。</p>
                <ul>
                <li><strong>处理器并行 (Processor parallelism)</strong>: 最直观的，就是在一台机器上放置多个CPU核心。</li>
                <li><strong>流水线 (Pipelining)</strong>: 将一条指令的执行过程（如取指、译码、执行、写回）分解成多个阶段，让不同指令的不同阶段重叠执行，就像工厂里的流水线一样。</li>
                <li><strong>超长指令字 (VLIW)</strong>: 在一条指令中打包多个可以同时执行的独立操作，交给硬件的不同功能单元去并行处理。</li>
                </ul>
                </li>
                <li>
                <p><strong>并行算法 (Parallel Algorithms)</strong>: 这是我们今天关注的重点，即在算法设计层面，主动地将一个大问题分解成多个可以同时执行的子任务，并设计它们之间的协作方式。</p>
                </li>
                </ul>
                <p>为了能够严谨地设计和分析并行算法，我们需要一个理论模型，就像串行算法有RAM（随机存取机）模型一样。</p>
                <h3 id="2-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B">2. 并行计算模型</h3>
                <p>我们需要一个简洁而强大的抽象模型来描述并行算法，而不必陷入具体硬件（如缓存、网络拓扑）的泥潭。</p>
                <h4 id="21-pram-%E6%A8%A1%E5%9E%8B%E7%90%86%E6%83%B3%E5%8C%96%E7%9A%84%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA">2.1 PRAM 模型：理想化的并行计算机</h4>
                <p><strong>并行随机存取机 (Parallel Random Access Machine, PRAM)</strong> 是并行算法理论中最经典、最重要的模型。它描绘了一个理想化的并行计算环境。</p>
                <p><strong>PRAM模型的构成</strong>：</p>
                <ol>
                <li><strong>多个同步处理器</strong>: 拥有 $P_1, P_2, \ldots, P_n$ 等多个处理器。它们共享同一个全局时钟，在每个时钟周期同步执行指令。</li>
                <li><strong>一个共享内存</strong>: 所有处理器都可以访问一个无限大的共享内存空间。</li>
                <li><strong>单位时间访问</strong>: 任何处理器对共享内存的任何位置进行一次读、写或进行一次本地计算，都只花费<strong>一个单位时间</strong>。</li>
                </ol>
                <div class="mermaid">
                graph TD
                    subgraph PRAM Model
                        P1(P₁) --- M(Shared Memory);
                        P2(P₂) --- M;
                        D[...] --- M;
                        Pn(Pₙ) --- M;
                        subgraph Processors
                            P1; P2; D; Pn;
                        end
                    end
                    
                    %% Create a separate node for the note and link it with a dotted line
                    NoteBox["Unit time access<br/>(read/write/computation)"];
                    M -.- NoteBox;
                    
                    style M fill:#9f9,stroke:#333,stroke-width:2px
                    style NoteBox fill:#fefefe,stroke:#333,stroke-width:1px,stroke-dasharray: 5 5
                </div>
                <p>在PRAM模型中，我们经常使用一个特殊的关键字 <code>pardo</code> (parallel do) 来表示一个并行循环。例如：</p>
                <p><code>for Pᵢ, 1 ≤ i ≤ n pardo A(i) := B(i)</code></p>
                <p>这行代码表示，处理器 $P_1$ 执行 <code>A(1) := B(1)</code>，处理器 $P_2$ 执行 <code>A(2) := B(2)</code>，...，$P_n$ 执行 <code>A(n) := B(n)</code>，并且所有这些赋值操作都在<strong>同一个时间步</strong>内同时完成。</p>
                <h4 id="22-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%86%B2%E7%AA%81%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">2.2 内存访问冲突及其解决方案</h4>
                <p>PRAM模型的美妙之处在于它的简洁，但也带来了一个核心问题：如果多个处理器在同一时间步试图访问<strong>同一个内存单元</strong>，会发生什么？这就是<strong>访问冲突</strong>。</p>
                <p>根据如何处理读和写的冲突，PRAM模型可以分为几类：</p>
                <ol>
                <li>
                <p><strong>EREW (Exclusive-Read Exclusive-Write)</strong>: <strong>独占读，独占写</strong>。</p>
                <ul>
                <li>最严格的模型。在任何时间步，一个内存单元最多只能被一个处理器读取，也最多只能被一个处理器写入。</li>
                <li>这是最容易在硬件上实现的模型，但对算法设计限制最大。</li>
                </ul>
                </li>
                <li>
                <p><strong>CREW (Concurrent-Read Exclusive-Write)</strong>: <strong>并发读，独占写</strong>。</p>
                <ul>
                <li>允许多个处理器在同一时间步读取同一个内存单元。</li>
                <li>但仍然只允许一个处理器写入一个内存单元。</li>
                <li>这是一个非常常用且实用的模型。</li>
                </ul>
                </li>
                <li>
                <p><strong>CRCW (Concurrent-Read Concurrent-Write)</strong>: <strong>并发读，并发写</strong>。</p>
                <ul>
                <li>最强大的模型。允许多个处理器同时读，也允许多个处理器同时写同一个内存单元。</li>
                <li>并发写会带来一个新问题：如果多个处理器写入不同的值，最终写入的值是什么？为此，CRCW模型又分为几个子类来定义冲突解决规则：
                <ul>
                <li><strong>任意 (Arbitrary) 规则</strong>: 任意一个处理器成功写入，我们不知道是哪一个。</li>
                <li><strong>优先级 (Priority) 规则</strong>: 处理器ID最小（或最大）的那个成功写入。</li>
                <li><strong>公共 (Common) 规则</strong>: 只有当所有试图写入的处理器都写入<strong>相同的值</strong>时，写入才成功。否则行为未定义或失败。</li>
                <li><strong>求和 (Sum) 规则</strong>: 将所有试图写入的值相加，结果写入。</li>
                </ul>
                </li>
                </ul>
                </li>
                </ol>
                <p>这些模型的强大程度关系是：
                <strong>CRCW &gt; CREW &gt; EREW</strong>
                也就是说，为一个较弱模型（如EREW）设计的算法，可以直接在更强的模型（如CRCW）上运行。反之则不一定。</p>
                <h3 id="3-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%80%E5%B9%B6%E8%A1%8C%E6%B1%82%E5%92%8C-parallel-summation">3. 案例分析一：并行求和 (Parallel Summation)</h3>
                <p>让我们用一个简单的问题来感受并行算法的威力：计算一个数组 $A$ 中 $n$ 个元素的总和。</p>
                <p><strong>问题</strong>:</p>
                <ul>
                <li>输入: $A(1), A(2), \ldots, A(n)$</li>
                <li>输出: $S = \sum\limits_{i=1}^{n} A(i)$</li>
                </ul>
                <p>串行算法很简单，一个循环，需要 $O(n)$ 的时间。我们能用并行做得更快吗？</p>
                <p><strong>并行思路：归约 (Reduction)</strong>
                我们可以利用一棵二叉树的结构来进行归约。</p>
                <ul>
                <li><strong>第0层</strong>: 原始数据。</li>
                <li><strong>第1层</strong>: 每两个相邻的元素相加，结果存起来。</li>
                <li><strong>第2层</strong>: 对上一层的结果，每两个相邻的再相加。</li>
                <li>...依此类推，直到最后只剩下一个数，即总和。</li>
                </ul>
                <p>假设 $n=8$，这个过程如下：</p>
                <div class="mermaid">
                graph TD
                    subgraph Reduction Tree for Summation
                        %% Define all nodes first with their text content
                        A1("A(1)"); A2("A(2)"); A3("A(3)"); A4("A(4)");
                        A5("A(5)"); A6("A(6)"); A7("A(7)"); A8("A(8)");
                        B11("1~2"); B12("3~4"); B13("5~6"); B14("7~8");
                        B21("1~4"); B22("5~8");
                        B31("1~8");

                        %% Define connections
                        A1 --> B11; A2 --> B11;
                        A3 --> B12; A4 --> B12;
                        A5 --> B13; A6 --> B13;
                        A7 --> B14; A8 --> B14;
                        B11 --> B21; B12 --> B21;
                        B13 --> B22; B14 --> B22;
                        B21 --> B31; B22 --> B31;
                    end
                    
                    %% Apply styles separately to make them circles
                    %% The 'rx' and 'ry' properties create circles/ellipses
                    style A1,A2,A3,A4,A5,A6,A7,A8 fill:#fff,stroke:#333,rx:20,ry:20
                    style B11,B12,B13,B14,B21,B22,B31 fill:#fff,stroke:#333,rx:20,ry:20
                </div>
                <p>我们用 $B(h, i)$ 表示在第 $h$ 层，第 $i$ 个节点的值。
                $$B(h, i) = B(h-1, 2i-1) + B(h-1, 2i)$$</p>
                <p><strong>PRAM 伪代码</strong>:
                (假设 $n=2^k$)</p>
                <ol>
                <li><strong>初始化 (1步)</strong>:
                <code>for Pᵢ, 1 ≤ i ≤ n pardo B(0, i) := A(i)</code></li>
                <li><strong>归约循环 (log n 步)</strong>:
                <code>for h = 1 to log n</code>
                <code>for Pᵢ, 1 ≤ i ≤ n/2ʰ pardo</code>
                <code>B(h, i) := B(h-1, 2i-1) + B(h-1, 2i)</code></li>
                <li><strong>输出 (1步)</strong>:
                <code>output B(log n, 1)</code></li>
                </ol>
                <p><strong>性能分析</strong>:</p>
                <ul>
                <li><strong>时间 (Time/Depth)</strong>: 初始化需要1步，归约循环执行 $\log n$ 次，每次循环体内的 <code>pardo</code> 都是一步。所以总时间是 $$T(n) = 1 + \log n + 1 = \log n + 2 = O(\log n)$$
                <ul>
                <li>这里的 $T(n)$ 实际上是算法的<strong>深度 (Depth)</strong> 或 <strong>跨度 (Span)</strong>，代表了最长依赖链的长度。</li>
                </ul>
                </li>
                <li><strong>总操作数 (Work)</strong>: 我们总共执行了多少次加法？
                <ul>
                <li>第1层: $n/2$ 次</li>
                <li>第2层: $n/4$ 次</li>
                <li>...</li>
                <li>第 $\log n$ 层: 1 次</li>
                <li>总工作量 $$W(n) = n/2 + n/4 + \ldots + 1 = n-1$$加上初始化的 $n$ 次赋值，总工作量是 $$W(n) = 2n-1 = O(n)$$</li>
                </ul>
                </li>
                </ul>
                <p>我们用 $O(\log n)$ 的时间完成了 $O(n)$ 的工作！这是一个巨大的飞跃。</p>
                <h4 id="31-%E4%BB%8E-pram-%E5%88%B0-work-depth-%E6%A8%A1%E5%9E%8B">3.1 从 PRAM 到 Work-Depth 模型</h4>
                <p>PRAM 模型有一个问题：它总是假设我们有足够多的处理器（比如 $n$ 个）。如果处理器数量 $p &lt; n$ 怎么办？PRAM 的描述方式不够灵活。</p>
                <p>因此，我们引入一个更抽象的模型：<strong>工作-深度 (Work-Depth, WD) 模型</strong>。
                我们只关心两个核心指标：</p>
                <ul>
                <li><strong>工作量 (Work) $W(n)$</strong>: 算法执行的总操作数。</li>
                <li><strong>深度 (Depth) $T(n)$</strong>: 算法的并行时间，即最长依赖路径的长度。（在之前的幻灯片里，为了简化，也记为 $T(n)$，但含义是深度）</li>
                </ul>
                <p>WD 模型的好处是它<strong>将算法与机器解耦</strong>。一个算法的 $W(n)$ 和 $T(n)$ 是固定的，与你有多少处理器无关。</p>
                <p><strong>布伦特定理 (Brent's Theorem)</strong> 给出了WD模型和PRAM模型之间的关系：
                一个具有 $W(n)$ 工作量和 $T(n)$ 深度的算法，可以在一个有 $p$ 个处理器的PRAM上，于 $O(W(n)/p + T(n))$ 时间内完成。</p>
                <p><strong>直观理解</strong>:</p>
                <ul>
                <li>$W(n)/p$: 这是将所有工作平均分配给 $p$ 个处理器所需要的理想时间。</li>
                <li>$T(n)$: 这是算法固有的串行瓶颈，即使有无限多的处理器也无法逾越。</li>
                <li>实际运行时间由这两者共同决定。</li>
                </ul>
                <p>对于我们的求和算法：$W(n) = O(n)$, $T(n) = O(\log n)$。
                在有 $p$ 个处理器的机器上，运行时间为 $O(n/p + \log n)$。
                这个结果告诉我们，即使我们只有很少的处理器，我们依然可以通过并行获得加速。当 $p = n/\log n$ 时，时间为 $O(\log n)$，我们获得了最优的加速效果。</p>
                <h3 id="4-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%BA%8C%E5%89%8D%E7%BC%80%E5%92%8C-prefix-sums--scan">4. 案例分析二：前缀和 (Prefix-Sums / Scan)</h3>
                <p>前缀和是一个更强大、更通用的并行计算原语。</p>
                <p><strong>问题</strong>:</p>
                <ul>
                <li>输入: $A(1), A(2), \ldots, A(n)$</li>
                <li>输出: 一个数组 $C$，其中 $C(i) = \sum\limits_{k=1}^{i} A(k)$</li>
                </ul>
                <p>例如，输入 <code>[1, 1, 2, 3, 6, 2, 0, 1]</code>，输出 <code>[1, 2, 4, 7, 13, 15, 15, 16]</code>。</p>
                <p>串行算法很简单，一个循环，$O(n)$ 时间。并行算法则需要更精巧的设计，通常使用<strong>平衡二叉树</strong>分两步完成。</p>
                <p><strong>算法步骤</strong>:</p>
                <p><strong>第一步：上行归约 (Up-Sweep / Reduction)</strong></p>
                <ul>
                <li>和并行求和完全一样。我们从叶子节点开始，向上计算每个内部节点所代表的子树的<strong>总和</strong>。我们将这些子树和存储在节点中（即 $B(h,i)$）。</li>
                <li>这一步结束后，树的每个节点都知道它“管辖”范围内的所有叶子节点的和。</li>
                <li>$$W(n) = O(n)$$ $$T(n) = O(\log n)$$</li>
                </ul>
                <p><strong>第二步：下行传递 (Down-Sweep / Scan)</strong></p>
                <ul>
                <li>现在我们从根节点开始向下传递信息，计算每个节点的前缀和。</li>
                <li>我们给根节点一个初始前缀和 0。</li>
                <li>对于树中的任意一个节点，当它从父节点接收到一个前缀和 <code>prefix_from_parent</code> 时：
                <ul>
                <li>它将 <code>prefix_from_parent</code> 传递给它的<strong>左孩子</strong>。</li>
                <li>它将 <code>prefix_from_parent</code> <strong>加上</strong> 它左孩子子树的总和（这在第一步已经算好了），然后将这个新值传递给它的<strong>右孩子</strong>。</li>
                </ul>
                </li>
                <li>叶子节点 $A(i)$ 接收到父节点传来的前缀和后，将其与自身的值相加，就得到了最终的前缀和 $C(i)$。</li>
                </ul>
                <p><strong>图解 (n=8)</strong>:</p>
                <div class="mermaid">
                graph TD
                    subgraph Prefix Sum Tree
                        direction TB
                        
                        %% Node Format: "p: prefix_from_parent | s: subtree_sum"
                        R("p: 0<br/>s: 16") --> N21("p: 0<br/>s: 7") & N22("p: 7<br/>s: 9");

                        N21 --> N11("p: 0<br/>s: 2") & N12("p: 2<br/>s: 5");
                        N22 --> N13("p: 7<br/>s: 8") & N14("p: 15<br/>s: 1");
                        
                        N11 --> L1("A(1)=1<br/>C(1)=1");
                        N11 --> L2("A(2)=1<br/>C(2)=2");
                        N12 --> L3("A(3)=2<br/>C(3)=4");
                        N12 --> L4("A(4)=3<br/>C(4)=7");
                        N13 --> L5("A(5)=6<br/>C(5)=13");
                        N13 --> L6("A(6)=2<br/>C(6)=15");
                        N14 --> L7("A(7)=0<br/>C(7)=15");
                        N14 --> L8("A(8)=1<br/>C(8)=16");
                    end
                    
                    style R,N21,N22,N11,N12,N13,N14 fill:#f99,stroke:#333
                </div>
                <ul>
                <li><strong>上行</strong>: 计算所有节点的 <code>s</code> 值 (subtree_sum)。</li>
                <li><strong>下行</strong>:
                <ul>
                <li>根节点 R 的 <code>p</code> (prefix_from_parent) 是 0。</li>
                <li>R 把 <code>p=0</code> 传给左孩子 N21。</li>
                <li>R 把 <code>p=0 + s(N21) = 0 + 7 = 7</code> 传给右孩子 N22。</li>
                <li>N21 把 <code>p=0</code> 传给左孩子 N11。</li>
                <li>N21 把 <code>p=0 + s(N11) = 0 + 2 = 2</code> 传给右孩子 N12。</li>
                <li>...以此类推。</li>
                <li>叶子节点 L1(A(1)) 从 N11 收到 <code>p=0</code>，最终结果是 <code>p + A(1) = 0+1=1</code>。</li>
                <li>叶子节点 L3(A(3)) 从 N12 收到 <code>p=2</code>，最终结果是 <code>p + A(3) = 2+2=4</code>。</li>
                </ul>
                </li>
                </ul>
                <p><strong>性能分析</strong>:</p>
                <ul>
                <li>两步都是在平衡二叉树上进行，每一步的深度都是 $O(\log n)$。</li>
                <li>总深度: $T(n) = O(\log n)$。</li>
                <li>每一步都在树的 $O(n)$ 个节点上执行常数次操作。</li>
                <li>总工作量: $W(n) = O(n)$。</li>
                </ul>
                <p>前缀和是一个极其有用的构建模块，可以用来解决很多问题，如数组打包、多项式求值等。</p>
                <h3 id="5-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%89%E5%B9%B6%E8%A1%8C%E5%BD%92%E5%B9%B6-parallel-merging">5. 案例分析三：并行归并 (Parallel Merging)</h3>
                <p><strong>问题</strong>: 将两个已排序的非递减数组 $A$ (大小为 $n$) 和 $B$ (大小为 $m$) 合并成一个有序数组 $C$。</p>
                <p>串行归并算法是 $O(n+m)$ 的。我们可以做得更快吗？</p>
                <p><strong>核心技术：划分 (Partitioning) 与 排序 (Ranking)</strong></p>
                <p>并行归并的关键思想是，对于 $A$ 中的每个元素 $A(i)$，如果我们知道它在最终数组 $C$ 中的正确位置，我们就可以用一个 <code>pardo</code> 循环，一步到位地把它放到那个位置。</p>
                <p>$A(i)$ 在 $C$ 中的位置是多少？是它自己的索引 $i$ 加上<strong>在数组 $B$ 中有多少个元素比它小</strong>。
                我们把“在数组 $X$ 中比值 $v$ 小的元素个数”定义为 <strong>RANK($v$, X)</strong>。</p>
                <p>那么，$A(i)$ 在 $C$ 中的最终位置是 <code>i + RANK(A(i), B)</code>。
                同理，$B(j)$ 在 $C$ 中的最终位置是 <code>j + RANK(B(j), A)</code>。</p>
                <p><strong>所以，归并问题被转化为了一个Ranking问题</strong>。</p>
                <p><strong>Ranking问题</strong>:</p>
                <ol>
                <li>对每个 $A(i)$，计算 <code>RANK(A(i), B)</code>。</li>
                <li>对每个 $B(j)$，计算 <code>RANK(B(j), A)</code>。</li>
                </ol>
                <p>一旦我们解决了Ranking问题，归并只需要 $O(1)$ 的并行时间：
                <code>for Pᵢ, 1 ≤ i ≤ n pardo C(i + RANK(A(i), B)) := A(i)</code>
                <code>for Pᵢ, 1 ≤ i ≤ m pardo C(j + RANK(B(j), A)) := B(j)</code></p>
                <p><strong>如何并行计算RANK？</strong></p>
                <ul>
                <li>
                <p><strong>方法一: 并行二分查找</strong>
                对于每个 $A(i)$，我们可以在有序数组 $B$ 中使用二分查找来找到比它小的元素个数。</p>
                <ul>
                <li>一次二分查找需要 $O(\log m)$ 时间。</li>
                <li>我们可以并行地为所有 $n$ 个 $A$ 的元素执行二分查找。</li>
                <li><strong>深度</strong>: $T(n) = O(\log m)$。</li>
                <li><strong>工作量</strong>: $W(n) = O(n \log m)$。</li>
                <li>同样，计算 $B$ 在 $A$ 中的RANK，工作量是 $O(m \log n)$。</li>
                <li>总工作量是 $O((n+m)\log(n+m))$。这比串行的 $O(n+m)$ 要差，我们称之为<strong>工作非效率 (work-inefficient)</strong>。</li>
                </ul>
                </li>
                <li>
                <p><strong>方法二: 划分思想 (更优)</strong>
                为了达到工作效率，我们需要更聪明的方法。</p>
                <ol>
                <li><strong>划分(Partitioning)</strong>:
                <ul>
                <li>我们不为每个元素计算RANK，而是只为一些“代表”元素（pivots）计算。</li>
                <li>假设 $n=m$，我们从 $A$ 中每隔 $\log n$ 个元素选一个，共选出 $p=n/\log n$ 个代表。</li>
                <li>我们用并行二分查找，计算这 $p$ 个代表在 $B$ 中的RANK。</li>
                <li>这些代表将数组 $B$ 也划分成了 $p$ 个块。</li>
                </ul>
                </li>
                <li><strong>并发工作(Actual Work)</strong>:
                <ul>
                <li>现在，原问题被分解成了 $2p$ 个更小的、独立的归并子问题。例如，$A$ 的第一个块和 $B$ 的第一个块进行归并，等等。</li>
                <li>这些小的子问题可以并行地用串行归并算法解决。</li>
                <li>通过精心选择块的大小，可以保证每个子问题的大小都是 $O(\log n)$。</li>
                </ul>
                </li>
                </ol>
                </li>
                </ul>
                <p><strong>性能分析 (方法二)</strong>:</p>
                <ul>
                <li><strong>阶段1 (划分)</strong>: $p=n/\log n$ 次二分查找，并行执行。
                <ul>
                <li>$T(n) = O(\log n)$</li>
                <li>$W(n) = p \cdot O(\log n) = (n/\log n) \cdot O(\log n) = O(n)$</li>
                </ul>
                </li>
                <li><strong>阶段2 (实际归并)</strong>: $2p$ 个 $O(\log n)$ 大小的子问题。
                <ul>
                <li>$T(n) = O(\log n)$ (因为每个子问题串行解决)</li>
                <li>$W(n) = 2p \cdot O(\log n) = 2(n/\log n) \cdot O(\log n) = O(n)$</li>
                </ul>
                </li>
                <li><strong>总计</strong>: $T(n) = O(\log n)$, $W(n) = O(n)$。这是一个<strong>工作效率</strong>的并行归并算法！</li>
                </ul>
                <h3 id="6-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E5%9B%9B%E5%B9%B6%E8%A1%8C%E6%89%BE%E6%9C%80%E5%A4%A7%E5%80%BC-maximum-finding">6. 案例分析四：并行找最大值 (Maximum Finding)</h3>
                <p><strong>问题</strong>: 在 $n$ 个元素中找到最大值。</p>
                <h4 id="%E6%96%B9%E6%B3%95%E4%B8%80%E7%B1%BB%E4%BC%BC%E6%B1%82%E5%92%8C%E7%9A%84%E5%BD%92%E7%BA%A6">方法一：类似求和的归约</h4>
                <ul>
                <li>将求和算法中的 <code>+</code> 操作符换成 <code>max</code> 操作符。</li>
                <li>性能完全相同：$T(n) = O(\log n)$, $W(n) = O(n)$。</li>
                <li>这是一个非常好的、实用的算法。</li>
                </ul>
                <h4 id="%E6%96%B9%E6%B3%95%E4%BA%8C%E5%85%A8%E5%AF%B9%E6%AF%94%E8%BE%83-all-pairs-comparison">方法二：全对比较 (All-pairs comparison)</h4>
                <ul>
                <li>这是一个更激进的并行思路。</li>
                <li>我们用 $n^2$ 个处理器，比较所有可能的元素对 $(A(i), A(j))$。</li>
                <li>我们用一个辅助布尔数组 <code>is_max</code>，初始都为 <code>true</code>。</li>
                <li><code>for i and j, 1 ≤ i, j ≤ n pardo</code>
                <code>if A(i) &lt; A(j) then is_max[i] := false</code></li>
                <li>最后，<code>is_max</code> 数组中唯一为 <code>true</code> 的那个位置对应的元素就是最大值。</li>
                </ul>
                <p><strong>性能分析</strong>:</p>
                <ul>
                <li><strong>深度</strong>: $T(n) = O(1)$。所有比较和赋值都在一步内完成！</li>
                <li><strong>工作量</strong>: $W(n) = O(n^2)$。</li>
                <li>这个算法速度极快，但工作量巨大，非常浪费资源。</li>
                </ul>
                <p><strong>Discussion 21: 如何解决访问冲突？</strong>
                在上面的 <code>is_max[i] := false</code> 步骤中，可能会发生并发写。例如，如果 $A(k)$ 不是最大值，那么所有比 $A(k)$ 大的 $A(j)$ 都会试图同时将 <code>is_max[k]</code> 设置为 <code>false</code>。</p>
                <ul>
                <li>这是一个典型的<strong>并发写</strong>场景，需要 <strong>CRCW PRAM</strong> 模型。</li>
                <li>由于所有处理器都试图写入相同的值 (<code>false</code>)，<strong>公共 (Common) CRCW</strong> 规则就足够了。只要有一个处理器想写 <code>false</code>，结果就是 <code>false</code>，这符合我们的算法逻辑。</li>
                <li>因此，这个 $O(1)$ 的算法需要在 CRCW PRAM 上才能正确运行。</li>
                </ul>
                <h4 id="%E6%96%B9%E6%B3%95%E4%B8%89%E5%8F%8C%E5%AF%B9%E6%95%B0%E8%8C%83%E5%BC%8F-doubly-logarithmic-paradigm">方法三：双对数范式 (Doubly-logarithmic Paradigm)</h4>
                <p>这是一个更高级的递归思想，旨在进一步降低并行时间。</p>
                <ul>
                <li><strong>思路</strong>: 将大小为 $n$ 的问题，分解为 $\sqrt{n}$ 个大小为 $\sqrt{n}$ 的子问题。</li>
                <li>
                <ol>
                <li>把数组 $A$ 划分成 $\sqrt{n}$ 个块，每块大小为 $\sqrt{n}$。</li>
                </ol>
                </li>
                <li>
                <ol start="2">
                <li><strong>递归地</strong>在每个块中并行找到最大值。</li>
                </ol>
                </li>
                <li>
                <ol start="3">
                <li>现在我们有了 $\sqrt{n}$ 个候选最大值，再在这些值中找到最终的最大值。</li>
                </ol>
                </li>
                </ul>
                <p><strong>性能分析</strong>:</p>
                <ul>
                <li>时间递推关系: $T(n) = T(\sqrt{n}) + O(1)$ (递归调用 + 找 $\sqrt{n}$ 个元素的最大值)
                <ul>
                <li>解这个递推方程，得到 $T(n) = O(\log \log n)$。这是一个非常慢增长的函数！</li>
                </ul>
                </li>
                <li>工作量递推关系: $W(n) = \sqrt{n} \cdot W(\sqrt{n}) + O(n)$ (递归调用 + 收集结果)
                <ul>
                <li>解这个递推方程，得到 $W(n) = O(n \log \log n)$。工作量略有增加，但时间大大减少。</li>
                </ul>
                </li>
                </ul>
                <h4 id="%E6%96%B9%E6%B3%95%E5%9B%9B%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7-random-sampling">方法四：随机采样 (Random Sampling)</h4>
                <p>这是并行算法与我们上一讲随机算法的完美结合，可以获得惊人的理论性能。</p>
                <ul>
                <li><strong>思路</strong>:
                <ol>
                <li>从 $n$ 个元素中随机选出 $n^{1/8}$ 个元素作为一个样本。</li>
                <li>在样本中并行找到最大值 $M$。</li>
                <li>用这个样本最大值 $M$ 作为“过滤器”，遍历整个数组，找出所有比 $M$ 大的元素，形成一个“候选集”。</li>
                <li>可以证明， باحتمال عالٍ جدًا (with very high probability)，这个候选集的大小会急剧缩小。</li>
                <li>对这个小得多的候选集，重复此过程或使用其他算法找到最终最大值。</li>
                </ol>
                </li>
                </ul>
                <p><strong>性能分析</strong>:</p>
                <ul>
                <li>在<strong>任意 (Arbitrary) CRCW PRAM</strong> 模型上，可以设计出一种随机采样算法，它能<strong>以极高的概率</strong>在以下复杂度内找到最大值：
                <ul>
                <li><strong>深度</strong>: $T(n) = O(1)$</li>
                <li><strong>工作量</strong>: $W(n) = O(n)$</li>
                </ul>
                </li>
                <li>这是理论上能达到的最佳结果：常数时间，线性工作量！它结合了并行、并发写和随机化的力量。</li>
                </ul>
                <h3 id="7-%E6%8B%93%E5%B1%95mapreduce-%E6%A8%A1%E5%9E%8B">7. 拓展：MapReduce 模型</h3>
                <p>到目前为止，我们讨论的都是理论上的 PRAM 模型。在工业界，处理大规模数据最成功的并行编程模型之一是 Google 提出的 <strong>MapReduce</strong>。</p>
                <p>MapReduce 将复杂的并行程序抽象为两个简单的函数：<code>Map</code> 和 <code>Reduce</code>。</p>
                <ul>
                <li><strong>Map 阶段</strong>:
                <ul>
                <li>输入是 (key, value) 对。</li>
                <li>Mapper 对每个输入对应用一个函数，产生零个或多个中间的 (key', value') 对。</li>
                <li>所有的 Map 操作是<strong>完全并行</strong>的。</li>
                </ul>
                </li>
                <li><strong>Shuffle &amp; Sort 阶段 (框架负责)</strong>:
                <ul>
                <li>框架将所有 Map 的输出收集起来，并按照中间键 <code>key'</code>进行分组。</li>
                <li>所有具有相同 <code>key'</code> 的 <code>value'</code> 被合并到一个列表中。</li>
                </ul>
                </li>
                <li><strong>Reduce 阶段</strong>:
                <ul>
                <li>输入是 (key', list of values')。</li>
                <li>Reducer 对每个键的列表应用一个函数，产生最终的输出。</li>
                <li>所有的 Reduce 操作也是<strong>并行</strong>的（不同键的 Reduce 任务可以并行）。</li>
                </ul>
                </li>
                </ul>
                <p><strong>示例：词频统计 (Word Count)</strong></p>
                <div class="mermaid">
                graph TD
                    subgraph Map Phase
                        D1("doc1: 'hello world'") --> M1(Map);
                        D2("doc2: 'hello class'") --> M2(Map);
                    end

                    M1 --> S1("('hello', 1)");
                    M1 --> S2("('world', 1)");
                    M2 --> S3("('hello', 1)");
                    M2 --> S4("('class', 1)");

                    subgraph Shuffle & Sort Phase
                        S1 & S3 --> G1("('hello', [1, 1])");
                        S2 --> G2("('world', [1])");
                        S4 --> G3("('class', [1])");
                    end

                    subgraph Reduce Phase
                        G1 --> R1(Reduce) --> O1("('hello', 2)");
                        G2 --> R2(Reduce) --> O2("('world', 1)");
                        G3 --> R3(Reduce) --> O3("('class', 1)");
                    end
                </div>
                <p>MapReduce 的巨大成功在于它提供了一个简单的高层抽象，将程序员从并行编程的复杂细节（如同步、通信、容错）中解放出来，让他们可以专注于业务逻辑本身。</p>
            </article>
        </main>
    </div>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
    <script src="../script.js"></script>
    <!-- The Modal -->
    <div id="about-me-modal" class="modal">
      <!-- Modal content -->
      <div class="modal-content">
        <span class="close-button">&times;</span>
        <h2>About Me</h2>
        <p>This is forliage, an undergraduate student of computer science and technology at Zhejiang University.</p>
        <p><strong>Motto:</strong> People always say that time heals all wounds, but I don't believe that. Time doen't heal the pain, it just makes us get used to pain. When you lose someone, you don't really forget them; you just learn how to live on without them.</p>
        <p><strong>Interests:</strong> Computer Graphics, Computer Version, Computer Animation, HPC, AIGC</p>
        <p><strong>Favorite Movie:</strong> The Shawshank Redemption, Dead Poets Society, Zootopia</p>
        <p><strong>Favorite Music:</strong> Blank Space, Sorega Daiji, Counting Stars, Whataya Want from Me</p>
        <p><strong>Contact Information:</strong>masterforliage@gmail.com</p>
        <hr>
        <h3>订阅我的博客</h3>
        <p>订阅功能正在建设中，敬请期待！</p>
      </div>
    </div>
    <script src="../modal.js"></script>
</body>
</html>