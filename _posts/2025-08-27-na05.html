<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>数值分析05:线性系统迭代法及其收敛性理论</title>
    <link rel="stylesheet" href="../style.css">
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
</head>
<body>
    <audio id="bg-music" src="../music.mp3" loop></audio>
    <button id="music-toggle" class="music-control">♪</button>
    <header>
        <h1>forliage的blog</h1>
        <nav>
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../posts.html">文章</a></li>
                <li><a href="../about.html">关于</a></li>
                <li><a href="../category.html?category=技术文章">技术文章</a></li>
                <li><a href="../category.html?category=生活随笔">生活随笔</a></li>
                <li><a href="../category.html?category=学习笔记">学习笔记</a></li>
                <li><a href="../category.html?category=心情日记">心情日记</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
        <div id="sidebar-container"></div>
        <main>
            <article>
                <h1 id="%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%9005%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F%E8%BF%AD%E4%BB%A3%E6%B3%95%E5%8F%8A%E5%85%B6%E6%94%B6%E6%95%9B%E6%80%A7%E7%90%86%E8%AE%BA">数值分析05:线性系统迭代法及其收敛性理论</h1>
                <h3 id="%E5%BC%95%E8%A8%80%E4%B8%BA%E4%BD%95%E8%BF%AD%E4%BB%A3%E5%A6%82%E4%BD%95%E8%BF%AD%E4%BB%A3"><strong>引言：为何迭代？如何迭代？</strong></h3>
                <p>在上一讲中，我们已经初步接触了用迭代法求解线性系统的思想。今天，我们将正式、系统地深入这个主题。</p>
                <p>让我们再次回到那个核心问题：我们已经有了稳定可靠的、经过主元法改进的高斯消元法这样的<strong>直接法</strong>，为什么还需要发展<strong>迭代法</strong>？</p>
                <p>答案主要在于<strong>处理超大规模稀疏系统</strong>时的巨大优势。想象一下，在天气预报、飞机设计或材料科学中，我们需要求解的线性方程组的维度 $n$ 可能高达数百万。</p>
                <ul>
                <li><strong>直接法 ($O(n^3)$):</strong> 即使是现代超级计算机，一个百万维度的稠密系统的 $10^{18}$ 次浮点运算也是一个巨大的挑战。</li>
                <li><strong>存储：</strong> 存储一个百万乘百万的稠密矩阵需要 $10^{12}$ 个浮点数，约等于8000GB的内存，这通常是不现实的。</li>
                <li><strong>稀疏性破坏：</strong> 更关键的是，这些系统通常是<strong>稀疏</strong>的，例如，每行只有5-10个非零元素。直接法中的行变换会引入大量非零元（称为<strong>Fill-in</strong>），彻底破坏这种宝贵的稀疏结构，导致内存需求激增。</li>
                </ul>
                <p><strong>迭代法</strong>正是为了克服这些困难而生。它有两大吸引力：</p>
                <ol>
                <li><strong>内存友好：</strong> 迭代过程通常只涉及矩阵和向量的乘法 ($A\mathbf{x}^{(k)}$)，可以完美地利用矩阵的稀疏性，存储需求仅为 $O(\text{nnz})$（非零元数量），远小于 $O(n^2)$。</li>
                <li><strong>可控精度：</strong> 我们可以根据实际需求设定容差，迭代到满足精度要求即可停止，无需进行完整的 $O(n^3)$ 运算。对于某些问题，一个中等精度的解可能就足够了。</li>
                </ol>
                <p>上一讲我们已经建立了迭代法的基本框架：将 $A\mathbf{x}=\mathbf{b}$ 转化为等价的不动点形式 $\mathbf{x} = T\mathbf{x}+\mathbf{c}$，然后进行迭代 $\mathbf{x}^{(k+1)}=T\mathbf{x}^{(k)}+\mathbf{c}$。</p>
                <p>今天，我们将详细探讨以下几个问题：</p>
                <ol>
                <li><strong>经典迭代法：</strong> Jacobi和Gauss-Seidel方法的具体实现和对比。</li>
                <li><strong>收敛性理论：</strong> 迭代法到底在什么条件下才收敛？这是本讲的理论核心。</li>
                <li><strong>加速收敛：</strong> 如何改进Gauss-Seidel方法，得到收敛更快的SOR方法？</li>
                <li><strong>实践分析：</strong> 如何通过分析迭代矩阵的特征值来判断收敛性并找到最优参数？</li>
                </ol>
                <h3 id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E7%BB%8F%E5%85%B8%E8%BF%AD%E4%BB%A3%E6%A0%BC%E5%BC%8F"><strong>第一部分：经典迭代格式</strong></h3>
                <p>我们再次使用矩阵分裂的思想 $A=D-L-U$ 来构造迭代格式。</p>
                <h4 id="731-jacobi-%E8%BF%AD%E4%BB%A3%E6%B3%95"><strong>7.3.1 Jacobi 迭代法</strong></h4>
                <p><strong>推导：</strong>
                $$A\mathbf{x} = \mathbf{b} \implies (D-L-U)\mathbf{x} = \mathbf{b} \implies D\mathbf{x} = (L+U)\mathbf{x} + \mathbf{b}$$
                假设所有对角元 $a_{ii} \neq 0$，则 $D$ 可逆：
                $$\mathbf{x} = D^{-1}(L+U)\mathbf{x} + D^{-1}\mathbf{b}$$</p>
                <p><strong>Jacobi 迭代格式：</strong>
                $$\mathbf{x}^{(k+1)} = \underbrace{D^{-1}(L+U)}_{T_J} \mathbf{x}^{(k)} + \underbrace{D^{-1}\mathbf{b}}_{\mathbf{c}_J}$$</p>
                <p><strong>分量形式 (Component-wise Form):</strong>
                $$x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j=1, j \neq i}^{n} a_{ij}x_j^{(k)} \right), \quad \text{for } i=1, \dots, n$$</p>
                <p><strong>实现要点：</strong></p>
                <ul>
                <li><strong>两个向量存储：</strong> 从分量形式可以看出，为了计算新的向量 $\mathbf{x}^{(k+1)}$ 的每一个分量，我们都需要<strong>完整的旧向量 $\mathbf{x}^{(k)}$</strong>。因此，在实现时，我们需要两个数组，一个用于存储<code>x_old</code> ($\mathbf{x}^{(k)}$)，一个用于存储<code>x_new</code> ($\mathbf{x}^{(k+1)}$)。在一轮迭代完全结束后，再将<code>x_new</code>复制给<code>x_old</code>。</li>
                <li><strong>并行性：</strong> 各个分量 $x_i^{(k+1)}$ 的计算是<strong>相互独立</strong>的，可以完美地分配给不同的处理器并行计算，这在高性能计算中是一个巨大优势。</li>
                </ul>
                <h4 id="732-gauss-seidel-%E8%BF%AD%E4%BB%A3%E6%B3%95"><strong>7.3.2 Gauss-Seidel 迭代法</strong></h4>
                <p><strong>思想：</strong> &quot;A bit wasteful, isn't it?&quot;Jacobi方法在计算 $x_i^{(k+1)}$ 时，没有利用已经算出的、更新的 $x_1^{(k+1)}, \dots, x_{i-1}^{(k+1)}$。Gauss-Seidel方法修正了这一点。</p>
                <p><strong>推导：</strong>
                $$(D-L-U)\mathbf{x} = \mathbf{b} \implies (D-L)\mathbf{x} = U\mathbf{x} + \mathbf{b}$$
                我们将所有包含“新”分量的项移到左边，“旧”分量的项留在右边。</p>
                <p><strong>Gauss-Seidel 迭代格式：</strong>
                $$\mathbf{x}^{(k+1)} = \underbrace{(D-L)^{-1}U}_{T_{GS}} \mathbf{x}^{(k)} + \underbrace{(D-L)^{-1}\mathbf{b}}_{\mathbf{c}_{GS}}$$</p>
                <p><strong>分量形式 (Component-wise Form):</strong>
                $$x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij}x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij}x_j^{(k)} \right), \quad \text{for } i=1, \dots, n$$</p>
                <p><strong>实现要点：</strong></p>
                <ul>
                <li><strong>一个向量存储：</strong> 从分量形式可以看出，我们可以用<strong>一个数组</strong>原地更新。在计算 $x_i^{(k+1)}$ 时，数组中前 $i-1$ 个元素已经是本次迭代更新过的值，后 $n-i$ 个元素还是上一次迭代的值。这节省了一半的内存。</li>
                <li><strong>串行性：</strong> $x_i^{(k+1)}$ 的计算依赖于 $x_{i-1}^{(k+1)}$，因此必须按顺序 $i=1, 2, \dots, n$ 进行，不适合直接并行化。</li>
                </ul>
                <p><strong>收敛性对比：</strong></p>
                <ul>
                <li>直观上，Gauss-Seidel使用了最新信息，人们期望它收敛更快。在很多情况下（例如对于严格对角占优或对称正定矩阵），确实如此。</li>
                <li>然而，“Neither of the methods are always convergent. And more, there are cases in which Jacobi method fails while Gauss-Seidel is convergent, and vice-versa.” 存在Jacobi收敛而Gauss-Seidel发散的例子，反之亦然。它们的收敛性取决于迭代矩阵的谱半径，而 $\rho(T_J)$ 和 $\rho(T_{GS})$ 之间没有绝对的大小关系。</li>
                </ul>
                <h3 id="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%94%B6%E6%95%9B%E6%80%A7%E7%90%86%E8%AE%BA"><strong>第二部分：收敛性理论</strong></h3>
                <p>这是理解所有迭代法行为的核心。</p>
                <h4 id="721-%E8%B0%B1%E5%8D%8A%E5%BE%84%E4%B8%8E%E7%9F%A9%E9%98%B5%E6%94%B6%E6%95%9B"><strong>7.2.1 谱半径与矩阵收敛</strong></h4>
                <p>我们已经知道，迭代法 $\mathbf{x}^{(k+1)} = T\mathbf{x}^{(k)} + \mathbf{c}$ 收敛的充要条件是 $\lim_{k\to\infty} T^k = O$ (零矩阵)。满足这个条件的矩阵被称为<strong>收敛矩阵 (Convergent Matrix)</strong>。</p>
                <p><strong>定义 (谱半径 - Spectral Radius):</strong>
                一个矩阵 $A$ 的谱半径 $\rho(A)$ 是其所有特征值绝对值的最大值。
                $$\rho(A) = \max {|\lambda| : \lambda \text{ is an eigenvalue of } A}$$</p>
                <p><strong>定理 (收敛矩阵的等价条件):</strong>
                对于一个 $n \times n$ 矩阵 $A$，以下陈述是等价的：</p>
                <ol>
                <li>$A$ 是一个收敛矩阵 (即 $\lim_{k\to\infty} A^k = O$)。</li>
                <li>对于<strong>某个</strong>自然矩阵范数，$\lim_{k\to\infty} |A^k| = 0$。</li>
                <li>对于<strong>所有</strong>自然矩阵范数，$\lim_{k\to\infty} |A^k| = 0$。</li>
                <li>$A$ 的谱半径<strong>严格小于1</strong>，即 $\rho(A) < 1$。</li>
                <li>对于任意向量 $\mathbf{x}$，都有 $\lim_{k\to\infty} A^k \mathbf{x} = \mathbf{0}$。</li>
                </ol>
                <p>这个定理是线性迭代法理论的基石。它告诉我们，判断一个迭代法是否收敛，最终归结为计算其迭代矩阵的谱半径。</p>
                <p><strong>谱半径与范数的关系：</strong>
                <strong>定理：</strong> 对于任意自然矩阵范数 $|\cdot|$ 和任意矩阵 $A$，都有 $\rho(A) \le |A|$。</p>
                <ul>
                <li><strong>证明思路：</strong> 设 $\lambda$ 是 $A$ 的一个特征值，$\mathbf{v}$ 是对应的特征向量。则 $A\mathbf{v} = \lambda\mathbf{v}$。
                $|\lambda||\mathbf{v}| = |\lambda\mathbf{v}| = |A\mathbf{v}| \le |A||\mathbf{v}|$。
                由于 $\mathbf{v}$ 非零，两边消去 $|\mathbf{v}|$ 得到 $|\lambda| \le |A|$。这对所有特征值都成立，所以 $\rho(A) = \max|\lambda| \le |A|$。</li>
                </ul>
                <h4 id="722-%E6%94%B6%E6%95%9B%E6%80%A7%E5%AE%9A%E7%90%86"><strong>7.2.2 收敛性定理</strong></h4>
                <p>结合以上理论，我们可以给出迭代法收敛性的最终定理。</p>
                <p><strong>定理 (线性迭代法收敛性):</strong>
                对于任意初始向量 $\mathbf{x}^{(0)} \in \mathbb{R}^n$，由 $\mathbf{x}^{(k+1)} = T\mathbf{x}^{(k)} + \mathbf{c}$ 生成的序列收敛到方程 $\mathbf{x}=T\mathbf{x}+\mathbf{c}$ 的唯一解的<strong>充分必要条件</strong>是 $\rho(T) < 1$。</p>
                <p><strong>证明思路 (简述):</strong></p>
                <ul>
                <li>($\Leftarrow$) <strong>如果 $\rho(T)<1$，则收敛：</strong>
                误差关系为 $\mathbf{e}^{(k)} = T^k \mathbf{e}^{(0)}$。因为 $\rho(T)<1$，所以 $T$ 是收敛矩阵，$\lim_{k\to\infty} T^k = O$。因此 $\lim_{k\to\infty} \mathbf{e}^{(k)} = \mathbf{0}$。</li>
                <li>($\Rightarrow$) <strong>如果对任意初值都收敛，则 $\rho(T)<1$：</strong>
                (反证法) 假设 $\rho(T) \ge 1$。那么存在一个特征值 $\lambda$ 使得 $|\lambda| \ge 1$。设其对应的特征向量为 $\mathbf{v}$。如果我们选择初始误差 $\mathbf{e}^{(0)} = \mathbf{v}$，那么 $\mathbf{e}^{(k)} = T^k \mathbf{v} = \lambda^k \mathbf{v}$。
                $|\mathbf{e}^{(k)}| = |\lambda|^k |\mathbf{v}|$。由于 $|\lambda| \ge 1$，这个误差范数不会趋于0，所以序列不收敛。这与“对任意初值都收敛”的前提矛盾。</li>
                </ul>
                <p><strong>实用的充分条件：</strong>
                计算谱半径通常很困难。一个更容易验证的<strong>充分条件</strong>是：
                <strong>如果存在某个自然矩阵范数使得 $|T| < 1$，则迭代法保证收敛。</strong>
                例如，对于Jacobi法，我们可以计算 $|T_J|_\infty = |D^{-1}(L+U)|_\infty$。如果这个值小于1，Jacobi就收敛。</p>
                <p><strong>定理 (对角占优保证收敛):</strong>
                如果矩阵 $A$ 是<strong>严格对角占优</strong>的，那么 Jacobi 和 Gauss-Seidel 方法都收敛。</p>
                <ul>
                <li><strong>证明思路 (以Jacobi为例):</strong>
                对于严格对角占优矩阵，可以证明其Jacobi迭代矩阵 $T_J$ 的无穷范数满足 $|T_J|_\infty = \max_i \sum_{j \neq i} \frac{|a_{ij}|}{|a_{ii}|} < 1$。根据范数收敛准则，Jacobi法收敛。Gauss-Seidel的证明更复杂一些，但结论相同。</li>
                </ul>
                <h4 id="733-sor-%E6%96%B9%E6%B3%95%E5%8A%A0%E9%80%9F-gauss-seidel"><strong>7.3.3 SOR 方法：加速 Gauss-Seidel</strong></h4>
                <p><strong>思想：</strong> 从另一个角度看待Gauss-Seidel。
                Gauss-Seidel的第 $i$ 步实际上是先计算一个Jacobi式的中间值 $\tilde{x}_i^{(k+1)}$，然后立即用它更新 $x_i^{(k)}$。我们可以看作是 $x_i^{(k)}$ 加上一个修正量。
                令 $r_i^{(k)} = b_i - \sum_{j=1}^n a_{ij}x_j^{(k)}$ 是第 $k$ 步的残差向量的第 $i$ 个分量。
                Gauss-Seidel的更新可以写成：$x_i^{(k+1)} = x_i^{(k)} + \frac{r_i^{(k)}}{a_{ii}}$ （这里 $r_i$ 内部混合了新旧分量）。</p>
                <p><strong>松弛法 (Relaxation):</strong>
                我们不必完全“相信”Gauss-Seidel给出的修正步长。我们可以引入一个<strong>松弛因子 (Relaxation Factor)</strong> $\omega$，来控制我们朝修正方向“走多远”。</p>
                <p><strong>逐次超松弛法 (Successive Over-Relaxation, SOR) 迭代格式:</strong>
                $$x_i^{(k+1)} = (1-\omega)x_i^{(k)} + \omega \left[ \frac{1}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij}x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij}x_j^{(k)} \right) \right]$$</p>
                <ul>
                <li>当 $\omega=1$ 时，SOR <strong>退化为 Gauss-Seidel</strong>。</li>
                <li>当 $0 < \omega < 1$ 时，称为<strong>欠松弛 (Under-Relaxation)</strong>，用于稳定某些发散的迭代。</li>
                <li>当 $\omega > 1$ 时，称为<strong>超松弛 (Over-Relaxation)</strong>，用于加速收敛。我们通常关心这种情况。</li>
                </ul>
                <p><strong>SOR 迭代矩阵:</strong>
                $$T_\omega = (D-\omega L)^{-1}((1-\omega)D + \omega U)$$</p>
                <p><strong>SOR 收敛性定理:</strong></p>
                <ul>
                <li><strong>Kahan 定理：</strong> $\rho(T_\omega) \ge |\omega-1|$。这意味着SOR要收敛，<strong>$\omega$ 必须在 $(0, 2)$ 区间内</strong>。这是一个必要条件。</li>
                <li><strong>Ostrowski-Reich 定理：</strong> 如果 $A$ 是<strong>对称正定</strong>的，那么只要 $0 < \omega < 2$，SOR就保证收敛。</li>
                </ul>
                <p>对于特定类型的矩阵（如对称正定三对角矩阵），甚至可以计算出使 $\rho(T_\omega)$ 最小的<strong>最优松弛因子 $\omega_{opt}$</strong>：
                $$\omega_{opt} = \frac{2}{1+\sqrt{1 - [\rho(T_J)]^2}}$$</p>
                <h3 id="%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%94%B6%E6%95%9B%E6%80%A7%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5"><strong>第三部分：收敛性分析实践</strong></h3>
                <p><strong>Discussion 14: 分析一个迭代方法</strong>
                给定矩阵 $A = \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{pmatrix}$, $\mathbf{b} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$ 和一个迭代格式：
                $$\mathbf{x}^{(k+1)} = \mathbf{x}^{(k)} + \omega(A\mathbf{x}^{(k)} - \mathbf{b})$$
                这是一个求解 $A\mathbf{x}=\mathbf{b}$ 的迭代法吗？不，它是求解 $A\mathbf{x}-\mathbf{b}=\mathbf{0}$，但迭代格式写错了。正确的应该是求解 $A\mathbf{x}=\mathbf{b}$ 的残差修正法，如 $\mathbf{x}^{(k+1)} = \mathbf{x}^{(k)} + \omega(\mathbf{b} - A\mathbf{x}^{(k)})$。我们以PDF上的格式为例进行分析。</p>
                <p><strong>1. 找出迭代矩阵 $T$:</strong>
                $$\mathbf{x}^{(k+1)} = (\mathbf{I} + \omega A)\mathbf{x}^{(k)} - \omega \mathbf{b}$$
                所以，迭代矩阵 $T = \mathbf{I} + \omega A = \begin{pmatrix} 1+2\omega &amp; \omega \\ \omega &amp; 1+2\omega \end{pmatrix}$。</p>
                <p><strong>2. 计算 $T$ 的特征值来得到谱半径:</strong>
                特征方程为 $\det(T-\lambda\mathbf{I}) = 0$。
                $$(1+2\omega - \lambda)^2 - \omega^2 = 0$$
                $$1+2\omega - \lambda = \pm \omega$$
                $$\lambda = 1+2\omega \mp \omega$$
                所以特征值为 $\lambda_1 = 1+\omega$ 和 $\lambda_2 = 1+3\omega$。</p>
                <p><strong>3. 分析收敛条件:</strong>
                要使迭代收敛，谱半径 $\rho(T) = \max\{|1+\omega|, |1+3\omega|\} < 1$。
                这需要同时满足两个不等式：
                (1) $-1 < 1+\omega < 1 \implies -2 < \omega < 0$
                (2) $-1 < 1+3\omega < 1 \implies -2 < 3\omega < 0 \implies -2/3 < \omega < 0$
                两个条件的交集是 <strong>$-2/3 < \omega < 0$</strong>。</p>
                <p><strong>4. 寻找最优 $\omega$:</strong>
                我们需要找到 $\omega$ 使得 $\rho(T)$ 最小。我们需要最小化函数 $f(\omega) = \max\{|1+\omega|, |1+3\omega|\}$。
                画出两个函数 $|1+\omega|$ (V型，顶点在-1) 和 $|1+3\omega|$ (更窄的V型，顶点在-1/3) 的图像。</p>
                <p>最大值函数的最小值出现在两条线的交点处，即：
                $$|1+\omega| = |1+3\omega|$$
                在收敛区间 $(-2/3, 0)$ 内，$1+\omega > 0$，$1+3\omega$ 可能为正也可能为负。
                若 $1+3\omega \ge 0$ (即 $\omega \ge -1/3$)，则 $1+\omega = 1+3\omega \implies \omega=0$，不在区间内。
                若 $1+3\omega < 0$ (即 $\omega < -1/3$)，则 $1+\omega = -(1+3\omega) = -1-3\omega \implies 4\omega = -2 \implies \omega = -1/2$。
                这个值在收敛区间内。
                当 $\omega = -1/2$ 时，$\rho(T) = |1-1/2| = |1-3/2| = 0.5$。这就是最小的谱半径。</p>
                <p>因此，最优松弛因子是 $\omega_{opt} = -1/2$。</p>
                <h3 id="%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93"><strong>课程总结</strong></h3>
                <p><strong>本讲核心要点：</strong></p>
                <ol>
                <li><strong>Jacobi</strong> 和 <strong>Gauss-Seidel</strong> 是将矩阵 $A$ 分裂为 $D-L-U$ 得到的两种基础迭代法，前者易于并行，后者通常收敛更快且节省内存。</li>
                <li>迭代法收敛的<strong>充要条件是迭代矩阵的谱半径 $\rho(T)<1$</strong>。这是一个深刻的理论结果，将线性代数的特征值理论与迭代过程的收敛性联系起来。</li>
                <li><strong>范数小于1</strong> ($ |T| < 1 $) 是一个更容易计算的<strong>充分条件</strong>，而<strong>严格对角占优</strong>是保证Jacobi和GS收敛的一个更易判断的矩阵性质。</li>
                <li><strong>SOR方法</strong>通过引入松弛因子 $\omega$ 来加速Gauss-Seidel，收敛的必要条件是 $0 < \omega < 2$。选择最优的 $\omega$ 可以显著提升收敛速度。</li>
                </ol>
                <p><strong>Lab 04 ：Jacobi 与 Gauss-Seidel 对比</strong>
                <strong>任务：</strong> 编写程序，用Jacobi和Gauss-Seidel方法求解给定的线性系统，并对比它们的表现。
                <strong>关键提示 (Note):</strong></p>
                <ul>
                <li>实验要求实现一种<strong>预处理</strong>策略来增强对角占优性：对于每一行 $i$，从该行向下扫描第 $i$ 列，找到绝对值最大的元素，通过<strong>行交换</strong>将其放到对角线位置。如果找不到非零元，则向上扫描，找到非零元后将其所在行<strong>加到</strong>第 $i$ 行。这种操作旨在尽可能地满足收敛条件，是数值实践中提高算法鲁棒性的常用技巧。</li>
                <li>你需要分别实现两种算法，对同一个问题进行求解，并可能需要记录迭代次数或运行时间来对比效率。</li>
                </ul>
            </article>
        </main>
    </div>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
    <script src="../script.js"></script>
</body>
</html>