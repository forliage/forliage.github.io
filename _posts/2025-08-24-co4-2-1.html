<!DOCTYPE html>

<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<title>计算机组成4-2-1:流水线的结构</title>
<link href="../style.css" rel="stylesheet"/>
<link href="../modal.css" rel="stylesheet"/>
<script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" type="text/javascript">
</script>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FPDBQB4LZD"></script>
<script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FPDBQB4LZD');
    </script>
</head>
<body>
<audio id="bg-music" loop="" src="../music.mp3"></audio>
<button class="music-control" id="music-toggle">♪</button><button class="dark-mode-control" id="dark-mode-toggle">🌙</button>
<header>
<h1>forliage的blog</h1>
<nav>
<ul>
<li><a href="../index.html">首页</a></li>
<li><a href="../posts.html">文章</a></li>
<li><a href="../about.html">关于</a></li>
<li><a href="../category.html?category=技术文章">技术文章</a></li>
<li><a href="../category.html?category=生活随笔">生活随笔</a></li>
<li><a href="../category.html?category=学习笔记">学习笔记</a></li>
<li><a href="../category.html?category=心情日记">心情日记</a></li>
<li><a href="#" id="about-me-btn">ABOUT ME</a></li>
</ul>
</nav>
</header>
<div class="container">
<div id="sidebar-container"></div>
<main>
<article>
<h1 id="%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%904-2-1%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9A%84%E7%BB%93%E6%9E%84">计算机组成4-2-1:流水线的结构</h1>
<h3 id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%8D%95%E5%91%A8%E6%9C%9F%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%9F%E7%BD%AA%E5%AF%B9%E6%97%B6%E9%97%B4%E7%9A%84%E6%B5%AA%E8%B4%B9"><strong>第一部分：单周期模型的“原罪”——对时间的浪费</strong></h3>
<p>在我们急于抛弃单周期模型之前，让我们先给它做一次精准的“尸检”，量化地分析它到底有多糟糕。这将为我们理解流水线的必要性提供最直接的动机。</p>
<h4 id="11-%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9F%E7%9A%84%E7%A1%AE%E5%AE%9A"><strong>1.1 定量分析：关键路径与时钟周期的确定</strong></h4>
<p>我们假设处理器中不同功能单元的延迟如下（这是一个非常经典的、接近实际的简化模型）：</p>
<ul>
<li><strong>存储器访问 (Instruction/Data Memory)</strong>：200 ps (皮秒)</li>
<li><strong>ALU及加法器</strong>：200 ps</li>
<li><strong>寄存器堆读/写</strong>：100 ps</li>
<li>其他组合逻辑（如MUX, 控制单元）延迟忽略不计。</li>
</ul>
<p>根据上节课的知识，单周期处理器的时钟周期必须<strong>容纳下最长的那条指令的执行路径</strong>，这条路径被称为<strong>关键路径</strong>。让我们来分析几条典型指令的执行总耗时：</p>
<ol>
<li>
<p><strong>R-Type (<code>add</code>, <code>sub</code>等)</strong></p>
<ul>
<li>路径：取指(IM) -&gt; 读寄存器(Reg) -&gt; ALU计算 -&gt; 写寄存器(Reg)</li>
<li>耗时：<code>200ps (IM) + 100ps (Reg Read) + 200ps (ALU) + 100ps (Reg Write) = 600 ps</code></li>
</ul>
</li>
<li>
<p><strong>Load (<code>ld</code>)</strong></p>
<ul>
<li>路径：取指(IM) -&gt; 读寄存器(Reg) -&gt; ALU计算地址 -&gt; 访存(DM) -&gt; 写寄存器(Reg)</li>
<li>耗时：<code>200ps (IM) + 100ps (Reg Read) + 200ps (ALU) + 200ps (DM) + 100ps (Reg Write) = 800 ps</code>
<img alt="figure 19" src="../images/imagec19.png"/></li>
</ul>
</li>
<li>
<p><strong>Store (<code>sd</code>)</strong></p>
<ul>
<li>路径：取指(IM) -&gt; 读寄存器(Reg) -&gt; ALU计算地址 -&gt; 访存(DM)</li>
<li>耗时：<code>200ps (IM) + 100ps (Reg Read) + 200ps (ALU) + 200ps (DM) = 700 ps</code></li>
</ul>
</li>
<li>
<p><strong>Branch (<code>beq</code>)</strong></p>
<ul>
<li>路径：取指(IM) -&gt; 读寄存器(Reg) -&gt; ALU比较</li>
<li>耗时：<code>200ps (IM) + 100ps (Reg Read) + 200ps (ALU) = 500 ps</code></li>
</ul>
</li>
</ol>
<p><img alt="figure 20" src="../images/imagec20.png"/></p>
<p><strong>结论显而易见</strong>：<code>ld</code>指令是我们的“短板”，它需要800ps。因此，整个处理器的时钟周期 $T_{clk}$ 必须设置为 <strong>800ps</strong>。这意味着，即使是只需要500ps的<code>beq</code>指令，也必须占用一个完整的800ps周期，其中有300ps的时间，处理器是在“无所事事”地空转！</p>
<h4 id="12-%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%AC%E8%B4%A8%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E7%9A%84%E8%BF%9D%E8%83%8C"><strong>1.2 问题的本质与设计原则的违背</strong></h4>
<p>单周期处理器的“原罪”在于：</p>
<ol>
<li><strong>资源利用率极低</strong>：在一个时钟周期内，当指令在执行ALU计算时，取指单元和数据存储器是空闲的；当在访存时，ALU是空闲的。每个功能单元在大部分时间里都在“摸鱼”。</li>
<li><strong>设计理念的违背</strong>：它违背了计算机设计的一个重要原则——<strong>加速大概率事件 (Making the common case fast)</strong>。在典型的程序中，简单的算术指令和分支指令出现的频率远高于访存指令。而我们却让这些“常客”去迁就最慢的“稀客”。</li>
<li><strong>扩展性差</strong>：如果我们想加入一条更复杂、更慢的指令（比如浮点乘法），整个处理器的时钟周期都会被进一步拉长，所有指令的性能都会因此下降。</li>
</ol>
<p><strong>能否为不同指令设置不同的时钟周期？</strong> 理论上可以，但硬件实现会变得异常复杂，需要复杂的异步电路设计，这在现代通用处理器中是不可行的。我们需要一个更通用、更优雅的解决方案。</p>
<h3 id="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9A%84%E6%80%9D%E6%83%B3%E4%BB%8E%E4%B8%B2%E8%A1%8C%E5%88%B0%E5%B9%B6%E8%A1%8C"><strong>第二部分：流水线的思想——从串行到并行</strong></h3>
<p>既然无法缩短最慢指令的总时长，也无法为不同指令定制周期，那我们能否换一个思路？我们能否让多个指令<strong>重叠执行</strong>，从而提高单位时间内的指令“吞吐率”？</p>
<p>这就是<strong>流水线 (Pipelining)</strong> 的核心思想。</p>
<h4 id="21-%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%AF%94%E6%B4%97%E8%A1%A3%E6%88%BF%E7%9A%84%E6%99%BA%E6%85%A7"><strong>2.1 生活中的类比：洗衣房的智慧</strong></h4>
<p>想象一下，有四位同学（A, B, C, D）要洗衣服，洗衣过程分为四个步骤：</p>
<ol>
<li>洗衣 (30分钟)</li>
<li>烘干 (40分钟)</li>
<li>叠衣 (20分钟)</li>
<li>放入衣柜 (10分钟)</li>
</ol>
<p><strong>串行（单周期）方案</strong>：
                同学A完成所有四步后，同学B才能开始。总时长 = $4 \times (30+40+20+10) = 400$ 分钟。</p>
<p><strong>流水线方案</strong>：</p>
<ul>
<li>当同学A的衣服进入烘干机时，同学B就可以开始使用洗衣机了。</li>
<li>当A的衣服在叠衣，B的在烘干时，C就可以开始洗衣了。</li>
<li>各个设备（洗衣机、烘干机）得到了充分利用。</li>
</ul>
<p><img alt="figure 21" src="../images/imagec21.png"/></p>
<p><strong>性能分析</strong>：</p>
<ul>
<li><strong>延迟 (Latency)</strong>：单个同学完成洗衣的总时间并没有减少，甚至可能因为切换的开销略有增加。</li>
<li><strong>吞吐率 (Throughput)</strong>：单位时间内完成洗衣任务的同学数量大大增加了！</li>
<li><strong>加速比 (Speedup)</strong>：理想情况下，如果每个步骤时间相同，N个任务的加速比将接近步骤的数量。</li>
</ul>
<p>这个简单的例子揭示了流水线的本质：<strong>通过将一个任务分解成多个独立的阶段，并让不同任务的不同阶段并行执行，从而提高系统的整体吞吐率，而不是降低单个任务的延迟。</strong></p>
<h4 id="22-%E5%B0%86%E6%B5%81%E6%B0%B4%E7%BA%BF%E6%80%9D%E6%83%B3%E5%BA%94%E7%94%A8%E4%BA%8Erisc-v%E5%A4%84%E7%90%86%E5%99%A8"><strong>2.2 将流水线思想应用于RISC-V处理器</strong></h4>
<p>我们的指令执行过程，天然就可以被划分为上节课提到的五个经典阶段：</p>
<ol>
<li><strong>IF (Instruction Fetch)</strong>: 取指</li>
<li><strong>ID (Instruction Decode)</strong>: 译码并读取寄存器</li>
<li><strong>EX (Execute)</strong>: 执行运算或计算地址</li>
<li><strong>MEM (Memory Access)</strong>: 访问数据存储器</li>
<li><strong>WB (Write Back)</strong>: 将结果写回寄存器</li>
</ol>
<p><strong>设计思路</strong>：</p>
<ul>
<li>我们将单周期的数据通路，沿着这五个阶段的边界，“切”成五段。</li>
<li>在每个阶段的末尾，我们插入一组特殊的寄存器，称为<strong>流水线寄存器 (Pipeline Registers)</strong>。</li>
<li>这些寄存器的作用，就像是洗衣房中不同步骤之间的“中转篮子”，它们负责<strong>暂存</strong>一个阶段的输出，并作为下一个阶段的输入，在下一个时钟周期提供给下一级。</li>
<li><strong>时钟周期</strong>不再由最长指令的总时间决定，而是由<strong>最长的那个流水线阶段的延迟</strong>决定。</li>
</ul>
<p><img alt="figure 22" src="../images/imagec22.png"/></p>
<p>上图完美地展示了流水线的并行性。在时钟周期5，有五条不同的指令同时处于流水线的五个不同阶段，处理器的所有功能单元都在满负荷工作！</p>
<h4 id="23-%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9A%84%E6%80%A7%E8%83%BD%E6%BD%9C%E5%8A%9B%E5%AE%9A%E6%80%A7%E4%B8%8E%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90"><strong>2.3 流水线的性能潜力：定性与定量分析</strong></h4>
<p><strong>定性分析</strong>：</p>
<ul>
<li><strong>CPI的变化</strong>：在充满指令的稳定状态下，每个时钟周期都有一条指令完成。因此，理想CPI从单周期的1（但周期很长），变成了流水线的1（但周期很短）。</li>
<li><strong>吞吐率的提升</strong>：假设单周期时钟为800ps，流水线每个阶段最长为200ps（即访存或ALU）。流水线的时钟周期可以缩短到200ps。吞吐率提升了 $800/200 = 4$ 倍！</li>
</ul>
<p><img alt="figure 23" src="../images/imagec23.png"/></p>
<p><strong>定量分析</strong>：</p>
<ul>
<li>
<p><strong>加速比公式</strong>：
                $$
                \text{Speedup} = \frac{\text{Time}<em>{\text{non-pipelined}}}{\text{Time}</em>{\text{pipelined}}} = \frac{N \times T_{clk_single}}{(N + k - 1) \times T_{clk_pipe}}
                $$
                其中，$N$是指令数，$k$是流水线级数。当$N$很大时，$(N+k-1) \approx N$，公式简化为：
                $$
                \text{Speedup} \approx \frac{T_{clk_single}}{T_{clk_pipe}} = \frac{\text{最长指令总延迟}}{\text{最长阶段延迟}}
                $$</p>
</li>
<li>
<p><strong>一个关键前提：阶段平衡</strong>
                流水线的性能提升，高度依赖于各个阶段的延迟是否均衡。如果一个阶段耗时400ps，其他四个都耗时100ps，那么时钟周期只能是400ps，性能提升将大打折扣。<strong>平衡流水线阶段</strong>是设计中的一个重要艺术。</p>
</li>
</ul>
<p><strong>总结流水线的核心优势</strong>：
                流水线并不减少单条指令的<strong>延迟 (Latency)</strong>，甚至会因为流水线寄存器的开销而略微增加。但是，它通过并行化，极大地提高了指令的<strong>吞吐率 (Throughput)</strong>。</p>
<h3 id="%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%B5%81%E6%B0%B4%E9%83%A8%E5%88%86%E7%9A%84%E8%AF%85%E5%92%92%E5%86%92%E9%99%A9-hazards"><strong>第三部分：流水部分的“诅咒”——冒险 (Hazards)</strong></h3>
<p>天下没有免费的午餐。流水线在带来巨大性能提升的同时，也引入了三种非常棘手的副作用，我们称之为<strong>冒险 (Hazards)</strong>。冒险是指在流水线中，下一条指令无法在下一个时钟周期正常开始执行的情况。它们是流水线设计者必须面对和解决的核心难题。</p>
<h4 id="31-%E7%BB%93%E6%9E%84%E5%86%92%E9%99%A9-structural-hazards"><strong>3.1 结构冒险 (Structural Hazards)</strong></h4>
<ul>
<li><strong>定义</strong>：当两条或多条指令在同一个时钟周期，需要<strong>争用同一个硬件资源</strong>时，就会发生结构冒险。</li>
<li><strong>经典例子：统一的存储器</strong>
<ul>
<li>假设我们的处理器只有一个存储器，既用于取指，也用于数据访问。</li>
<li>观察流水线时空图：在时钟周期4，指令<code>i</code>处于MEM阶段（需要访问数据存储器），而指令<code>i+3</code>处于IF阶段（需要访问指令存储器）。</li>
<li>如果只有一个存储器，它们就会发生冲突！指令<code>i+3</code>的取指操作必须<strong>暂停 (Stall)</strong> 一个周期，等待指令<code>i</code>用完存储器。</li>
</ul>
</li>
<li><strong>解决方案</strong>：
                <ol>
<li><strong>资源复制</strong>：这是最简单粗暴但有效的方法。我们设计<strong>分离的指令存储器和数据存储器</strong>（或者在现代CPU中，是分离的指令Cache和数据Cache，即<strong>哈佛结构</strong>）。这样，IF阶段和MEM阶段的访存操作就可以并行进行，互不干扰。</li>
<li><strong>流水化资源</strong>：如果某个资源无法复制（例如一个复杂的浮点运算单元），可以尝试将其本身也设计成流水线式的，使其可以在多个周期内接收新的任务。</li>
</ol>
</li>
</ul>
<h4 id="32-%E6%95%B0%E6%8D%AE%E5%86%92%E9%99%A9-data-hazards"><strong>3.2 数据冒险 (Data Hazards)</strong></h4>
<ul>
<li>
<p><strong>定义</strong>：当一条指令需要使用到<strong>前一条尚未执行完毕的指令的结果</strong>时，就会发生数据冒险。这是最常见也最需要精巧设计的冒险。</p>
</li>
<li>
<p><strong>代码示例</strong>：</p>
<pre class="hljs"><code><div>add x19, x0, x1   // 指令1: 计算x19
                sub x2, x19, x3    // 指令2: 使用x19
                </div></code></pre>
</li>
<li>
<p><strong>问题分析</strong>：</p>
<ul>
<li><code>add</code>指令在WB阶段（第5个周期）才会把结果写入寄存器<code>x19</code>。</li>
<li>但是，<code>sub</code>指令在ID阶段（第3个周期）就需要从寄存器堆中读出<code>x19</code>的值。</li>
<li>此时，<code>x19</code>中的值还是旧的！<code>sub</code>指令读到了一个错误的数据。
                <img alt="figure 24" src="../images/imagec24.png"/></li>
</ul>
</li>
<li>
<p><strong>朴素的解决方案：暂停 (Stall / Bubble)</strong></p>
<ul>
<li>我们可以让流水线暂停。当检测到数据冒险时，让<code>sub</code>指令以及其后的所有指令在流水线中“冻结”几个周期，直到<code>add</code>指令完成WB阶段。</li>
<li>这种暂停在流水线中通常通过插入<strong>空操作 (NOP)</strong> 或称为<strong>气泡 (Bubble)</strong> 来实现。</li>
<li><strong>缺点</strong>：严重影响性能！为了等待一个数据，流水线可能要空转好几个周期，吞吐率急剧下降。</li>
</ul>
</li>
<li>
<p><strong>更聪明的解决方案：数据前递/旁路 (Forwarding / Bypassing)</strong></p>
<ul>
<li><strong>核心思想</strong>：我们为什么非要等到数据被写回寄存器堆再使用呢？<code>add</code>指令的结果在<strong>EX阶段结束时</strong>就已经在ALU的出口处产生了。这个结果比WB阶段早了整整两个周期！</li>
<li><strong>实现</strong>：我们可以增加一些额外的数据通路和MUX，将ALU的输出结果**直接“转发”**给下一条指令的ALU输入端，绕过寄存器堆。</li>
<li><img alt="figure 25" src="../images/imagec25.png"/></li>
<li>通过数据前递，<code>sub</code>指令可以在其EX阶段及时拿到<code>add</code>指令的计算结果，流水线无需暂停，继续全速运行！</li>
</ul>
</li>
<li>
<p><strong>数据冒险的特殊情况：Load-Use Hazard</strong></p>
<ul>
<li>数据前递虽好，但并非万能。考虑以下情况：<pre class="hljs"><code><div>ld x1, 0(x2)     // 指令1: 从内存加载数据到x1
                sub x4, x1, x5   // 指令2: 立即使用x1
                </div></code></pre>
</li>
<li><strong>问题分析</strong>：
                <ul>
<li><code>ld</code>指令的数据，直到<strong>MEM阶段结束时</strong>才从数据存储器中准备好。</li>
<li>而<code>sub</code>指令在<strong>EX阶段开始时</strong>就需要这个数据。</li>
<li>即使我们从MEM阶段的输出进行前递，数据到达<code>sub</code>的ALU输入时也已经晚了一个周期。我们无法“向后穿越时间”来前递数据。
                <img alt="figure 26" src="../images/imagec26.png"/></li>
</ul>
</li>
<li><strong>解决方案：暂停+前递</strong>
<ul>
<li>这是唯一无法完全通过前递解决的数据冒险。我们必须让<code>sub</code>指令<strong>暂停一个周期</strong>。</li>
<li>暂停后，<code>ld</code>指令进入WB阶段，<code>sub</code>进入EX阶段。此时，<code>ld</code>在MEM阶段结束时产生的数据，就可以顺利地前递给<code>sub</code>的EX阶段了。</li>
<li>这种“加载后立即使用”的冒险需要一次<strong>强制的1周期停顿</strong>。</li>
</ul>
</li>
<li>
<p><strong>编译器的角色：指令调度 (Instruction Scheduling)</strong></p>
<ul>
<li>既然硬件层面有1周期的停顿惩罚，我们能否在软件层面避免它？</li>
<li>优秀的编译器会进行<strong>指令调度</strong>，尝试在<code>ld</code>指令和使用其结果的指令之间，插入一条或多条不相关的指令，来填补这个“气泡”。</li>
<li><img alt="figure 27" src="../images/imagec27.png"/></li>
<li>这是硬件和软件协同优化性能的绝佳范例。</li>
</ul>
</li>
</ul>
<h4 id="33-%E6%8E%A7%E5%88%B6%E5%86%92%E9%99%A9-control-hazards"><strong>3.3 控制冒险 (Control Hazards)</strong></h4>
<ul>
<li>
<p><strong>定义</strong>：由分支、跳转等改变程序控制流的指令引起的冒险。处理器无法在分支结果出来之前，确定下一条要取指的指令的地址。</p>
</li>
<li>
<p><strong>问题分析</strong>：</p>
<ul>
<li>在我们的5级流水线中，<code>beq</code>指令在EX阶段（第3周期）才能计算出比较结果，在MEM阶段（第4周期）才能确定是否跳转并更新PC。</li>
<li>但是，取指单元（IF阶段）在第2个周期就需要知道下一条指令的地址。</li>
<li>当我们处理<code>beq</code>指令的ID阶段时，我们已经取了<code>beq</code>的下一条指令(PC+4)。当我们处理<code>beq</code>的EX阶段时，我们又取了<code>beq</code>的下下条指令(PC+8)。</li>
<li>如果<code>beq</code>最终判断需要跳转，那么我们刚刚辛苦取来的这两条指令都是<strong>错误的</strong>，必须被<strong>冲刷 (Flush)</strong> 掉，并从正确的分支目标地址重新开始取指。</li>
<li>这将导致多个周期的性能损失。</li>
</ul>
</li>
<li>
<p><strong>解决方案（由简单到复杂）</strong>：</p>
<ol>
<li><strong>冻结或暂停流水线 (Stall)</strong>：在ID阶段译码出是分支指令后，立即冻结流水线，直到分支结果确定。简单但性能损失巨大。</li>
<li><strong>分支预测 (Branch Prediction)</strong>：与其傻等，不如<strong>猜测</strong>分支的结果。
                <ul>
<li><strong>最简单的预测：预测不跳转 (Predict Not Taken)</strong>。我们总是假设分支不发生，继续取PC+4的指令。如果猜对了，流水线没有任何损失。如果猜错了（分支实际发生了），我们再冲刷掉错误路径上的指令，并从目标地址重新取指。这被称为<strong>分支预测惩罚 (Misprediction Penalty)</strong>。</li>
<li><strong>提前计算</strong>：为了减少惩罚，我们可以将分支判断和目标地址计算的硬件，从EX阶段<strong>提前到ID阶段</strong>。这样，如果猜错，只需要冲刷掉一条已经进入IF阶段的指令，惩罚减小。</li>
<li><strong>静态预测</strong>：编译器根据一些启发式规则进行预测。例如，向后跳转的循环分支，大概率会发生；向前跳转的错误处理分支，大概率不发生。</li>
<li><strong>动态预测</strong>：这是现代处理器的核心技术。用硬件（如<strong>分支历史表 Branch History Table, BHT</strong>）记录每条分支指令过去的执行行为，并据此预测它下一次的行为。例如，一个简单的<strong>1位预测器</strong>记录上次是否跳转。更强大的<strong>2位饱和计数器</strong>可以容忍一次偶然的错误行为，只有在连续两次预测错误时才翻转预测状态。
                <img alt="figure 28" src="../images/imagec28.png"/></li>
</ul>
</li>
<li><strong>延迟分支 (Delayed Branch)</strong>（一种历史性的 ISA 级解决方案）：在ISA层面规定，分支指令后面的那个指令槽位（称为<strong>延迟槽 Delay Slot</strong>）中的指令，无论分支是否发生，都<strong>总是被执行</strong>。编译器负责找到一条有用的、不影响分支结果的指令填充进去。如果找不到，就填充一个NOP。这种方法将分支的控制惩罚转移给了编译器，简化了早期流水线硬件的设计，但在现代深流水线中已不常用。</li>
</ol>
</li>
</ul>
</li></ul></article><div class="share-buttons">
<p>分享到：</p>
<a class="share-btn weibo" href="#" onclick="sharePost(event, 'weibo')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Sina Weibo</title><path d="M10.098 20.323c-3.977.391-7.414-1.406-7.672-4.02-.259-2.609 2.759-5.047 6.74-5.441 3.979-.394 7.413 1.404 7.671 4.018.259 2.6-2.759 5.049-6.737 5.439l-.002.004zM9.05 17.219c-.384.616-1.208.884-1.829.602-.612-.279-.793-.991-.406-1.593.379-.595 1.176-.861 1.793-.601.622.263.82.972.442 1.592zm1.27-1.627c-.141.237-.449.353-.689.253-.236-.09-.313-.361-.177-.586.138-.227.436-.346.672-.24.239.09.315.36.18.601l.014-.028zm.176-2.719c-1.893-.493-4.033.45-4.857 2.118-.836 1.704-.026 3.591 1.886 4.21 1.983.64 4.318-.341 5.132-2.179.8-1.793-.201-3.642-2.161-4.149zm7.563-1.224c-.346-.105-.57-.18-.405-.615.375-.977.42-1.804 0-2.404-.781-1.112-2.915-1.053-5.364-.03 0 0-.766.331-.571-.271.376-1.217.315-2.224-.27-2.809-1.338-1.337-4.869.045-7.888 3.08C1.309 10.87 0 13.273 0 15.348c0 3.981 5.099 6.395 10.086 6.395 6.536 0 10.888-3.801 10.888-6.82 0-1.822-1.547-2.854-2.915-3.284v.01zm1.908-5.092c-.766-.856-1.908-1.187-2.96-.962-.436.09-.706.511-.616.932.09.42.511.691.932.602.511-.105 1.067.044 1.442.465.376.421.466.977.316 1.473-.136.406.089.856.51.992.405.119.857-.105.992-.512.33-1.021.12-2.178-.646-3.035l.03.045zm2.418-2.195c-1.576-1.757-3.905-2.419-6.054-1.968-.496.104-.812.587-.706 1.081.104.496.586.813 1.082.707 1.532-.331 3.185.15 4.296 1.383 1.112 1.246 1.429 2.943.947 4.416-.165.48.106 1.007.586 1.157.479.165.991-.104 1.157-.586.675-2.088.241-4.478-1.338-6.235l.03.045z"></path></svg>
<span>微博</span>
</a>
<a class="share-btn twitter" href="#" onclick="sharePost(event, 'twitter')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M21.543 7.104c.015.211.015.423.015.636 0 6.507-4.954 14.01-14.01 14.01v-.003A13.94 13.94 0 0 1 0 19.539a9.88 9.88 0 0 0 7.287-2.041 4.93 4.93 0 0 1-4.6-3.42 4.916 4.916 0 0 0 2.223-.084A4.926 4.926 0 0 1 .96 9.167v-.062a4.887 4.887 0 0 0 2.235.616A4.928 4.928 0 0 1 1.67 3.148 13.98 13.98 0 0 0 11.82 8.292a4.929 4.929 0 0 1 8.39-4.49 9.868 9.868 0 0 0 3.128-1.196 4.941 4.941 0 0 1-2.165 2.724A9.828 9.828 0 0 0 24 4.555a10.019 10.019 0 0 1-2.457 2.549z"></path></svg>
<span>Twitter</span>
</a>
<a class="share-btn linkedin" href="#" onclick="sharePost(event, 'linkedin')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg>
<span>LinkedIn</span>
</a>
<a class="share-btn wechat" href="#" onclick="sharePost(event, 'wechat')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>WeChat</title><path d="M8.691 2.188C3.891 2.188 0 5.476 0 9.53c0 2.212 1.17 4.203 3.002 5.55a.59.59 0 0 1 .213.665l-.39 1.48c-.019.07-.048.141-.048.213 0 .163.13.295.29.295a.326.326 0 0 0 .167-.054l1.903-1.114a.864.864 0 0 1 .717-.098 10.16 10.16 0 0 0 2.837.403c.276 0 .543-.027.811-.05-.857-2.578.157-4.972 1.932-6.446 1.703-1.415 3.882-1.98 5.853-1.838-.576-3.583-4.196-6.348-8.596-6.348zM5.785 5.991c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178A1.17 1.17 0 0 1 4.623 7.17c0-.651.52-1.18 1.162-1.18zm5.813 0c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178 1.17 1.17 0 0 1-1.162-1.178c0-.651.52-1.18 1.162-1.18zm5.34 2.867c-1.797-.052-3.746.512-5.28 1.786-1.72 1.428-2.687 3.72-1.78 6.22.942 2.453 3.666 4.229 6.884 4.229.826 0 1.622-.12 2.361-.336a.722.722 0 0 1 .598.082l1.584.926a.272.272 0 0 0 .14.047c.134 0 .24-.111.24-.247 0-.06-.023-.12-.038-.177l-.327-1.233a.582.582 0 0 1-.023-.156.49.49 0 0 1 .201-.398C23.024 18.48 24 16.82 24 14.98c0-3.21-2.931-5.837-6.656-6.088V8.89c-.135-.01-.27-.027-.407-.03zm-2.53 3.274c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.97-.982zm4.844 0c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.969-.982z"></path></svg>
<span>微信</span>
</a>
<a class="share-btn qq" href="#" onclick="sharePost(event, 'qq')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Tencent QQ</title><path d="M21.395 15.035a40 40 0 0 0-.803-2.264l-1.079-2.695c.001-.032.014-.562.014-.836C19.526 4.632 17.351 0 12 0S4.474 4.632 4.474 9.241c0 .274.013.804.014.836l-1.08 2.695a39 39 0 0 0-.802 2.264c-1.021 3.283-.69 4.643-.438 4.673.54.065 2.103-2.472 2.103-2.472 0 1.469.756 3.387 2.394 4.771-.612.188-1.363.479-1.845.835-.434.32-.379.646-.301.778.343.578 5.883.369 7.482.189 1.6.18 7.14.389 7.483-.189.078-.132.132-.458-.301-.778-.483-.356-1.233-.646-1.846-.836 1.637-1.384 2.393-3.302 2.393-4.771 0 0 1.563 2.537 2.103 2.472.251-.03.581-1.39-.438-4.673"></path></svg>
<span>QQ</span>
</a>
<a class="share-btn facebook" href="#" onclick="sharePost(event, 'facebook')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M9.101 23.691v-7.98H6.627v-3.667h2.474v-1.58c0-4.085 1.848-5.978 5.858-5.978.401 0 .955.042 1.468.103a8.68 8.68 0 0 1 1.141.195v3.325a8.623 8.623 0 0 0-.653-.036 26.805 26.805 0 0 0-.733-.009c-.707 0-1.259.096-1.675.309a1.686 1.686 0 0 0-.679.622c-.258.42-.374.995-.374 1.752v1.297h3.919l-.386 2.103-.287 1.564h-3.246v8.245C19.396 23.238 24 18.179 24 12.044c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.628 3.874 10.35 9.101 11.647Z"></path></svg>
<span>Facebook</span>
</a>
</div>
</main>
</div>
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
<script src="../script.js"></script>
<!-- The Modal -->
<div class="modal" id="about-me-modal">
<!-- Modal content -->
<div class="modal-content">
<span class="close-button">×</span>
<h2>About Me</h2>
<p>This is forliage, an undergraduate student of computer science and technology at Zhejiang University.</p>
<p><strong>Motto:</strong> People always say that time heals all wounds, but I don't believe that. Time doen't heal the pain, it just makes us get used to pain. When you lose someone, you don't really forget them; you just learn how to live on without them.</p>
<p><strong>Interests:</strong> Computer Graphics, Computer Version, Computer Animation, HPC, AIGC</p>
<p><strong>Favorite Movie:</strong> The Shawshank Redemption, Dead Poets Society, Zootopia</p>
<p><strong>Favorite Music:</strong> Blank Space, Sorega Daiji, Counting Stars, Whataya Want from Me</p>
<p><strong>Contact Information:</strong>masterforliage@gmail.com</p>
<hr/>
<h3>订阅我的博客</h3>
<p>订阅功能正在建设中，敬请期待！</p>
</div>
</div>
<script src="../modal.js"></script>
</body>
</html>