<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>ads03:倒排文件索引（Inverted File Index）</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <audio id="bg-music" src="../music.mp3" loop></audio>
    <button id="music-toggle" class="music-control">♪</button>
    <header>
        <h1>forliage的blog</h1>
        <nav>
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../posts.html">文章</a></li>
                <li><a href="../about.html">关于</a></li>
                <li><a href="../category.html?category=技术文章">技术文章</a></li>
                <li><a href="../category.html?category=生活随笔">生活随笔</a></li>
                <li><a href="../category.html?category=学习笔记">学习笔记</a></li>
                <li><a href="../category.html?category=心情日记">心情日记</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
        <div id="sidebar-container"></div>
        <main>
            <article>
                <h1 id="ads03%E5%80%92%E6%8E%92%E6%96%87%E4%BB%B6%E7%B4%A2%E5%BC%95inverted-file-index">ads03:倒排文件索引（Inverted File Index）</h1>
                <h3 id="part-1-%E9%97%AE%E9%A2%98%E7%9A%84%E6%8F%90%E5%87%BA--%E4%BF%A1%E6%81%AF%E7%9A%84%E6%B1%AA%E6%B4%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E8%88%AA%E8%A1%8C">Part 1: 问题的提出 —— 信息的汪洋中如何航行？</h3>
                <p>我们每天都在使用搜索引擎。想象一下，当你在搜索框里输入“Computer Science”时，搜索引擎如何在不到一秒的时间内，从数千亿的网页中，精确地找出包含这个词组的页面，并呈现给你？</p>
                <p>这就是我们今天课程要解决的核心问题：<strong>如何快速地找到在哪些文档中包含了我们想要查询的关键词？</strong></p>
                <p>面对这个问题，我们最直观的想法是什么？</p>
                <h4 id="%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-1-%E6%9A%B4%E5%8A%9B%E6%89%AB%E6%8F%8F%E6%B3%95-scan-each-page">解决方案 1: 暴力扫描法 (Scan each page)</h4>
                <p>最简单粗暴的方法就是：把所有网页（文档）都看作一个长长的字符串，然后一篇一篇地去扫描，看看里面有没有“Computer Science”这个子串。</p>
                <p>这个方法可行吗？理论上可行。但现实呢？Google索引了超过10亿的网页。假设每篇网页平均100KB，扫描一篇需要1毫秒，那么扫描完所有网页需要：</p>
                <p>1,000,000,000 (网页) * 0.001 (秒/网页) = 1,000,000 秒 ≈ 11.5 天</p>
                <p>当你得到结果时，可能已经是很久的事情了。所以，这个方案在现实世界中是完全不可接受的。我们需要更聪明的办法。</p>
                <h4 id="%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-2-%E8%AF%8D%E9%A1%B9-%E6%96%87%E6%A1%A3%E5%85%B3%E8%81%94%E7%9F%A9%E9%98%B5-term-document-incidence-matrix">解决方案 2: 词项-文档关联矩阵 (Term-Document Incidence Matrix)</h4>
                <p>既然逐篇扫描太慢，我们能不能预先处理好所有文档，建立一张“速查表”呢？一个自然的想法就是<strong>词项-文档关联矩阵</strong>。</p>
                <p>我们把所有文档中出现过的词提取出来，作为矩阵的行；把所有文档的编号作为矩阵的列。如果一个词在某篇文档中出现，就在对应的单元格记为<code>1</code>，否则记为<code>0</code>。</p>
                <p><strong>【示例】</strong>
                假设我们有以下4个文档（Document sets）：</p>
                <ul>
                <li><strong>Doc 1:</strong> Gold silver truck</li>
                <li><strong>Doc 2:</strong> Shipment of gold damaged in a fire</li>
                <li><strong>Doc 3:</strong> Delivery of silver arrived in a silver truck</li>
                <li><strong>Doc 4:</strong> Shipment of gold arrived in a truck</li>
                </ul>
                <p>我们可以构建出如下的矩阵：</p>
                <table>
                <thead>
                <tr>
                <th style="text-align:left">Term</th>
                <th style="text-align:center">Doc 1</th>
                <th style="text-align:center">Doc 2</th>
                <th style="text-align:center">Doc 3</th>
                <th style="text-align:center">Doc 4</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                <td style="text-align:left">a</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                </tr>
                <tr>
                <td style="text-align:left">arrived</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                </tr>
                <tr>
                <td style="text-align:left">damaged</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">0</td>
                </tr>
                <tr>
                <td style="text-align:left">delivery</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                </tr>
                <tr>
                <td style="text-align:left">fire</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">0</td>
                </tr>
                <tr>
                <td style="text-align:left">gold</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                </tr>
                <tr>
                <td style="text-align:left">of</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                </tr>
                <tr>
                <td style="text-align:left">in</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                </tr>
                <tr>
                <td style="text-align:left">shipment</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                </tr>
                <tr>
                <td style="text-align:left">silver</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                </tr>
                <tr>
                <td style="text-align:left">truck</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">0</td>
                <td style="text-align:center">1</td>
                <td style="text-align:center">1</td>
                </tr>
                </tbody>
                </table>
                <p>现在，如果我们想查询包含 <code>silver</code> <strong>并且</strong> <code>truck</code> 的文档，该怎么做？</p>
                <ol>
                <li>找到 <code>silver</code> 对应的行向量： <code>[1, 0, 1, 0]</code></li>
                <li>找到 <code>truck</code> 对应的行向量： <code>[1, 0, 1, 1]</code></li>
                <li>对这两个向量进行**按位与(AND)**操作：
                <code>[1, 0, 1, 0] &amp; [1, 0, 1, 1] = [1, 0, 1, 0]</code></li>
                </ol>
                <p>结果向量中为<code>1</code>的位置，就是同时包含这两个词的文档，即 Doc 1 和 Doc 3。这个方法在逻辑上非常清晰，查询也很快。</p>
                <p><strong>但它的致命缺陷是什么？</strong></p>
                <ol>
                <li><strong>极度稀疏 (Sparsity)</strong>：想象一下，英语词汇量可能有几十万，而网页数量是千亿级别。这个矩阵的绝大多数单元格都会是 <code>0</code>。这造成了巨大的存储空间浪费。</li>
                <li><strong>难以扩展 (Scalability)</strong>：每增加一个新词或一篇新文档，就需要给这个巨大的矩阵增加一行或一列。维护成本极高。</li>
                </ol>
                <p><strong>数学分析：</strong>
                该矩阵的空间复杂度为 <strong>O(|V| × |D|)</strong>，其中 |V| 是词典中词项的总数，|D| 是文档的总数。对于Web规模的数据，|V| 在百万级，|D| 在千亿级，这个矩阵的大小是天文数字，任何现代计算机都无法存储。</p>
                <p>所以，词项-文档矩阵虽然在思路上进了一步，但依然不实用。我们需要一种只存储“有效信息”（也就是那些 <code>1</code> 的位置）的数据结构。</p>
                <hr>
                <h3 id="part-2-%E6%A0%B8%E5%BF%83%E5%88%A9%E5%99%A8--%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95-inverted-file-index">Part 2: 核心利器 —— 倒排索引 (Inverted File Index)</h3>
                <h4 id="%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-3-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95">解决方案 3: 倒排索引</h4>
                <p>倒排索引正是为了解决矩阵稀疏性问题而生的。它的核心思想非常简单：<strong>我们不记录词在哪个文档中“没有出现”，只记录它“在哪里出现了”</strong>。</p>
                <p><strong>【定义】</strong></p>
                <ul>
                <li><strong>索引 (Index)</strong>: 是一种用于快速定位文本中给定词项的机制。</li>
                <li><strong>倒排文件/倒排索引 (Inverted File)</strong>: 它包含了一个从<strong>词项(Term)<strong>到其出现位置的</strong>指针列表</strong>的映射。这个“位置”通常是指向文档的ID。</li>
                </ul>
                <p>之所以称为“倒排”，是因为它颠倒了“文档 -&gt; 词项”的自然关系，变成了“<strong>词项 -&gt; 文档</strong>”。</p>
                <p>一个倒排索引主要由两部分组成：</p>
                <ol>
                <li><strong>词典 (Dictionary/Vocabulary)</strong>: 包含了系统中所有的词项。</li>
                <li><strong>倒排列表 (Postings List)</strong>: 对于词典中的每个词项，都有一个与之对应的列表，记录了包含该词项的所有文档的ID。</li>
                </ol>
                <p><strong>【示例】</strong>
                还是用上面的4个文档作为例子，我们可以构建出这样的倒排索引：</p>
                <div class="mermaid">
                graph TD
                    subgraph "词典 (Dictionary)"
                        direction LR
                        A[fire]
                        B[gold]
                        C[of]
                        D[in]
                        E[shipment]
                        F[silver]
                        G[truck]
                    end

                    subgraph "倒排列表 (Postings Lists)"
                        direction LR
                        P1["[2]"]
                        P2["[1, 2, 4]"]
                        P3["[2, 3, 4]"]
                        P4["[2, 3, 4]"]
                        P5["[2, 4]"]
                        P6["[1, 3]"]
                        P7["[1, 3, 4]"]
                    end

                    A --> P1
                    B --> P2
                    C --> P3
                    D --> P4
                    E --> P5
                    F --> P6
                    G --> P7
                </div>
                <p>这个结构清晰地展示了：词<code>gold</code>出现在文档1, 2, 4中；词<code>silver</code>出现在文档1, 3中。</p>
                <p>现在，再来处理查询 <code>silver &amp; truck</code>：</p>
                <ol>
                <li>从词典中找到 <code>silver</code>，获取其倒排列表: <code>[1, 3]</code></li>
                <li>从词典中找到 <code>truck</code>，获取其倒排列表: <code>[1, 3, 4]</code></li>
                <li><strong>求两个列表的交集</strong>: <code>intersect([1, 3], [1, 3, 4]) = [1, 3]</code></li>
                </ol>
                <p>我们得到了结果 Doc 1 和 Doc 3，与矩阵法一致，但存储效率天差地别！我们只存储了有用的信息。</p>
                <h4 id="%E6%89%A9%E5%B1%95%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E5%87%BA%E7%8E%B0">扩展倒排索引：不仅仅是出现</h4>
                <p>一个基础的倒排索引只能回答“是否出现”的问题，但现代搜索引擎需要更多信息，比如：</p>
                <ul>
                <li>这个词在一个文档里出现了多少次？（<strong>词频 Frequency</strong>）</li>
                <li>它具体出现在文档的哪个位置？（<strong>位置信息 Position</strong>）</li>
                <li>如何根据相关性对结果排序？</li>
                <li>如何高亮显示搜索结果中的关键词？</li>
                </ul>
                <p>为了支持这些功能，我们需要一个更完备的倒排索引结构。</p>
                <table>
                <thead>
                <tr>
                <th style="text-align:left">No.</th>
                <th style="text-align:left">Term</th>
                <th style="text-align:left">Times; Doc ID, Word Position(s)</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                <td style="text-align:left">...</td>
                <td style="text-align:left">...</td>
                <td style="text-align:left">...</td>
                </tr>
                <tr>
                <td style="text-align:left">5</td>
                <td style="text-align:left">fire</td>
                <td style="text-align:left">&lt;1; (2;7)&gt;</td>
                </tr>
                <tr>
                <td style="text-align:left">6</td>
                <td style="text-align:left">gold</td>
                <td style="text-align:left">&lt; 3; (1;1), (2;3), (4;3)&gt;</td>
                </tr>
                <tr>
                <td style="text-align:left">...</td>
                <td style="text-align:left">...</td>
                <td style="text-align:left">...</td>
                </tr>
                <tr>
                <td style="text-align:left">10</td>
                <td style="text-align:left">silver</td>
                <td style="text-align:left">&lt;2; (1;2), (3;3)&gt;</td>
                </tr>
                <tr>
                <td style="text-align:left">11</td>
                <td style="text-align:left">truck</td>
                <td style="text-align:left">&lt; 3; (1;3), (3;8), (4;7)&gt;</td>
                </tr>
                </tbody>
                </table>
                <p>这里的 <code>&lt;3; (1;1), (2;3), (4;3)&gt;</code> 表示：词 <code>gold</code></p>
                <ul>
                <li>总共出现了 <strong>3</strong> 次 (Times/Frequency)</li>
                <li>出现在文档 <strong>1</strong> 的第 <strong>1</strong> 个位置。</li>
                <li>出现在文档 <strong>2</strong> 的第 <strong>3</strong> 个位置。</li>
                <li>出现在文档 <strong>4</strong> 的第 <strong>3</strong> 个位置。</li>
                </ul>
                <p>现在我们可以回答之前提出的两个问题了：</p>
                <ol>
                <li>
                <p><strong>如何高亮显示关键词？</strong>
                有了位置信息，当我们要展示文档3给用户时，我们知道 <code>silver</code> 出现在第3个词的位置，<code>truck</code> 出现在第8个词的位置。我们可以在渲染页面时，轻松地给这些位置的词加上高亮标签（如HTML的<code>&lt;strong&gt;</code>）。</p>
                </li>
                <li>
                <p><strong>为什么我们要保留&quot;times&quot; (词频)？</strong>
                词频是<strong>相关性排序 (Relevance Ranking)</strong> 的基石。直觉上，一篇文档中出现“搜索引擎”10次，比只出现1次的文档，更可能与“搜索引擎”这个主题相关。词频是计算著名的 <strong>TF-IDF</strong> 等排序算法的核心要素之一。我们稍后会详细讲解。</p>
                </li>
                </ol>
                <hr>
                <h3 id="part-3-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%9A%84%E6%9E%84%E5%BB%BA-index-generation">Part 3: 倒排索引的构建 (Index Generation)</h3>
                <p>了解了倒排索引的结构，我们来看看如何从原始文档集合构建它。这个过程通常是一个流水线作业。</p>
                <h4 id="%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B%E4%BC%AA%E4%BB%A3%E7%A0%81">构建流程伪代码</h4>
                <div class="code-container">
                <pre><code>// 初始化一个空的倒排索引
InvertedIndex index = new InvertedIndex();

while (还有未处理的文档 D) {
    // 读取一篇文档
    document D = read_a_document();
    
    // 对文档进行分词
    tokens = tokenize(D.content);
    
    while (tokens 中还有词项 T) {
        // 读取一个词项
        term T = read_a_term(tokens);
        
        // 查找词典中是否已有该词
        if ( !index.dictionary.contains(T) ) {
            // 如果没有，添加到词典，并创建一个新的倒排列表
            index.dictionary.add(T);
            index.postings.add(new PostingList());
        }
        
        // 获取该词项的倒排列表
        PostingList posting_list = index.get_posting_list(T);
        
        // 将当前文档信息（ID, 频率, 位置）添加到倒排列表中
        posting_list.add_node(D.ID, ...);
    }
}

// 将构建好的索引写入磁盘
write_index_to_disk(index);
</code></pre>
                </div>
                <p>这个流程中，<code>tokenize(D.content)</code> 并不是简单的按空格切分，它包含了一系列重要的预处理步骤。</p>
                <h4 id="%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86">文本预处理</h4>
                <p><strong>1. 词干提取 (Word Stemming) 与 词形还原 (Lemmatization)</strong>
                在搜索时，用户输入 <code>running</code>，他可能也想看到包含 <code>run</code> 或 <code>ran</code> 的结果。为了实现这一点，我们需要将这些词的不同形态统一为它们的原型或词干。</p>
                <ul>
                <li><strong>词干提取 (Stemming)</strong>: 一种比较粗暴的、基于规则的方法，直接砍掉词的后缀。例如，<code>processing</code>, <code>processes</code>, <code>processed</code> 可能都会被处理成 <code>process</code>。</li>
                <li><strong>词形还原 (Lemmatization)</strong>: 一种更精细的、基于词典和形态学分析的方法，将词还原为它的基本形态（lemma）。例如，<code>said</code> 会被还原为 <code>say</code>，<code>better</code> 会被还原为 <code>good</code>。</li>
                </ul>
                <div class="code-container">
                <pre><code>     says
     said     ──&gt;  process  ──&gt;   say
     saying
</code></pre>
                </div>
                <p><strong>2. 停用词 (Stop Words) 移除</strong>
                像 <code>a</code>, <code>the</code>, <code>in</code>, <code>of</code>, <code>it</code> 这样的词，在几乎所有文档中都大量出现。它们对表达文档的核心主题意义不大，但会占用大量的索引空间，并在查询处理时增加不必要的计算。这些词被称为“停用词”，我们通常在索引前将它们剔除。</p>
                <h4 id="%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E9%80%89%E6%8B%A9">数据结构的选择</h4>
                <p>构建索引时，我们需要一个高效的数据结构来存储<strong>词典</strong>，以便快速查找、插入。</p>
                <p><strong>【讨论】</strong> 在访问词典时，使用<strong>哈希表 (Hashing)</strong> 和<strong>搜索树 (Search Trees)</strong> 各有什么优缺点？</p>
                <p><strong>1. 哈希表 (e.g., C++ <code>std::unordered_map</code>)</strong></p>
                <ul>
                <li><strong>优点</strong>:
                <ul>
                <li><strong>速度极快</strong>：平均查找、插入和删除的时间复杂度为 <strong>O(1)</strong>。</li>
                </ul>
                </li>
                <li><strong>缺点</strong>:
                <ul>
                <li><strong>无序性</strong>：哈希表不保留词项的顺序。这使得它无法支持<strong>范围查询</strong>或<strong>前缀查询</strong>（例如，查找所有以 <code>comp*</code> 开头的词）。</li>
                <li><strong>空间开销</strong>：为了维持低冲突率，哈希表通常需要预留比实际元素更多的空间（较低的装载因子）。</li>
                <li><strong>哈希冲突</strong>：虽然有好的哈希函数可以缓解，但冲突处理总会带来一些性能开销。</li>
                </ul>
                </li>
                </ul>
                <p><strong>2. 搜索树 (e.g., B-Tree, B+Tree, C++ <code>std::map</code>)</strong></p>
                <ul>
                <li><strong>优点</strong>:
                <ul>
                <li><strong>有序性</strong>：树结构（特别是B树）本身就是有序的，可以高效地支持范围查询和前缀查询。这对于实现搜索建议（autocomplete）等功能至关重要。</li>
                <li><strong>性能稳定</strong>：最坏情况下的时间复杂度为 <strong>O(log N)</strong>，没有哈希表的极端情况。</li>
                </ul>
                </li>
                <li><strong>缺点</strong>:
                <ul>
                <li><strong>速度稍慢</strong>：O(log N) 普遍慢于 O(1)。</li>
                <li><strong>实现复杂</strong>：相比哈希表，平衡树的实现和维护更复杂。</li>
                <li><strong>空间开销</strong>：每个节点需要存储指向子节点的指针，有额外的空间开销。</li>
                </ul>
                </li>
                </ul>
                <p><strong>结论</strong>：在实际的搜索引擎中，常常是两者结合使用。例如，使用**Trie树（字典树）**或其变种来存储词典，它在支持前缀查询方面表现出色，同时空间效率也高。而对于一些内部查找，哈希表因其速度优势仍被广泛应用。</p>
                <p><strong>C++代码示例 (数据结构定义)</strong></p>
                <div class="code-container">
                <pre><code class="language-cpp">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
#include &lt;map&gt;
#include &lt;unordered_map&gt;
#include &lt;algorithm&gt;

// 表示一个词项在某个文档中的具体信息
struct Posting {
    int doc_id;
    int frequency;
    std::vector&lt;int&gt; positions;
};

// 倒排列表是一个Posting的向量
using PostingList = std::vector&lt;Posting&gt;;

// 基于搜索树（红黑树）的倒排索引
using TreeBasedInvertedIndex = std::map&lt;std::string, PostingList&gt;;

// 基于哈希表的倒排索引
using HashBasedInvertedIndex = std::unordered_map&lt;std::string, PostingList&gt;;
</code></pre>
                </div>
                <hr>
                <h3 id="part-4-%E5%BA%94%E5%AF%B9%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE--%E6%89%A9%E5%B1%95%E6%80%A7%E8%AE%BE%E8%AE%A1">Part 4: 应对海量数据 —— 扩展性设计</h3>
                <h4 id="1-%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3%E9%97%AE%E9%A2%98%E5%8D%95%E6%9C%BA%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%B4%A2%E5%BC%95%E6%9E%84%E5%BB%BA-spimi">1. 内存不足问题：单机大规模索引构建 (SPIMI)</h4>
                <p>当文档集合非常大，以至于无法在内存中一次性构建整个倒排索引时，我们怎么办？</p>
                <p>这里介绍一种广泛使用的算法：<strong>单遍在内存索引 (Single-Pass In-Memory Indexing, SPIMI)</strong>。</p>
                <p><strong>核心思想</strong>：分而治之，然后合并。</p>
                <ol>
                <li><strong>分块处理</strong>：从磁盘读取文档，在内存中构建一个“临时”倒排索引，直到内存快要用完。</li>
                <li><strong>块内排序</strong>：对这个内存中的临时索引，按<strong>词项</strong>进行字母序排序。</li>
                <li><strong>写入磁盘</strong>：将这个排好序的临时索引块完整地写入磁盘。</li>
                <li><strong>重复</strong>：清空内存，继续处理下一批文档，生成下一个排好序的索引块。</li>
                <li><strong>多路归并</strong>：当所有文档都处理完毕后，磁盘上会有一堆按词项排序的索引块。最后，执行一个<strong>多路归并排序 (multi-way merge)</strong>，将这些块合并成一个最终的、巨大的、有序的倒排索引。</li>
                </ol>
                <p>这个过程巧妙地利用了外部排序的思想，使得我们可以在有限的内存下，处理几乎无限大的文档集合。</p>
                <h4 id="2-web%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%88%86%E5%B8%83%E5%BC%8F%E7%B4%A2%E5%BC%95-distributed-indexing">2. Web级索引：分布式索引 (Distributed Indexing)</h4>
                <p>当数据量达到千亿网页级别时，单台机器无论如何也无法存储和处理。这时必须采用分布式集群。有两种主流的分布式索引策略：</p>
                <p><strong>策略一: 按词项分区 (Term-partitioned Index)</strong>
                将词典切分，分配到不同的机器上。</p>
                <ul>
                <li>
                <p>机器 A 负责 <code>a</code> - <code>c</code> 开头的词</p>
                </li>
                <li>
                <p>机器 B 负责 <code>d</code> - <code>f</code> 开头的词</p>
                </li>
                <li>
                <p>...</p>
                </li>
                <li>
                <p>机器 Z 负责 <code>x</code> - <code>z</code> 开头的词</p>
                </li>
                <li>
                <p><strong>查询处理</strong>：一个查询，如 &quot;distributed indexing&quot;，需要被分发到 &quot;d&quot; 所在的机器和 &quot;i&quot; 所在的机器，分别获取倒排列表，然后由一个聚合节点合并结果。</p>
                </li>
                <li>
                <p><strong>优缺点</strong>：并发性好，但跨节点的查询会增加网络开销和延迟。</p>
                </li>
                </ul>
                <p><strong>策略二: 按文档分区 (Document-partitioned Index)</strong>
                将文档集合切分，每台机器负责一个子集，并为这个子集建立一个<strong>完整</strong>的倒排索引。</p>
                <ul>
                <li>
                <p>机器 A 负责文档 1 ~ 1000万</p>
                </li>
                <li>
                <p>机器 B 负责文档 1001万 ~ 2000万</p>
                </li>
                <li>
                <p>...</p>
                </li>
                <li>
                <p><strong>查询处理</strong>：一个查询需要被广播到<strong>所有</strong>的机器上。每台机器在自己的索引上进行查询，返回局部结果。最后由一个聚合节点合并所有局部结果。</p>
                </li>
                <li>
                <p><strong>优缺点</strong>：扩展性极好，增加新文档只需增加新机器。查询时并行度高。这是当今大型搜索引擎（如Google）采用的主流方案，通常被称为<strong>分片 (Sharding)</strong>。</p>
                </li>
                </ul>
                <h4 id="3-%E5%8A%A8%E6%80%81%E7%B4%A2%E5%BC%95-dynamic-indexing">3. 动态索引 (Dynamic Indexing)</h4>
                <p>互联网是动态变化的，新的网页不断产生，旧的网页可能被删除或修改。我们不可能每天都重新构建整个索引。</p>
                <p>解决方案是采用 <strong>主-辅索引 (Main-Auxiliary Index)</strong> 结构。</p>
                <div class="mermaid">
                graph TD
                    subgraph Legend
                        direction LR
                        NewDocs((New Docs))
                        MainIndex[[Main Index]]
                        AuxIndex[(Auxiliary Index)]
                        SearchResults[Search Results]
                        Merge(Periodic Merge)
                    end
                    
                    NewDocs --> AuxIndex
                    MainIndex -- Query --> SearchResults
                    AuxIndex -- Query --> SearchResults
                    AuxIndex -- Merge --> MainIndex
                </div>
                <ul>
                <li><strong>主索引 (Main Index)</strong>: 一个巨大的、静态的、存储在磁盘上的索引，它不直接接受修改。</li>
                <li><strong>辅助索引 (Auxiliary Index)</strong>: 一个较小的、动态的、通常存储在内存中的索引。所有新来的文档都先被加入到这个索引中。</li>
                <li><strong>删除列表 (Deletion List)</strong>: 当一个文档被删除时，我们不立即从主索引中移除它（因为磁盘操作很慢），而是将其ID记录在一个“删除列表”中。</li>
                </ul>
                <p><strong>查询流程</strong>:</p>
                <ol>
                <li>用户发起查询。</li>
                <li>系统同时查询<strong>主索引</strong>和<strong>辅助索引</strong>。</li>
                <li>合并两边的结果。</li>
                <li>使用<strong>删除列表</strong>过滤掉已删除的文档。</li>
                <li>返回最终结果给用户。</li>
                </ol>
                <p><strong>【回答问题】</strong></p>
                <ul>
                <li>
                <p><strong>何时重建索引 (Re-index)?</strong>
                当辅助索引变得太大，或者删除列表过长时，查询性能会下降。此时，系统会触发一个<strong>合并 (Merge)</strong> 操作：将辅助索引中的内容合并到主索引中，并真正地移除被标记为删除的文档，生成一个新的、干净的主索引。这个过程在后台进行，不影响线上服务。</p>
                </li>
                <li>
                <p><strong>如何删除文档?</strong>
                采用<strong>逻辑删除</strong>。即，只将其ID加入删除列表，而不是物理删除。物理删除留到下一次合并时进行。</p>
                </li>
                </ul>
                <hr>
                <h3 id="part-5-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%8E%E8%AF%84%E4%BC%B0">Part 5: 性能优化与评估</h3>
                <h4 id="1-%E7%B4%A2%E5%BC%95%E5%8E%8B%E7%BC%A9-compression">1. 索引压缩 (Compression)</h4>
                <p>倒排索引，特别是倒排列表，会占用巨大的存储空间。压缩是必不可少的。</p>
                <ul>
                <li>
                <p><strong>词典压缩</strong>: 对于排好序的词典，相邻的词项通常有共同的前缀。可以使用<strong>前缀编码 (Front Coding)</strong> 等技术来压缩。
                <code>arrived, damaged, deliver, fire, ...</code> -&gt; <code>arrivedamagedeliverfire...</code> + 指针</p>
                </li>
                <li>
                <p><strong>倒排列表压缩</strong>: 这是压缩的重点。
                一个词的倒排列表（文档ID列表）是<strong>单调递增</strong>的。
                <code>computer</code> -&gt; <code>[2, 15, 47, ..., 58879, 58890, ...]</code></p>
                <p>我们可以不存储原始ID，而是存储ID之间的<strong>差值 (Gap / Delta)</strong>。
                <code>computer</code> -&gt; <code>[2, 13, 32, ..., (gap), 11, ...]</code></p>
                <p>这些差值通常是小数字，而小数字可以用更少的比特位来表示。<strong>可变字节编码 (Variable Byte Encoding)</strong> 或 <strong>Gamma/Delta 编码</strong>等技术就是专门用来高效存储这些小整数的。这可以极大地减少索引的磁盘占用，同时由于读取的数据量变小，也能提升I/O速度。</p>
                </li>
                </ul>
                <h4 id="2-%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E4%BC%98%E5%8C%96%E9%98%88%E5%80%BC%E6%B3%95-thresholding">2. 查询处理优化：阈值法 (Thresholding)</h4>
                <p>对于一个热门查询，可能有上百万个匹配的文档。用户只关心前10个或前20个最相关的结果。我们没有必要为所有一百万个文档都计算精确的相关性得分。</p>
                <ul>
                <li><strong>文档阈值</strong>: 只计算排名前 <code>k</code> 个文档的得分。例如，基于一些静态质量分（如PageRank）先筛选出高质量的文档，只在这些文档中进行详细匹配。</li>
                <li><strong>词项阈值</strong>: 对于一个长查询（比如10个词），我们可以先用最稀有（IDF值最高）的2-3个词进行查询，找到一个候选文档集合，然后再用剩下的词在这个小得多的集合里进行打分和过滤。</li>
                </ul>
                <h4 id="3-%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87">3. 搜索引擎的评估指标</h4>
                <p>一个搜索引擎的好坏，可以从多个维度来衡量：</p>
                <ul>
                <li><strong>效率 (Efficiency)</strong>
                <ul>
                <li><strong>索引速度</strong>: 每小时能处理多少文档？</li>
                <li><strong>查询速度 (Latency)</strong>: 返回查询结果需要多长时间？</li>
                </ul>
                </li>
                <li><strong>表达能力 (Expressiveness)</strong>
                <ul>
                <li>查询语言是否强大？能否支持复杂的布尔逻辑、短语查询、模糊查询？</li>
                </ul>
                </li>
                <li><strong>用户满意度 (User Happiness)</strong>: 这是最终极、也最难衡量的指标。</li>
                </ul>
                <p>为了量化用户满意度，信息检索领域引入了两个核心的学术指标：<strong>精确率 (Precision)</strong> 和 <strong>召回率 (Recall)</strong>。</p>
                <p>要进行评测，我们需要：</p>
                <ol>
                <li>一个标准的<strong>文档集合</strong>。</li>
                <li>一个标准的<strong>查询集合</strong>。</li>
                <li>对于每个查询，由专家<strong>人工标注</strong>出文档集中哪些是相关的，哪些是不相关的。</li>
                </ol>
                <p>然后，我们可以定义：</p>
                <ul>
                <li><strong>RR (Retrieved Relevant)</strong>: 检索到的，并且是相关的文档。</li>
                <li><strong>IR (Retrieved Irrelevant)</strong>: 检索到的，但是不相关的文档（误报）。</li>
                <li><strong>RN (Retrieved Not)</strong>: 未检索到，但是相关的文档（漏报）。</li>
                </ul>
                <div class="mermaid">
                graph TD
                    subgraph "整个文档集合"
                        subgraph "相关文档 (Relevant Docs)"
                            RR
                            RN
                        end
                        subgraph "不相关文档 (Irrelevant Docs)"
                            IR
                            IN("IN: 未检索到的不相关文档")
                        end
                        subgraph "检索到的结果 (Retrieved)"
                            style RR fill:#f9f,stroke:#333,stroke-width:2px
                            style IR fill:#ccf,stroke:#333,stroke-width:2px
                            RR
                            IR
                        end
                    end
                </div>
                <ul>
                <li>
                <p><strong>精确率 (Precision)</strong>: 在你返回的结果中，有多少是用户真正想要的？
                <strong>P = RR / (RR + IR)</strong>
                <em>追求高精确率，意味着“宁缺毋滥”。</em></p>
                </li>
                <li>
                <p><strong>召回率 (Recall)</strong>: 在所有用户想要的结果中，你返回了多少？
                <strong>R = RR / (RR + RN)</strong>
                <em>追求高召回率，意味着“宁滥勿缺”。</em></p>
                </li>
                </ul>
                <p><strong>精确率与召回率的权衡 (Precision-Recall Tradeoff)</strong>
                这两者通常是相互矛盾的。</p>
                <ul>
                <li>为了提高召回率，搜索引擎可能会放宽标准，返回更多可能相关的结果，但这也会引入更多不相关的“垃圾”，导致精确率下降。</li>
                <li>为了提高精确率，搜索引擎会采用非常严格的标准，只返回非常有把握的结果，但这可能会漏掉一些同样相关但不那么匹配的结果，导致召回率下降。</li>
                </ul>
                <p>理想的搜索引擎是在右上角（精确率和召回率都为1），但现实中我们只能在这条曲线上寻找一个平衡点。</p>
                <hr>
                <h3 id="part-6-%E6%8F%90%E5%8D%87%E7%9B%B8%E5%85%B3%E6%80%A7--%E4%B8%8D%E6%AD%A2%E6%98%AF%E5%8C%B9%E9%85%8D">Part 6: 提升相关性 —— 不止是匹配</h3>
                <p><strong>【讨论】</strong> 如何提升搜索结果的相关性？
                仅仅找到包含查询词的文档是远远不够的。我们需要对结果进行排序，把最可能满足用户需求的排在最前面。</p>
                <ol>
                <li>
                <p><strong>基于内容的排序算法：TF-IDF</strong>
                我们之前提到了词频 (TF)。一个词在文档中出现次数越多，越可能相关。但我们还需要考虑一个词的“区分度”。</p>
                <ul>
                <li><strong>TF (Term Frequency)</strong>: 词 t 在文档 d 中出现的频率。</li>
                <li><strong>IDF (Inverse Document Frequency)</strong>: 逆文档频率。一个词在越多的文档中出现，它的区分度就越低（如“的”、“是”），IDF值就越小。反之，一个词越稀有，IDF值越大。
                <strong>IDF(t) = log(总文档数 / 包含词 t 的文档数)</strong></li>
                <li><strong>TF-IDF Score</strong>: <code>Score(t, d) = TF(t, d) * IDF(t)</code>
                一个文档的总得分，可以是查询中所有词的TF-IDF得分之和。</li>
                </ul>
                </li>
                <li>
                <p><strong>基于链接分析的算法：PageRank</strong>
                Google的成名绝技。它的核心思想是：一个网页的重要性，取决于指向它的其他网页的数量和质量。一个被很多“重要”网页链接的网页，自己也很可能是一个重要的网页。PageRank是一种独立于查询的、对网页的静态质量评分。</p>
                </li>
                <li>
                <p><strong>向量空间模型 (Vector Space Model)</strong>
                将文档和查询都表示为高维空间中的一个向量，向量的每一维对应一个词，值可以是TF-IDF。然后通过计算查询向量和文档向量之间的<strong>余弦相似度 (Cosine Similarity)</strong> 来判断它们的相关性。夹角越小，相似度越高。</p>
                </li>
                <li>
                <p><strong>现代搜索引擎的综合策略</strong>
                现代搜索引擎的排序模型极其复杂，是一个综合了上百种特征（features）的机器学习模型。这些特征包括：</p>
                <ul>
                <li>内容相关性（TF-IDF, BM25等）</li>
                <li>网页质量（PageRank, TrustRank等）</li>
                <li>用户行为数据（点击率、停留时间等）</li>
                <li>查询的上下文和个性化信息（用户历史、地理位置等）</li>
                </ul>
                </li>
                </ol>
                <hr>
                <h3 id="part-7-%E5%AE%9E%E8%B7%B5%E9%A1%B9%E7%9B%AE%E4%B8%8E%E6%80%BB%E7%BB%93">Part 7: 实践项目与总结</h3>
                <h4 id="%E8%BF%B7%E4%BD%A0%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0%E4%BC%AA%E4%BB%A3%E7%A0%81">迷你搜索引擎实现伪代码</h4>
                <p>现在，让我们把今天学到的知识串起来，构思一个迷你搜索引擎的完整实现流程。</p>
                <p><strong>数据结构定义</strong></p>
                <div class="code-container">
                <pre><code class="language-cpp">// 在前面已定义
struct Posting { ... };
using PostingList = std::vector&lt;Posting&gt;;
using InvertedIndex = std::map&lt;std::string, PostingList&gt;;
</code></pre>
                </div>
                <p><strong>1. 索引构建模块 <code>buildIndex</code></strong></p>
                <div class="code-container">
                <pre><code>function buildIndex(document_collection):
    index = new InvertedIndex()
    stop_words = load_stop_words()
    doc_id = 0

    for each document in document_collection:
        doc_id++
        content = document.text
        
        // 1. 分词
        tokens = tokenize(content)
        position = 0
        
        // 统计词频
        term_frequencies = new Map&lt;string, vector&lt;int&gt;&gt;()
        
        for each token in tokens:
            position++
            
            // 2. 预处理
            normalized_token = to_lower_case(token)
            if stop_words.contains(normalized_token):
                continue
            stemmed_token = stem(normalized_token)
            
            // 记录词频和位置
            if not term_frequencies.has(stemmed_token):
                term_frequencies[stemmed_token] = new vector&lt;int&gt;()
            term_frequencies[stemmed_token].push(position)

        // 3. 更新倒排索引
        for each term, positions in term_frequencies:
            if not index.has(term):
                index[term] = new PostingList()
            
            posting = new Posting(doc_id, positions.size(), positions)
            index[term].push(posting)
            
    return index
</code></pre>
                </div>
                <p><strong>2. 查询处理模块 <code>performQuery</code></strong></p>
                <div class="code-container">
                <pre><code>function intersect_postings(list1, list2):
    // 高效的列表求交集算法（使用双指针）
    result = new PostingList()
    p1 = 0, p2 = 0
    while p1 &lt; list1.size() and p2 &lt; list2.size():
        if list1[p1].doc_id == list2[p2].doc_id:
            // 这里可以合并posting信息，但为简化，只保留一个
            result.push(list1[p1])
            p1++, p2++
        else if list1[p1].doc_id &lt; list2[p2].doc_id:
            p1++
        else:
            p2++
    return result

function performQuery(query_string, index):
    // 1. 解析查询
    query_terms = parse_and_process_query(query_string) // 分词、小写、词干化等
    
    if query_terms is empty:
        return []
    
    // 2. 获取倒排列表并求交集 (处理 AND 查询)
    result_postings = index[query_terms[0]]
    for i = 1 to query_terms.size() - 1:
        current_postings = index[query_terms[i]]
        result_postings = intersect_postings(result_postings, current_postings)
        
    // 3. 计算得分 (这里用一个简化的得分：词频之和)
    scored_results = []
    for each posting in result_postings:
        score = calculate_score(posting, query_terms, index) // e.g., TF-IDF
        scored_results.push({doc_id: posting.doc_id, score: score})

    // 4. 排序
    sort scored_results by score in descending order
    
    // 5. 返回结果
    return scored_results
</code></pre>
                </div>
            </article>
        </main>
    </div>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
    <script src="../script.js"></script>
</body>
</html>