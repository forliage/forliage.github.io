<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>计算机组成5-1:存储器层次结构</title>
    
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../modal.css">
    
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FPDBQB4LZD"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FPDBQB4LZD');
    </script>
</head>
<body>
    <audio id="bg-music" src="../music.mp3" loop></audio>
    <button id="music-toggle" class="music-control">♪</button>
    <header>
        <h1>forliage的blog</h1>
        <nav>
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../posts.html">文章</a></li>
                <li><a href="../about.html">关于</a></li>
                <li><a href="../category.html?category=技术文章">技术文章</a></li>
                <li><a href="../category.html?category=生活随笔">生活随笔</a></li>
                <li><a href="../category.html?category=学习笔记">学习笔记</a></li>
                <li><a href="../category.html?category=心情日记">心情日记</a></li>
                <li><a href="#" id="about-me-btn">ABOUT ME</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
        <div id="sidebar-container"></div>
        <main>
            <article>
                <h1 id="%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%905-1%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84">计算机组成5-1:存储器层次结构</h1>
                <p><strong>CPU与内存之间的“鸿沟”</strong></p>
                <p>在前面的章节中，我们投入了大量的精力，设计出了越来越快、越来越智能的处理器。我们学习了流水线、指令级并行、乱序执行，所有这些技术的目的只有一个——让CPU的计算核心能够在一个时钟周期内完成更多的工作。</p>
                <p>然而，一个残酷的现实摆在我们面前：<strong>一个再快的CPU，如果总是饥肠辘辘地等待数据，那它也只是一堆昂贵的“沙子”。</strong></p>
                <p>在之前的讨论中，我们一直生活在一个理想里：我们假设指令和数据可以瞬时从内存中获取。但现实是，自从计算机诞生以来，CPU的速度与主存（DRAM）的速度之间的差距，不仅没有缩小，反而在以惊人的速度<strong>持续扩大</strong>。我们称之为<strong>内存墙（Memory Wall）</strong>。</p>
                <p><img src="../images/imagec49.png" alt="figure 49"></p>
                <p>这条不断扩大的鸿沟，是现代计算机体系结构设计师面临的<strong>最核心的挑战</strong>，甚至比提升CPU本身的计算能力更为严峻。如果CPU每执行几条指令，就要花费数百个时钟周期去等待内存，那么我们之前为流水线所做的一切优化都将付诸东流。</p>
                <p>今天，我们的任务就是正面迎击这个挑战。我们将探索计算机体系结构中另一个与流水线同等重要的基石——<strong>存储器层次结构（Memory Hierarchy）</strong>。我们将学习如何利用巧妙的结构设计和深刻的程序行为洞察，为CPU构建一个<strong>既大又快</strong>的存储系统幻象。</p>
                <h3 id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E7%8E%B0%E5%AE%9E"><strong>第一部分：存储技术的现实</strong></h3>
                <p>要解决问题，首先要了解问题的根源。CPU与内存性能的鸿沟，源于底层存储技术的物理特性。我们主要关注两种核心的易失性存储技术：SRAM和DRAM。</p>
                <h4 id="11-sram-%E9%9D%99%E6%80%81%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8--%E5%BF%AB%E7%9A%84%E4%BB%A3%E8%A1%A8"><strong>1.1 SRAM (静态随机存取存储器) —— “快”的代表</strong></h4>
                <ul>
                <li><strong>工作原理</strong>：每个比特（bit）的数据，由一个包含6个晶体管（6T）的锁存器电路来存储。只要供电，这个锁存器就会稳定地维持在<code>0</code>或<code>1</code>的状态，无需刷新。
                <img src="../images/imagec50.png" alt="figure 50"></li>
                <li><strong>特性分析</strong>：
                <ul>
                <li><strong>优点：速度极快</strong>。其读写延迟非常低，通常在0.5-2.5纳秒（ns）之间，与CPU的时钟周期在同一个数量级。</li>
                <li><strong>缺点：密度低，成本高，功耗大</strong>。存储1比特就需要6个晶体管，导致单位面积能集成的容量很小，且价格昂贵，静态功耗也较高。</li>
                </ul>
                </li>
                <li><strong>应用场景</strong>：因为其“快”但“贵”且“小”的特性，SRAM是构建<strong>CPU内部高速缓存</strong>（Cache）和寄存器堆的理想材料。</li>
                </ul>
                <h4 id="12-dram-%E5%8A%A8%E6%80%81%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8--%E5%A4%A7%E7%9A%84%E4%BB%A3%E8%A1%A8"><strong>1.2 DRAM (动态随机存取存储器) —— “大”的代表</strong></h4>
                <ul>
                <li><strong>工作原理</strong>：每个比特的数据，被存储为一个微型电容器上的电荷。一个晶体管作为开关，控制对电容器的访问。
                <img src="../images/imagec51.png" alt="figure 51"></li>
                <li><strong>特性分析</strong>：
                <ul>
                <li><strong>优点：密度极高，成本低廉</strong>。1T1C（一个晶体管+一个电容）的结构，使得DRAM可以在同等芯片面积上实现比SRAM高得多的存储容量，且每比特的成本要低几个数量级。</li>
                <li><strong>缺点：速度相对较慢，且需要刷新</strong>。
                <ul>
                <li><strong>慢</strong>：读取电容上的微弱电荷是一个复杂且相对耗时的过程（50-70ns）。</li>
                <li><strong>动态特性</strong>：电容器会随时间漏电，因此存储的信息必须被周期性地<strong>刷新（Refresh）</strong>，这会带来额外的延迟和功耗。</li>
                </ul>
                </li>
                </ul>
                </li>
                <li><strong>应用场景</strong>：DRAM的“大”且“便宜”的特性，使其成为计算机<strong>主存储器</strong>（Main Memory）的不二之选。</li>
                </ul>
                <h4 id="13-%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92"><strong>1.3 存储技术的“不可能三角”</strong></h4>
                <p><img src="../images/imagec52.png" alt="figure 52"></p>
                <p>这张表格血淋淋地揭示了存储世界的残酷现实：</p>
                <ul>
                <li><strong>SRAM</strong>: 快如闪电，但每GB成本高达数千美元。</li>
                <li><strong>DRAM</strong>: 速度尚可，但比SRAM慢一个数量级，每GB成本几十美元。</li>
                <li><strong>闪存 (Flash Storage)</strong>: 非易失性（断电不丢数据），速度介于DRAM和磁盘之间，成本也居中。</li>
                <li><strong>磁盘 (Magnetic Disk)</strong>: 容量巨大，成本极低（每GB不到一美元），但速度慢得令人发指，访问延迟是DRAM的<strong>10万倍</strong>以上！</li>
                </ul>
                <p>用户的需求是贪婪的：我们想要一个<strong>像SRAM一样快，像磁盘一样大，像DRAM一样便宜</strong>的存储器。这在物理上是不可能实现的。</p>
                <p><strong>既然物理定律无法打破，我们能否通过架构的智慧，创造一个这样的“幻象”？</strong>
                答案是肯定的。而我们手中最强大的武器，就是一个深刻的、普适的程序行为规律——<strong>局部性原理</strong>。</p>
                <h3 id="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86%E9%BB%91%E6%9A%97%E4%B8%AD%E7%9A%84%E7%81%AF%E5%A1%94"><strong>第二部分：局部性原理——黑暗中的灯塔</strong></h3>
                <p>程序访问内存，并非完全随机、毫无规律可循。绝大多数程序在运行时，都表现出强烈的<strong>局部性（Locality）</strong>。这是存储器层次结构能够成功的<strong>唯一理论基石</strong>。</p>
                <h4 id="21-%E6%97%B6%E9%97%B4%E5%B1%80%E9%83%A8%E6%80%A7-temporal-locality"><strong>2.1 时间局部性 (Temporal Locality)</strong></h4>
                <ul>
                <li><strong>定义</strong>：如果一个数据项在某个时间点被访问了，那么在不久的将来，它有极大的概率会被<strong>再次访问</strong>。</li>
                <li><strong>生活化理解</strong>：你今天早上穿的鞋，明天早上大概率还会穿。</li>
                <li><strong>程序中的例子</strong>：
                <ul>
                <li><strong>循环中的指令</strong>：循环体内的指令会在每次迭代中被反复执行。</li>
                <li><strong>循环变量</strong>：如 <code>for (int i = 0; ...)</code> 中的变量 <code>i</code>。</li>
                <li><strong>栈顶附近的变量</strong>：函数调用时，局部变量和参数集中在栈顶，会被频繁访问。</li>
                <li><strong>高频使用的数据</strong>：如一个累加器变量。</li>
                </ul>
                </li>
                </ul>
                <h4 id="22-%E7%A9%BA%E9%97%B4%E5%B1%80%E9%83%A8%E6%80%A7-spatial-locality"><strong>2.2 空间局部性 (Spatial Locality)</strong></h4>
                <ul>
                <li><strong>定义</strong>：如果一个数据项被访问了，那么与它<strong>地址相邻</strong>的其他数据项，也很有可能在不久的将来被访问。</li>
                <li><strong>生活化理解</strong>：你看书时，看完了第58页，下一页大概率会看第59页，而不是随机翻到第300页。</li>
                <li><strong>程序中的例子</strong>：
                <ul>
                <li><strong>顺序执行的指令流</strong>：这是最强的空间局部性体现。</li>
                <li><strong>数组遍历</strong>：访问<code>array[i]</code>之后，通常会接着访问<code>array[i+1]</code>。</li>
                <li><strong>数据结构</strong>：结构体或类的成员变量在内存中通常是连续存放的。</li>
                </ul>
                </li>
                </ul>
                <p><strong>局部性原理的启示</strong>：
                程序在任何一小段时间内，实际访问的，只是其庞大地址空间中一个非常小的、集中的“<strong>工作集（Working Set）</strong>”。这个洞察，为我们打破存储技术的“不可能三角”指明了方向。</p>
                <h3 id="%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E6%9E%84%E5%BB%BA%E5%8F%88%E5%A4%A7%E5%8F%88%E5%BF%AB%E7%9A%84%E5%B9%BB%E8%B1%A1"><strong>第三部分：存储器层次结构——构建“又大又快”的幻象</strong></h3>
                <p>既然程序访问具有局部性，我们就可以构建一个存储器金字塔，来“欺骗”CPU。</p>
                <h4 id="31-%E8%AE%BE%E8%AE%A1%E5%93%B2%E5%AD%A6%E4%B8%8E%E7%BB%93%E6%9E%84"><strong>3.1 设计哲学与结构</strong></h4>
                <p><strong>核心思想</strong>：将存储系统组织成一个层次化的结构。越靠近CPU的层次，其存储介质<strong>越快、越小、越贵</strong>；越远离CPU的层次，则<strong>越慢、越大、越便宜</strong>。</p>
                <p><img src="../images/imagec53.png" alt="figure 53"></p>
                <p>一个典型的存储器层次结构：</p>
                <ul>
                <li><strong>L0: CPU寄存器</strong> (SRAM)</li>
                <li><strong>L1 Cache (一级缓存)</strong>: 通常在CPU核心内部，使用最快的SRAM。容量极小（几十KB）。</li>
                <li><strong>L2 Cache (二级缓存)</strong>: 通常也在CPU芯片上，使用速度稍慢但容量更大的SRAM。容量几百KB到几MB。</li>
                <li><strong>L3 Cache (三级缓存)</strong>: 在现代多核CPU中常见，被所有核心共享，容量更大（几MB到几十MB）。</li>
                <li><strong>主存 (Main Memory)</strong>: (DRAM) 容量巨大（几GB到几百GB）。</li>
                <li><strong>本地二级存储</strong>: (闪存SSD / 磁盘HDD) 非易失性，容量TB级别。</li>
                <li><strong>远程二级存储</strong>: (分布式文件系统 / 云存储)</li>
                </ul>
                <p><strong>工作原理</strong>：
                整个层次结构作为一个整体工作。数据在相邻层次之间以**块（Block）**为单位进行复制和移动。</p>
                <ul>
                <li>当CPU需要一个数据时，它首先访问最顶层的L1 Cache。</li>
                <li><strong>如果数据在L1中（命中，Hit）</strong>，CPU直接获取，速度极快。</li>
                <li><strong>如果数据不在L1中（缺失，Miss）</strong>，则访问下一层L2 Cache。</li>
                <li><strong>如果在L2中命中</strong>，则将包含该数据的整个<strong>块</strong>从L2复制到L1，然后再提供给CPU。</li>
                <li><strong>如果L2也缺失</strong>，则继续访问L3，乃至主存。</li>
                <li>这个过程一直向下，直到找到数据为止。然后，数据块会沿着层次结构，被一级一级地复制上来，最终到达L1 Cache和CPU。</li>
                </ul>
                <p><strong>为什么这个机制有效？</strong></p>
                <ul>
                <li><strong>利用时间局部性</strong>：一旦一个数据块被调入高层缓存，它会在那里停留一段时间。根据时间局部性，它很可能会被CPU反复访问，而这些后续的访问都将是高速的“命中”。</li>
                <li><strong>利用空间局部性</strong>：我们不只是把CPU需要的那个字节调入缓存，而是把它所在的整个“块”（通常是64字节）都调入。根据空间局部性，CPU接下来很可能会访问这个块中的其他数据，这些访问也将是高速的“命中”。</li>
                </ul>
                <h4 id="32-%E5%85%B3%E9%94%AE%E6%9C%AF%E8%AF%AD%E4%B8%8E%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><strong>3.2 关键术语与性能度量</strong></h4>
                <p>理解存储层次结构，必须掌握以下几个核心概念：</p>
                <ul>
                <li><strong>块 (Block) / 行 (Line)</strong>：在相邻层次之间传输数据的最小单位。块越大，越能利用空间局部性，但如果利用不好，也会浪费带宽。</li>
                <li><strong>命中 (Hit)</strong>：CPU要访问的数据在当前层次的缓存中找到了。</li>
                <li><strong>缺失 (Miss)</strong>：在当前层次没找到，需要去更低、更慢的层次寻找。</li>
                <li><strong>命中率 (Hit Rate)</strong>：命中次数 / 总访问次数。这是衡量缓存效率的最重要指标。</li>
                <li><strong>缺失率 (Miss Rate)</strong>：1 - 命中率。</li>
                <li><strong>命中时间 (Hit Time)</strong>：访问当前层次并确定是命中的时间。包括地址比较、数据读取等。对于L1 Cache，通常是1-4个时钟周期。</li>
                <li><strong>缺失代价 (Miss Penalty)</strong>：从下一层存储把数据块调入当前层，并最终送给CPU所需的时间。这是性能瓶颈所在，可能高达数百个时钟周期。</li>
                </ul>
                <p><strong>性能的最终衡量指标：平均访存时间 (AMAT)</strong>
                $$
                \text{AMAT} = \text{Hit Time} + \text{Miss Rate} \times \text{Miss Penalty}
                $$
                这个公式是整个存储器层次结构性能分析的基石。我们的所有优化手段，最终都是为了<strong>降低AMAT</strong>。途径有三：</p>
                <ol>
                <li><strong>降低Hit Time</strong>（如使用更简单的Cache设计）</li>
                <li><strong>降低Miss Rate</strong>（如使用更大的Cache、更聪明的放置策略）</li>
                <li><strong>降低Miss Penalty</strong>（如使用多级缓存、高速总线）</li>
                </ol>
                <h3 id="%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E7%BC%93%E5%AD%98cache%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E8%AE%BE%E8%AE%A1"><strong>第四部分：缓存（Cache）的基本原理与设计</strong></h3>
                <p>现在，让我们聚焦于存储层次结构中与CPU关系最密切的部分——<strong>缓存（Cache）</strong>。它通常指CPU与主存之间的SRAM缓存（L1, L2, L3）。</p>
                <p>缓存的设计，必须回答四个核心问题，这四个问题定义了所有缓存的形态：</p>
                <ol>
                <li><strong>块放置 (Block Placement)</strong>：一个从主存取来的块，可以放在缓存的哪个位置？</li>
                <li><strong>块识别 (Block Identification)</strong>：当CPU给出一个地址时，如何快速判断它所对应的块是否在缓存中，以及在哪个位置？</li>
                <li><strong>块替换 (Block Replacement)</strong>：当发生缺失，且缓存中没有空闲位置时，应该把哪个旧的块替换出去？</li>
                <li><strong>写策略 (Write Strategy)</strong>：当CPU执行写操作时，数据应该如何更新到缓存和主存中，以保证数据的一致性？</li>
                </ol>
                <p>今天，我们首先深入探讨最简单的一种缓存设计，来初步回答前两个问题。</p>
                <h4 id="41-%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84%E7%BC%93%E5%AD%98-direct-mapped-cache"><strong>4.1 直接映射缓存 (Direct Mapped Cache)</strong></h4>
                <p>这是最简单、最基础的缓存放置策略。</p>
                <ul>
                <li>
                <p><strong>放置策略</strong>：一个主存块，只能被放置到缓存中的<strong>一个唯一确定的位置</strong>。</p>
                </li>
                <li>
                <p><strong>映射规则</strong>：
                $$
                (\text{Cache Block Index}) = (\text{Memory Block Address}) \pmod (\text{Number of Blocks in Cache})
                $$
                即，用主存的块号对缓存的总块数取模。</p>
                </li>
                <li>
                <p><strong>硬件实现的巧妙简化</strong>：如果缓存的块数是$2^n$，那么取模运算就可以简化为<strong>取主存块地址的低n位</strong>。这使得地址到索引的映射在硬件上实现起来极其简单和快速，只需要进行地址位的截取，无需任何计算。</p>
                </li>
                </ul>
                <p><img src="../images/imagec54.png" alt="figure 54"></p>
                <h4 id="42-%E5%9D%97%E8%AF%86%E5%88%AB%E6%A0%87%E7%AD%BE-tag-%E4%B8%8E%E6%9C%89%E6%95%88%E4%BD%8D-valid-bit"><strong>4.2 块识别：标签 (Tag) 与有效位 (Valid Bit)</strong></h4>
                <p>仅仅通过索引定位到缓存中的一个位置是不够的。因为多个不同的主存块（例如块1、块9、块17，如果缓存有8块）都可能映射到同一个缓存索引（索引1）。我们必须能够区分，当前这个位置上存的到底是哪一个。</p>
                <ul>
                <li>
                <p><strong>解决方案：标签 (Tag)</strong></p>
                <ul>
                <li>我们在缓存的每一行，除了存储数据块本身，还需要额外存储一个<strong>标签</strong>。</li>
                <li>这个标签存储了该数据块原始的<strong>主存块地址的高位部分</strong>。</li>
                <li>当CPU访问一个地址时：
                <ol>
                <li>使用地址的<strong>索引位</strong>，定位到缓存中的某一行。</li>
                <li><strong>并行地</strong>，将地址的<strong>标签位</strong>与该行存储的标签进行<strong>比较</strong>。</li>
                <li>如果两者<strong>相等</strong>，并且...</li>
                </ol>
                </li>
                </ul>
                </li>
                <li>
                <p><strong>引入有效位 (Valid Bit)</strong></p>
                <ul>
                <li>还有一个问题：缓存刚加电时，里面是无效的垃圾数据。或者某个位置可能从未被使用过。</li>
                <li>我们为每一行增加一个<strong>有效位</strong>。当一个有效的数据块被加载进来时，该位置为<code>1</code>；初始状态或被替换后，置为<code>0</code>。</li>
                <li><strong>最终的命中条件</strong>：当索引匹配，<strong>并且</strong>标签匹配，<strong>并且</strong>有效位为<code>1</code>时，才算是一次真正的<strong>命中</strong>。</li>
                </ul>
                </li>
                </ul>
                <h4 id="43-%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%92%E5%88%86"><strong>4.3 地址的划分</strong></h4>
                <p>对于一个直接映射缓存，CPU发出的物理地址被划分为三个部分：
                <img src="../images/imagec55.png" alt="figure 55"></p>
                <ul>
                <li><strong>标签 (Tag)</strong>：地址的高位，用于与缓存行中的标签进行比较。</li>
                <li><strong>索引 (Index)</strong>：地址的中间位，用于选择缓存中的哪一行。</li>
                <li><strong>块内偏移 (Byte Offset)</strong>：地址的低位，用于在一个块中选择所需的字节。 (如果块大小大于一个字节)</li>
                </ul>
                <h4 id="44-%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84%E7%BC%93%E5%AD%98%E8%AE%BF%E9%97%AE%E7%A4%BA%E4%BE%8B"><strong>4.4 一个完整的直接映射缓存访问示例</strong></h4>
                <p>假设我们有一个8块、每块1个字的直接映射缓存。访存序列为：10110, 11010, 10110, ... (二进制地址)
                <img src="../images/imagec56.png" alt="figure 56"></p>
                <ol>
                <li>
                <p><strong>访问 10110</strong>:</p>
                <ul>
                <li>地址分解：Tag=<code>10</code>, Index=<code>110</code>。</li>
                <li>检查索引<code>110</code>的缓存行。有效位为<code>N</code>(无效)。<strong>Miss!</strong></li>
                <li>从主存地址<code>10110</code>处取出数据，存入索引<code>110</code>的数据区。</li>
                <li>将Tag=<code>10</code>写入该行的标签区。</li>
                <li>将有效位置为<code>Y</code>。
                <img src="../images/imagec57.png" alt="figure 57"></li>
                </ul>
                </li>
                <li>
                <p><strong>访问 11010</strong>:</p>
                <ul>
                <li>地址分解：Tag=<code>11</code>, Index=<code>010</code>。</li>
                <li>检查索引<code>010</code>的缓存行。有效位为<code>N</code>。<strong>Miss!</strong></li>
                <li>加载数据，更新Tag=<code>11</code>，有效位置<code>Y</code>。
                <img src="../images/imagec58.png" alt="figure 58"></li>
                </ul>
                </li>
                <li>
                <p><strong>访问 10110 (第二次)</strong>:</p>
                <ul>
                <li>地址分解：Tag=<code>10</code>, Index=<code>110</code>。</li>
                <li>检查索引<code>110</code>的缓存行。有效位为<code>Y</code>。</li>
                <li>比较地址的Tag(<code>10</code>)与该行存储的Tag(<code>10</code>)。<strong>相等！</strong></li>
                <li><strong>Hit!</strong> 直接从缓存中返回数据。
                <img src="../images/imagec59.png" alt="figure 59">
                <img src="../images/imagec60.png" alt="figure 60"></li>
                </ul>
                </li>
                <li>
                <p><strong>访问 10010 (冲突示例)</strong>:</p>
                <ul>
                <li>地址分解：Tag=<code>10</code>, Index=<code>010</code>。</li>
                <li>检查索引<code>010</code>的缓存行。有效位为<code>Y</code>，Tag=<code>11</code>。</li>
                <li>比较地址的Tag(<code>10</code>)与存储的Tag(<code>11</code>)。<strong>不相等！</strong></li>
                <li><strong>Miss!</strong> 这种情况我们称之为<strong>冲突缺失 (Conflict Miss)</strong>。虽然缓存还有空位，但因为<code>11010</code>和<code>10010</code>不幸地映射到了同一个索引，发生了“争地盘”的现象。</li>
                <li>旧的数据（来自<code>11010</code>）被<strong>替换</strong>掉。新的数据（来自<code>10010</code>）和新的Tag(<code>10</code>)被写入该行。
                <img src="../images/imagec61.png" alt="figure 61"></li>
                </ul>
                </li>
                </ol>
                <p><strong>小结</strong>：直接映射缓存的设计非常简单，硬件实现速度快（只需要一次比较）。但它的缺点也很明显——冲突缺失率可能较高，即使在缓存远未满的情况下，频繁访问映射到同一索引的地址也会导致缓存的剧烈抖动（Thrashing）。</p>
            </article>
        </main>
    </div>
    
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
    <script src="../script.js"></script>
    <!-- The Modal -->
    <div id="about-me-modal" class="modal">
      <!-- Modal content -->
      <div class="modal-content">
        <span class="close-button">&times;</span>
        <h2>About Me</h2>
        <p>This is forliage, an undergraduate student of computer science and technology at Zhejiang University.</p>
        <p><strong>Motto:</strong> People always say that time heals all wounds, but I don't believe that. Time doen't heal the pain, it just makes us get used to pain. When you lose someone, you don't really forget them; you just learn how to live on without them.</p>
        <p><strong>Interests:</strong> Computer Graphics, Computer Version, Computer Animation, HPC, AIGC</p>
        <p><strong>Favorite Movie:</strong> The Shawshank Redemption, Dead Poets Society, Zootopia</p>
        <p><strong>Favorite Music:</strong> Blank Space, Sorega Daiji, Counting Stars, Whataya Want from Me</p>
        <p><strong>Contact Information:</strong>masterforliage@gmail.com</p>
        <hr>
        <h3>订阅我的博客</h3>
        <p>订阅功能正在建设中，敬请期待！</p>
      </div>
    </div>
    <script src="../modal.js"></script>
</body>
</html>