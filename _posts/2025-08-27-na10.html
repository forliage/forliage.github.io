<!DOCTYPE html>

<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<title>数值分析10:数值微积分与最佳多项式逼近</title>
<link href="../style.css" rel="stylesheet"/>
<link href="../modal.css" rel="stylesheet"/>
<script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" type="text/javascript">
</script>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FPDBQB4LZD"></script>
<script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FPDBQB4LZD');
    </script>
</head>
<body>
<audio id="bg-music" loop="" src="../music.mp3"></audio>
<button class="music-control" id="music-toggle">♪</button><button class="dark-mode-control" id="dark-mode-toggle">🌙</button>
<header>
<h1>forliage的blog</h1>
<nav>
<ul>
<li><a href="../index.html">首页</a></li>
<li><a href="../posts.html">文章</a></li>
<li><a href="../about.html">关于</a></li>
<li><a href="../category.html?category=技术文章">技术文章</a></li>
<li><a href="../category.html?category=生活随笔">生活随笔</a></li>
<li><a href="../category.html?category=学习笔记">学习笔记</a></li>
<li><a href="../category.html?category=心情日记">心情日记</a></li>
<li><a href="#" id="about-me-btn">ABOUT ME</a></li>
</ul>
</nav>
</header>
<div class="container">
<div id="sidebar-container"></div>
<main>
<article>
<h1 id="%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%9010%E6%95%B0%E5%80%BC%E5%BE%AE%E7%A7%AF%E5%88%86%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%80%BC%E8%BF%91">数值分析10:数值微积分与最佳多项式逼近</h1>
<h3 id="%E5%BC%95%E8%A8%80%E4%BB%8E%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91%E5%88%B0%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C"><strong>引言：从函数逼近到函数操作</strong></h3>
<p>在过去的几讲中，我们花了大量时间探讨一个核心主题：<strong>函数逼近</strong>。无论是通过<strong>插值</strong>（拉格朗日、牛顿、样条）来精确穿过数据点，还是通过<strong>最小二乘法</strong>来拟合含噪声数据的整体趋势，我们的目标都是用一个“简单”的函数（主要是多项式）去“代替”一个“复杂”或未知的函数。</p>
<p>今天，我们将把这一思想推向其逻辑上的下一个阶段：我们为什么要逼近函数？一个非常重要的原因就是为了对它们进行<strong>微积分操作</strong>。</p>
<ul>
<li>如果我们只有一个函数的离散数据点，我们如何估算它在某一点的<strong>导数</strong>？</li>
<li>如果一个函数的原函数无法用初等函数表示（例如 $e^{-x^2}$），我们如何计算它在某个区间上的<strong>定积分</strong>？</li>
</ul>
<p>答案很简单：<strong>我们不对原始的复杂函数进行操作，而是对它的简单逼近函数（比如插值多项式）进行操作。</strong> 这就是<strong>数值微分 (Numerical Differentiation)</strong> 和<strong>数值积分 (Numerical Integration)</strong> 的基本思想。</p>
<p>课程的第一部分，我们将探讨数值微分。我们会发现，这是一个非常“微妙”甚至有些“危险”的过程。一个看似自然的近似方法，可能会因为对舍入误差的极度敏感而变得非常<strong>不稳定</strong>。</p>
<p>课程的第二部分，我们将转向数值积分，也称为<strong>数值求积 (Numerical Quadrature)</strong>。幸运的是，积分在数学上是一个“平滑”或“平均”的过程，因此数值积分方法通常具有非常好的<strong>稳定性</strong>和<strong>收敛性</strong>。我们将从最基础的牛顿-柯特斯公式（梯形法则、辛普森法则）入手。</p>
<p>最后，课程的第三部分，我们将回到逼近理论的一个巅峰话题。在最小二乘法中，我们最小化了<strong>L2范数</strong>下的误差（平方误差和）。但是，如果我们想让逼近多项式在整个区间上的<strong>最大误差</strong>（<strong>L∞范数</strong>）最小化，该怎么做？这个问题，即<strong>minimax问题</strong>，引出了数值分析中最优雅、最深刻的理论之一，以及一类极其重要的特殊函数——<strong>切比雪夫多项式 (Chebyshev Polynomials)</strong>。我们将看到，这些多项式不仅是minimax问题的答案，还能帮助我们解决龙格现象，并引出一种被称为<strong>幂级数经济化</strong>的巧妙技术。</p>
<h3 id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86%E4%B8%80%E4%B8%AA%E7%97%85%E6%80%81%E7%9A%84%E9%97%AE%E9%A2%98"><strong>第一部分：数值微分——一个“病态”的问题</strong></h3>
<h4 id="41-%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E4%B8%8E%E4%BD%8E%E9%98%B6%E5%85%AC%E5%BC%8F"><strong>4.1 基本思想与低阶公式</strong></h4>
<p><strong>核心思想：</strong>
                给定函数 $f(x)$，我们想近似 $f'(x_0)$。最直接的来源是导数的极限定义：
                $$f'(x_0) = \lim_{h \to 0} \frac{f(x_0+h) - f(x_0)}{h}$$</p>
<p>如果我们取一个很小但非零的 $h$，就可以得到近似公式。</p>
<p><strong>1. 前向差分公式 (Forward-Difference Formula):</strong>
                $$f'(x_0) \approx \frac{f(x_0+h) - f(x_0)}{h}$$
                几何上，这是用连接点 $(x_0, f(x_0))$ 和 $(x_0+h, f(x_0+h))$ 的<strong>割线斜率</strong>来近似点 $x_0$ 处的<strong>切线斜率</strong>。</p>
<p><strong>2. 后向差分公式 (Backward-Difference Formula):</strong>
                $$f'(x_0) \approx \frac{f(x_0) - f(x_0-h)}{h}$$
                这是用点 $(x_0-h, f(x_0-h))$ 和 $(x_0, f(x_0))$ 的割线斜率来近似。</p>
<p><strong>误差分析：</strong>
                这些公式的精度如何？我们可以用泰勒展开来分析。将 $f(x_0+h)$ 在 $x_0$ 处展开：
                $$f(x_0+h) = f(x_0) + f'(x_0)h + \frac{f''(\xi)}{2}h^2$$
                整理后得到：
                $$\frac{f(x_0+h) - f(x_0)}{h} = f'(x_0) + \frac{f''(\xi)}{2}h$$
                <strong>截断误差 (Truncation Error):</strong>
                $$f'(x_0) - \left[\frac{f(x_0+h) - f(x_0)}{h}\right] = -\frac{f''(\xi)}{2}h = O(h)$$
                前向和后向差分公式的截断误差都是 $h$ 的一阶，我们称之为<strong>一阶方法</strong>。这意味着，如果步长 $h$ 减半，误差大约也减半，收敛速度很慢。</p>
<p><strong>3. 中心差分公式 (Central-Difference Formula):</strong>
                有没有更好的方法？我们可以组合两个泰勒展开：
                $$f(x_0+h) = f(x_0) + f'(x_0)h + \frac{f''(x_0)}{2}h^2 + \frac{f'''(\xi_1)}{6}h^3$$
                $$f(x_0-h) = f(x_0) - f'(x_0)h + \frac{f''(x_0)}{2}h^2 - \frac{f'''(\xi_2)}{6}h^3$$
                两式相减：
                $$f(x_0+h) - f(x_0-h) = 2f'(x_0)h + \frac{f'''(\xi_1)+f'''(\xi_2)}{6}h^3$$
                整理得到：
                $$f'(x_0) = \underbrace{\frac{f(x_0+h) - f(x_0-h)}{2h}}_{\text{中心差分公式}} - \underbrace{\frac{f'''(\xi)}{6}h^2}_{\text{截断误差}}$$
                中心差分公式的截断误差是 $O(h^2)$，是一个<strong>二阶方法</strong>！步长 $h$ 减半，误差会减小到原来的四分之一，精度远高于前向/后向差分。这是最常用的数值微分公式之一。</p>
<h4 id="411-%E9%AB%98%E9%98%B6%E5%85%AC%E5%BC%8F%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%8E%A8%E5%AF%BC"><strong>4.1.1 高阶公式的系统推导</strong></h4>
<p>如何系统地推导更高阶的公式？
                <strong>方法：</strong> 用 $n+1$ 个点的<strong>拉格朗日插值多项式</strong> $P_n(x)$ 及其误差项 $R_n(x)$ 来逼近 $f(x)$，然后对整个表达式求导：
                $$f(x) = \sum_{k=0}^n f(x_k)L_k(x) + \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k)$$
                $$f'(x) = \sum_{k=0}^n f(x_k)L'_k(x) + \frac{d}{dx}\left[ \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k) \right]$$
                当 $x$ 是一个插值节点 $x_j$ 时，对误差项求导变得复杂。但这个方法给出了推导各种差分公式的统一框架。</p>
<p><strong>例如 (Discussion 26):</strong>
                使用点 $x_0, x_0+h, x_0+2h$ 构造二次插值多项式，然后求导并分别在三个点上取值，可以得到三个不同的<strong>三点公式</strong>。</p>
<ul>
<li>$f'(x_0) = \frac{1}{2h}[-3f(x_0) + 4f(x_0+h) - f(x_0+2h)] + \frac{h^2}{3}f'''(\xi)$</li>
<li>$f'(x_0+h) = \frac{1}{2h}[f(x_0+2h) - f(x_0)]$ (这正是以 $x_0+h$ 为中心的中心差分公式！)</li>
<li>$f'(x_0+2h) = \frac{1}{2h}[f(x_0) - 4f(x_0+h) + 3f(x_0+2h)] + \frac{h^2}{3}f'''(\xi)$</li>
</ul>
<p>可以看到，中心点公式的截断误差项系数（$1/6$）比端点公式（$1/3$）更小，因此精度更高。</p>
<h4 id="412-%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86%E7%9A%84%E4%B8%8D%E7%A8%B3%E5%AE%9A%E6%80%A7"><strong>4.1.2 数值微分的不稳定性</strong></h4>
<p>"numerical differentiation is unstable!" 为什么？
                让我们重新审视中心差分公式。在计算机上，我们计算的函数值 $f(x_0\pm h)$ 并非精确值，而是带有舍入误差的 $\tilde{f}(x_0\pm h)$。设 $|f(x) - \tilde{f}(x)| \le \epsilon$。
                我们实际计算的导数是：
                $$\tilde{f}'(x_0) = \frac{\tilde{f}(x_0+h) - \tilde{f}(x_0-h)}{2h}$$
                总误差 = 截断误差 + 舍入误差
                $$|f'(x_0) - \tilde{f}'(x_0)| \le \left| \frac{f'''(\xi)}{6}h^2 \right| + \left| \frac{(f(x_0+h)-\tilde{f}(x_0+h)) - (f(x_0-h)-\tilde{f}(x_0-h))}{2h} \right|$$
                $$|f'(x_0) - \tilde{f}'(x_0)| \le \frac{M_3}{6}h^2 + \frac{\epsilon+\epsilon}{2h} = \frac{M_3}{6}h^2 + \frac{\epsilon}{h}$$</p>
<p><strong>误差行为分析：</strong></p>
<ul>
<li>当步长 $h$ 减小时，<strong>截断误差</strong> ($\propto h^2$) 减小。</li>
<li>当步长 $h$ 减小时，<strong>舍入误差</strong> ($\propto 1/h$) <strong>增大</strong>！</li>
</ul>
<p>这是一个致命的矛盾。我们不能像在数学理论中那样让 $h$ 任意趋于0。存在一个<strong>最优步长 $h_{opt}$</strong>，使得总误差最小。小于这个 $h$，舍入误差将占主导，结果会越来越差！这就是<strong>数值微分的不稳定性</strong>。它对输入数据的噪声（在此即为舍入误差）非常敏感。</p>
<h4 id="42-%E4%BA%8C%E9%98%B6%E5%AF%BC%E6%95%B0%E8%BF%91%E4%BC%BC"><strong>4.2 二阶导数近似</strong></h4>
<p>类似地，我们可以通过组合泰勒展开来推导二阶导数的公式 (Discussion 27)。
                $$f(x_0+h) = f(x_0) + f'(x_0)h + \frac{f''(x_0)}{2}h^2 + \frac{f'''(x_0)}{6}h^3 + O(h^4)$$
                $$f(x_0-h) = f(x_0) - f'(x_0)h + \frac{f''(x_0)}{2}h^2 - \frac{f'''(x_0)}{6}h^3 + O(h^4)$$
                两式相加：
                $$f(x_0+h) + f(x_0-h) = 2f(x_0) + f''(x_0)h^2 + O(h^4)$$
                整理得到：
                $$f''(x_0) = \frac{f(x_0+h) - 2f(x_0) + f(x_0-h)}{h^2} - \frac{h^2}{12}f^{(4)}(\xi)$$
                这是一个 $O(h^2)$ 精度的<strong>中心差分公式</strong>，用于近似二阶导数。它同样面临着 $1/h^2$ 形式的舍入误差放大问题，比一阶导数更不稳定。</p>
<h3 id="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86%E4%B8%80%E4%B8%AA%E7%A8%B3%E5%AE%9A%E7%9A%84%E8%BF%87%E7%A8%8B"><strong>第二部分：数值积分——一个“稳定”的过程</strong></h3>
<h4 id="43-%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E6%8F%92%E5%80%BC%E5%9E%8B%E6%B1%82%E7%A7%AF"><strong>4.3 基本思想：插值型求积</strong></h4>
<p><strong>核心思想：</strong>
                我们想计算 $I = \int_a^b f(x)dx$。</p>
<ol>
<li>
<p>在 $[a,b]$ 上选择 $n+1$ 个节点 $x_0, \dots, x_n$。</p>
</li>
<li>
<p>构造一个穿过这些点的插值多项式 $P_n(x)$。</p>
</li>
<li>
<p>用 $P_n(x)$ 的积分来近似 $f(x)$ 的积分：</p>
<p>
                $$
                \begin{aligned}
                I &amp;= \int_a^b f(x)dx \approx \int_a^b P_n(x)dx = \int_a^b \sum_{k=0}^n f(x_k)L_k(x)dx \\
                &amp;= \sum_{k=0}^n f(x_k) \underbrace{\int_a^b L_k(x)dx}_{A_k} = \sum_{k=0}^n A_k f(x_k)
                \end{aligned}
                $$
                </p>
</li>
</ol>
<p>这个形式被称为<strong>插值型求积公式 (Interpolatory Quadrature)</strong>。$x_k$ 称为<strong>节点 (nodes)</strong>，$A_k$ 称为<strong>权 (weights) 或 Cotes 系数</strong>。
                数值积分的本质就是用一个<strong>带权和</strong>来近似积分值。</p>
<p><strong>误差分析：</strong>
                $$
                \begin{aligned}
                Error &amp;= \int_a^b f(x)dx - \int_a^b P_n(x)dx = \int_a^b (f(x)-P_n(x))dx = \int_a^b R_n(x)dx \\
                &amp;= \int_a^b \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k) dx
                \end{aligned}
                $$</p>
<p>与微分不同，积分是一个平均过程，它会“平滑”掉函数值的微小误差。因此，数值积分方法通常是<strong>非常稳定</strong>的。</p>
<h4 id="431-newton-cotes-%E5%85%AC%E5%BC%8F"><strong>4.3.1 Newton-Cotes 公式</strong></h4>
<p>这是一族最经典的求积公式，它们基于在 $[a,b]$ 区间上取<strong>等距节点</strong>。</p>
<p><strong>1. 梯形法则 (Trapezoidal Rule, n=1):</strong>
                使用两个端点 $x_0=a, x_1=b$ 进行线性插值。
                $$A_0 = \int_a^b L_0(x)dx = \int_a^b \frac{x-b}{a-b}dx = \frac{b-a}{2}$$
                $$A_1 = \int_a^b L_1(x)dx = \int_a^b \frac{x-a}{b-a}dx = \frac{b-a}{2}$$
                <strong>公式：</strong> $\int_a^b f(x)dx \approx \frac{b-a}{2}[f(a)+f(b)]$
                <strong>误差：</strong> $E_T = -\frac{(b-a)^3}{12}f''(\xi) = O(h^3)$
                <strong>精度 (Degree of Precision):</strong> 一个求积公式的精度是指它能精确积分的最高次多项式的次数。梯形法则是对线性函数精确的，所以其<strong>精度为1</strong>。</p>
<p><strong>2. 辛普森法则 (Simpson's Rule, n=2):</strong>
                使用三个点 $x_0=a, x_1=(a+b)/2, x_2=b$ 进行二次插值。
                <strong>公式：</strong> $\int_a^b f(x)dx \approx \frac{b-a}{6}\left[f(a) + 4f\left(\frac{a+b}{2}\right) + f(b)\right]$
                <strong>误差：</strong> $E_S = -\frac{(b-a)^5}{2880}f^{(4)}(\xi) = O(h^5)$
                <strong>精度：</strong> 令人惊讶的是，辛普森法则不仅对二次多项式精确，对<strong>三次多项式也精确</strong>！所以其<strong>精度为3</strong>。这种精度的“意外”提升是由于误差项中奇数阶导数项的对称性抵消造成的。</p>
<p><strong>更高阶的Newton-Cotes公式</strong>（如Simpson's 3/8 Rule, Boole's Rule）可以类似推导，但它们在高阶时可能出现负权，导致数值不稳定，因此不常用。实用的做法是将低阶公式进行复合。</p>
<h3 id="%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%9C%80%E4%BD%B3%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%80%BC%E8%BF%91%E4%B8%8E%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%9A%E9%A1%B9%E5%BC%8F"><strong>第三部分：最佳多项式逼近与切比雪夫多项式</strong></h3>
<h4 id="831-minimax-%E9%80%BC%E8%BF%91%E9%97%AE%E9%A2%98"><strong>8.3.1 Minimax 逼近问题</strong></h4>
<p>我们已经学习了最小二乗（L2）逼近。现在我们考虑一个更严格的逼近标准：<strong>最小化最大误差（L∞）</strong>。</p>
<p><strong>Minimax 问题:</strong>
                给定函数 $f(x)$，在所有次数不超过 $n$ 的多项式 $\Pi_n$ 中，找到那个 $P_n^*(x)$，使得<strong>一致范数（或无穷范数）</strong> $||f - P_n||_\infty = \max_{x \in [a,b]} |f(x) - P_n(x)|$ 达到最小。</p>
<p><strong>切比雪夫等振荡定理 (Chebyshev's Equioscillation Theorem):</strong>
                这个问题的解 $P_n^*(x)$ 存在且唯一，其充要条件是误差函数 $E(x)=f(x)-P_n^*(x)$ 在区间 $[a,b]$ 上至少有 <strong>$n+2$ 个点</strong>，在这些点上误差达到其最大值（或最小值），并且<strong>正负交替</strong>。
                这些点被称为<strong>切比雪夫交错点组 (Chebyshev Alternating Set)</strong>。</p>
<h4 id="832-%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%9A%E9%A1%B9%E5%BC%8F"><strong>8.3.2 切比雪夫多项式</strong></h4>
<p>如何找到这个最佳逼近多项式？直接构造非常困难。但切比雪夫找到了一个相关问题的巧妙解。</p>
<p><strong>问题 (v 3.0):</strong> 在所有次数为 $n-1$ 的多项式中，找到 $P_{n-1}(x)$，使得 $||x^n - P_{n-1}(x)||_\infty$ 在 $[-1,1]$ 上最小。
                这等价于寻找一个<strong>首项系数为1 (monic) 的 $n$ 次多项式</strong>，使其在 $[-1,1]$ 上的无穷范数最小。</p>
<p><strong>切比雪夫的洞察：</strong>
                考虑函数 $T_n(x) = \cos(n \arccos x)$。</p>
<ul>
<li>通过变量替换 $x=\cos\theta$，我们有 $T_n(\cos\theta) = \cos(n\theta)$。</li>
<li>利用三角恒等式，可以证明 $T_n(x)$ 是一个关于 $x$ 的 $n$ 次多项式。
                $T_0(x)=1, T_1(x)=x, T_{n+1}(x)=2xT_n(x)-T_{n-1}(x)$。</li>
<li>$T_n(x)$ 的首项系数是 $2^{n-1}$。</li>
<li>在 $[-1,1]$ 区间内，$\cos(n\theta)$ 的值在 $+1$ 和 $-1$ 之间振荡。它在 $n+1$ 个点上达到其极值 $\pm 1$，并且正负交替！</li>
</ul>
<p>这完美地满足了等振荡定理的要求！
                因此，使得 $||x^n - P_{n-1}(x)||_\infty$ 最小的那个多项式正是<strong>缩放后的切比雪夫多项式</strong>：
                $$\tilde{T}_n(x) = \frac{1}{2^{n-1}} T_n(x)$$
                这个多项式的最小最大值为 $\frac{1}{2^{n-1}}$。</p>
<h4 id="833-%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8"><strong>8.3.3 切比雪夫多项式的应用</strong></h4>
<p><strong>1. 最佳插值节点的选择:</strong>
                回顾插值误差公式：$|f(x)-P_n(x)| = \left| \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k) \right|$。
                为了最小化误差上界，我们需要选择一组插值节点 $x_0, \dots, x_n$，使得节点多项式 $\prod(x-x_k)$ 的最大值最小。
                这个问题正是我们刚刚解决的：这个最佳的节点多项式就是 $\tilde{T}_{n+1}(x)$。
                因此，<strong>最佳的插值节点</strong>就是 **$n+1$ 次切比雪夫多项式 $T_{n+1}(x)$ 的根**。
                $$x_k = \cos\left(\frac{(2k+1)\pi}{2(n+1)}\right), \text{ for } k=0, \dots, n.$$
                这些根在区间 $[-1,1]$ 的两端更密集，中间更稀疏，正好可以抑制龙格现象。</p>
<p><strong>2. 幂级数经济化 (Economization of Power Series):</strong>
                假设我们有一个高次多项式（例如，一个截断的泰勒级数）$P_n(x)$ 来逼近 $f(x)$。我们想用一个次数更低的 $P_{n-1}(x)$ 来代替它，同时希望损失的精度尽可能小。
                $P_n(x) - P_{n-1}(x) = Q_{n-1}(x)$
                $P_n(x) = a_n x^n + \dots$
                我们可以将 $x^n$ 用切比雪夫多项式表示：$x^n = \frac{1}{2^{n-1}}T_n(x) + (\text{lower degree terms})$。
                于是 $P_n(x) = a_n \left(\frac{1}{2^{n-1}}T_n(x) + \dots\right) + \dots$
                如果我们直接扔掉包含 $T_n(x)$ 的这一项，即令 $P_{n-1}(x) = P_n(x) - \frac{a_n}{2^{n-1}}T_n(x)$，那么我们引入的误差在 $[-1,1]$ 上的最大值仅为 $|\frac{a_n}{2^{n-1}}|$。
                这是一种非常高效的降低多项式次数的方法，其精度损失远小于直接截断泰勒级数的最高次项。</p>
<h3 id="%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93"><strong>课程总结</strong></h3>
<p><strong>本讲核心要点：</strong></p>
<ol>
<li><strong>数值微分</strong>通过逼近多项式的导数来估算函数导数，但它是一个<strong>不稳定</strong>的过程，因为舍入误差会随着步长 $h$ 的减小而被放大。中心差分格式 ($O(h^2)$) 优于前向/后向差分 ($O(h)$)。</li>
<li><strong>数值积分</strong>通过对插值多项式积分来估算定积分，它是一个<strong>稳定</strong>的过程。<strong>梯形法则</strong>和<strong>辛普森法则</strong>是基于等距节点的Newton-Cotes公式中最简单和常用的两种。</li>
<li><strong>最佳多项式逼近</strong>旨在最小化逼近的<strong>最大误差 (minimax)</strong>。其解由<strong>切比雪夫等振荡定理</strong>刻画。</li>
<li><strong>切比雪夫多项式</strong>是minimax逼近理论的核心，它解决了首一多项式的最小范数问题，并为我们提供了<strong>最佳插值节点</strong>的选择方案，以及<strong>幂级数经济化</strong>的强大工具。</li>
</ol>
</article><div class="share-buttons">
<p>分享到：</p>
<a class="share-btn weibo" href="#" onclick="sharePost(event, 'weibo')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Sina Weibo</title><path d="M10.098 20.323c-3.977.391-7.414-1.406-7.672-4.02-.259-2.609 2.759-5.047 6.74-5.441 3.979-.394 7.413 1.404 7.671 4.018.259 2.6-2.759 5.049-6.737 5.439l-.002.004zM9.05 17.219c-.384.616-1.208.884-1.829.602-.612-.279-.793-.991-.406-1.593.379-.595 1.176-.861 1.793-.601.622.263.82.972.442 1.592zm1.27-1.627c-.141.237-.449.353-.689.253-.236-.09-.313-.361-.177-.586.138-.227.436-.346.672-.24.239.09.315.36.18.601l.014-.028zm.176-2.719c-1.893-.493-4.033.45-4.857 2.118-.836 1.704-.026 3.591 1.886 4.21 1.983.64 4.318-.341 5.132-2.179.8-1.793-.201-3.642-2.161-4.149zm7.563-1.224c-.346-.105-.57-.18-.405-.615.375-.977.42-1.804 0-2.404-.781-1.112-2.915-1.053-5.364-.03 0 0-.766.331-.571-.271.376-1.217.315-2.224-.27-2.809-1.338-1.337-4.869.045-7.888 3.08C1.309 10.87 0 13.273 0 15.348c0 3.981 5.099 6.395 10.086 6.395 6.536 0 10.888-3.801 10.888-6.82 0-1.822-1.547-2.854-2.915-3.284v.01zm1.908-5.092c-.766-.856-1.908-1.187-2.96-.962-.436.09-.706.511-.616.932.09.42.511.691.932.602.511-.105 1.067.044 1.442.465.376.421.466.977.316 1.473-.136.406.089.856.51.992.405.119.857-.105.992-.512.33-1.021.12-2.178-.646-3.035l.03.045zm2.418-2.195c-1.576-1.757-3.905-2.419-6.054-1.968-.496.104-.812.587-.706 1.081.104.496.586.813 1.082.707 1.532-.331 3.185.15 4.296 1.383 1.112 1.246 1.429 2.943.947 4.416-.165.48.106 1.007.586 1.157.479.165.991-.104 1.157-.586.675-2.088.241-4.478-1.338-6.235l.03.045z"></path></svg>
<span>微博</span>
</a>
<a class="share-btn twitter" href="#" onclick="sharePost(event, 'twitter')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M21.543 7.104c.015.211.015.423.015.636 0 6.507-4.954 14.01-14.01 14.01v-.003A13.94 13.94 0 0 1 0 19.539a9.88 9.88 0 0 0 7.287-2.041 4.93 4.93 0 0 1-4.6-3.42 4.916 4.916 0 0 0 2.223-.084A4.926 4.926 0 0 1 .96 9.167v-.062a4.887 4.887 0 0 0 2.235.616A4.928 4.928 0 0 1 1.67 3.148 13.98 13.98 0 0 0 11.82 8.292a4.929 4.929 0 0 1 8.39-4.49 9.868 9.868 0 0 0 3.128-1.196 4.941 4.941 0 0 1-2.165 2.724A9.828 9.828 0 0 0 24 4.555a10.019 10.019 0 0 1-2.457 2.549z"></path></svg>
<span>Twitter</span>
</a>
<a class="share-btn linkedin" href="#" onclick="sharePost(event, 'linkedin')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg>
<span>LinkedIn</span>
</a>
<a class="share-btn wechat" href="#" onclick="sharePost(event, 'wechat')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>WeChat</title><path d="M8.691 2.188C3.891 2.188 0 5.476 0 9.53c0 2.212 1.17 4.203 3.002 5.55a.59.59 0 0 1 .213.665l-.39 1.48c-.019.07-.048.141-.048.213 0 .163.13.295.29.295a.326.326 0 0 0 .167-.054l1.903-1.114a.864.864 0 0 1 .717-.098 10.16 10.16 0 0 0 2.837.403c.276 0 .543-.027.811-.05-.857-2.578.157-4.972 1.932-6.446 1.703-1.415 3.882-1.98 5.853-1.838-.576-3.583-4.196-6.348-8.596-6.348zM5.785 5.991c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178A1.17 1.17 0 0 1 4.623 7.17c0-.651.52-1.18 1.162-1.18zm5.813 0c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178 1.17 1.17 0 0 1-1.162-1.178c0-.651.52-1.18 1.162-1.18zm5.34 2.867c-1.797-.052-3.746.512-5.28 1.786-1.72 1.428-2.687 3.72-1.78 6.22.942 2.453 3.666 4.229 6.884 4.229.826 0 1.622-.12 2.361-.336a.722.722 0 0 1 .598.082l1.584.926a.272.272 0 0 0 .14.047c.134 0 .24-.111.24-.247 0-.06-.023-.12-.038-.177l-.327-1.233a.582.582 0 0 1-.023-.156.49.49 0 0 1 .201-.398C23.024 18.48 24 16.82 24 14.98c0-3.21-2.931-5.837-6.656-6.088V8.89c-.135-.01-.27-.027-.407-.03zm-2.53 3.274c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.97-.982zm4.844 0c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.969-.982z"></path></svg>
<span>微信</span>
</a>
<a class="share-btn qq" href="#" onclick="sharePost(event, 'qq')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Tencent QQ</title><path d="M21.395 15.035a40 40 0 0 0-.803-2.264l-1.079-2.695c.001-.032.014-.562.014-.836C19.526 4.632 17.351 0 12 0S4.474 4.632 4.474 9.241c0 .274.013.804.014.836l-1.08 2.695a39 39 0 0 0-.802 2.264c-1.021 3.283-.69 4.643-.438 4.673.54.065 2.103-2.472 2.103-2.472 0 1.469.756 3.387 2.394 4.771-.612.188-1.363.479-1.845.835-.434.32-.379.646-.301.778.343.578 5.883.369 7.482.189 1.6.18 7.14.389 7.483-.189.078-.132.132-.458-.301-.778-.483-.356-1.233-.646-1.846-.836 1.637-1.384 2.393-3.302 2.393-4.771 0 0 1.563 2.537 2.103 2.472.251-.03.581-1.39-.438-4.673"></path></svg>
<span>QQ</span>
</a>
<a class="share-btn facebook" href="#" onclick="sharePost(event, 'facebook')">
<svg role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M9.101 23.691v-7.98H6.627v-3.667h2.474v-1.58c0-4.085 1.848-5.978 5.858-5.978.401 0 .955.042 1.468.103a8.68 8.68 0 0 1 1.141.195v3.325a8.623 8.623 0 0 0-.653-.036 26.805 26.805 0 0 0-.733-.009c-.707 0-1.259.096-1.675.309a1.686 1.686 0 0 0-.679.622c-.258.42-.374.995-.374 1.752v1.297h3.919l-.386 2.103-.287 1.564h-3.246v8.245C19.396 23.238 24 18.179 24 12.044c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.628 3.874 10.35 9.101 11.647Z"></path></svg>
<span>Facebook</span>
</a>
</div>
</main>
</div>
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
<script src="../script.js"></script>
<!-- The Modal -->
<div class="modal" id="about-me-modal">
<!-- Modal content -->
<div class="modal-content">
<span class="close-button">×</span>
<h2>About Me</h2>
<p>This is forliage, an undergraduate student of computer science and technology at Zhejiang University.</p>
<p><strong>Motto:</strong> People always say that time heals all wounds, but I don't believe that. Time doen't heal the pain, it just makes us get used to pain. When you lose someone, you don't really forget them; you just learn how to live on without them.</p>
<p><strong>Interests:</strong> Computer Graphics, Computer Version, Computer Animation, HPC, AIGC</p>
<p><strong>Favorite Movie:</strong> The Shawshank Redemption, Dead Poets Society, Zootopia</p>
<p><strong>Favorite Music:</strong> Blank Space, Sorega Daiji, Counting Stars, Whataya Want from Me</p>
<p><strong>Contact Information:</strong>masterforliage@gmail.com</p>
<hr/>
<h3>订阅我的博客</h3>
<p>订阅功能正在建设中，敬请期待！</p>
</div>
</div>
<script src="../modal.js"></script>
</body>
</html>