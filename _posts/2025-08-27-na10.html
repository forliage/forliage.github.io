<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>数值分析10:数值微积分与最佳多项式逼近</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../modal.css">
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FPDBQB4LZD"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FPDBQB4LZD');
    </script>
</head>
<body>
    <audio id="bg-music" src="../music.mp3" loop></audio>
    <button id="music-toggle" class="music-control">♪</button>
    <header>
        <h1>forliage的blog</h1>
        <nav>
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../posts.html">文章</a></li>
                <li><a href="../about.html">关于</a></li>
                <li><a href="../category.html?category=技术文章">技术文章</a></li>
                <li><a href="../category.html?category=生活随笔">生活随笔</a></li>
                <li><a href="../category.html?category=学习笔记">学习笔记</a></li>
                <li><a href="../category.html?category=心情日记">心情日记</a></li>
                <li><a href="#" id="about-me-btn">ABOUT ME</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
        <div id="sidebar-container"></div>
        <main>
            <article>
                <h1 id="%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%9010%E6%95%B0%E5%80%BC%E5%BE%AE%E7%A7%AF%E5%88%86%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%80%BC%E8%BF%91">数值分析10:数值微积分与最佳多项式逼近</h1>
                <h3 id="%E5%BC%95%E8%A8%80%E4%BB%8E%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91%E5%88%B0%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C"><strong>引言：从函数逼近到函数操作</strong></h3>
                <p>在过去的几讲中，我们花了大量时间探讨一个核心主题：<strong>函数逼近</strong>。无论是通过<strong>插值</strong>（拉格朗日、牛顿、样条）来精确穿过数据点，还是通过<strong>最小二乘法</strong>来拟合含噪声数据的整体趋势，我们的目标都是用一个“简单”的函数（主要是多项式）去“代替”一个“复杂”或未知的函数。</p>
                <p>今天，我们将把这一思想推向其逻辑上的下一个阶段：我们为什么要逼近函数？一个非常重要的原因就是为了对它们进行<strong>微积分操作</strong>。</p>
                <ul>
                <li>如果我们只有一个函数的离散数据点，我们如何估算它在某一点的<strong>导数</strong>？</li>
                <li>如果一个函数的原函数无法用初等函数表示（例如 $e^{-x^2}$），我们如何计算它在某个区间上的<strong>定积分</strong>？</li>
                </ul>
                <p>答案很简单：<strong>我们不对原始的复杂函数进行操作，而是对它的简单逼近函数（比如插值多项式）进行操作。</strong> 这就是<strong>数值微分 (Numerical Differentiation)</strong> 和<strong>数值积分 (Numerical Integration)</strong> 的基本思想。</p>
                <p>课程的第一部分，我们将探讨数值微分。我们会发现，这是一个非常“微妙”甚至有些“危险”的过程。一个看似自然的近似方法，可能会因为对舍入误差的极度敏感而变得非常<strong>不稳定</strong>。</p>
                <p>课程的第二部分，我们将转向数值积分，也称为<strong>数值求积 (Numerical Quadrature)</strong>。幸运的是，积分在数学上是一个“平滑”或“平均”的过程，因此数值积分方法通常具有非常好的<strong>稳定性</strong>和<strong>收敛性</strong>。我们将从最基础的牛顿-柯特斯公式（梯形法则、辛普森法则）入手。</p>
                <p>最后，课程的第三部分，我们将回到逼近理论的一个巅峰话题。在最小二乘法中，我们最小化了<strong>L2范数</strong>下的误差（平方误差和）。但是，如果我们想让逼近多项式在整个区间上的<strong>最大误差</strong>（<strong>L∞范数</strong>）最小化，该怎么做？这个问题，即<strong>minimax问题</strong>，引出了数值分析中最优雅、最深刻的理论之一，以及一类极其重要的特殊函数——<strong>切比雪夫多项式 (Chebyshev Polynomials)</strong>。我们将看到，这些多项式不仅是minimax问题的答案，还能帮助我们解决龙格现象，并引出一种被称为<strong>幂级数经济化</strong>的巧妙技术。</p>
                <h3 id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86%E4%B8%80%E4%B8%AA%E7%97%85%E6%80%81%E7%9A%84%E9%97%AE%E9%A2%98"><strong>第一部分：数值微分——一个“病态”的问题</strong></h3>
                <h4 id="41-%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E4%B8%8E%E4%BD%8E%E9%98%B6%E5%85%AC%E5%BC%8F"><strong>4.1 基本思想与低阶公式</strong></h4>
                <p><strong>核心思想：</strong>
                给定函数 $f(x)$，我们想近似 $f'(x_0)$。最直接的来源是导数的极限定义：
                $$f'(x_0) = \lim_{h \to 0} \frac{f(x_0+h) - f(x_0)}{h}$$</p>
                <p>如果我们取一个很小但非零的 $h$，就可以得到近似公式。</p>
                <p><strong>1. 前向差分公式 (Forward-Difference Formula):</strong>
                $$f'(x_0) \approx \frac{f(x_0+h) - f(x_0)}{h}$$
                几何上，这是用连接点 $(x_0, f(x_0))$ 和 $(x_0+h, f(x_0+h))$ 的<strong>割线斜率</strong>来近似点 $x_0$ 处的<strong>切线斜率</strong>。</p>
                <p><strong>2. 后向差分公式 (Backward-Difference Formula):</strong>
                $$f'(x_0) \approx \frac{f(x_0) - f(x_0-h)}{h}$$
                这是用点 $(x_0-h, f(x_0-h))$ 和 $(x_0, f(x_0))$ 的割线斜率来近似。</p>
                <p><strong>误差分析：</strong>
                这些公式的精度如何？我们可以用泰勒展开来分析。将 $f(x_0+h)$ 在 $x_0$ 处展开：
                $$f(x_0+h) = f(x_0) + f'(x_0)h + \frac{f''(\xi)}{2}h^2$$
                整理后得到：
                $$\frac{f(x_0+h) - f(x_0)}{h} = f'(x_0) + \frac{f''(\xi)}{2}h$$
                <strong>截断误差 (Truncation Error):</strong>
                $$f'(x_0) - \left[\frac{f(x_0+h) - f(x_0)}{h}\right] = -\frac{f''(\xi)}{2}h = O(h)$$
                前向和后向差分公式的截断误差都是 $h$ 的一阶，我们称之为<strong>一阶方法</strong>。这意味着，如果步长 $h$ 减半，误差大约也减半，收敛速度很慢。</p>
                <p><strong>3. 中心差分公式 (Central-Difference Formula):</strong>
                有没有更好的方法？我们可以组合两个泰勒展开：
                $$f(x_0+h) = f(x_0) + f'(x_0)h + \frac{f''(x_0)}{2}h^2 + \frac{f'''(\xi_1)}{6}h^3$$
                $$f(x_0-h) = f(x_0) - f'(x_0)h + \frac{f''(x_0)}{2}h^2 - \frac{f'''(\xi_2)}{6}h^3$$
                两式相减：
                $$f(x_0+h) - f(x_0-h) = 2f'(x_0)h + \frac{f'''(\xi_1)+f'''(\xi_2)}{6}h^3$$
                整理得到：
                $$f'(x_0) = \underbrace{\frac{f(x_0+h) - f(x_0-h)}{2h}}_{\text{中心差分公式}} - \underbrace{\frac{f'''(\xi)}{6}h^2}_{\text{截断误差}}$$
                中心差分公式的截断误差是 $O(h^2)$，是一个<strong>二阶方法</strong>！步长 $h$ 减半，误差会减小到原来的四分之一，精度远高于前向/后向差分。这是最常用的数值微分公式之一。</p>
                <h4 id="411-%E9%AB%98%E9%98%B6%E5%85%AC%E5%BC%8F%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%8E%A8%E5%AF%BC"><strong>4.1.1 高阶公式的系统推导</strong></h4>
                <p>如何系统地推导更高阶的公式？
                <strong>方法：</strong> 用 $n+1$ 个点的<strong>拉格朗日插值多项式</strong> $P_n(x)$ 及其误差项 $R_n(x)$ 来逼近 $f(x)$，然后对整个表达式求导：
                $$f(x) = \sum_{k=0}^n f(x_k)L_k(x) + \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k)$$
                $$f'(x) = \sum_{k=0}^n f(x_k)L'_k(x) + \frac{d}{dx}\left[ \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k) \right]$$
                当 $x$ 是一个插值节点 $x_j$ 时，对误差项求导变得复杂。但这个方法给出了推导各种差分公式的统一框架。</p>
                <p><strong>例如 (Discussion 26):</strong>
                使用点 $x_0, x_0+h, x_0+2h$ 构造二次插值多项式，然后求导并分别在三个点上取值，可以得到三个不同的<strong>三点公式</strong>。</p>
                <ul>
                <li>$f'(x_0) = \frac{1}{2h}[-3f(x_0) + 4f(x_0+h) - f(x_0+2h)] + \frac{h^2}{3}f'''(\xi)$</li>
                <li>$f'(x_0+h) = \frac{1}{2h}[f(x_0+2h) - f(x_0)]$ (这正是以 $x_0+h$ 为中心的中心差分公式！)</li>
                <li>$f'(x_0+2h) = \frac{1}{2h}[f(x_0) - 4f(x_0+h) + 3f(x_0+2h)] + \frac{h^2}{3}f'''(\xi)$</li>
                </ul>
                <p>可以看到，中心点公式的截断误差项系数（$1/6$）比端点公式（$1/3$）更小，因此精度更高。</p>
                <h4 id="412-%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86%E7%9A%84%E4%B8%8D%E7%A8%B3%E5%AE%9A%E6%80%A7"><strong>4.1.2 数值微分的不稳定性</strong></h4>
                <p>&quot;numerical differentiation is unstable!&quot; 为什么？
                让我们重新审视中心差分公式。在计算机上，我们计算的函数值 $f(x_0\pm h)$ 并非精确值，而是带有舍入误差的 $\tilde{f}(x_0\pm h)$。设 $|f(x) - \tilde{f}(x)| \le \epsilon$。
                我们实际计算的导数是：
                $$\tilde{f}'(x_0) = \frac{\tilde{f}(x_0+h) - \tilde{f}(x_0-h)}{2h}$$
                总误差 = 截断误差 + 舍入误差
                $$|f'(x_0) - \tilde{f}'(x_0)| \le \left| \frac{f'''(\xi)}{6}h^2 \right| + \left| \frac{(f(x_0+h)-\tilde{f}(x_0+h)) - (f(x_0-h)-\tilde{f}(x_0-h))}{2h} \right|$$
                $$|f'(x_0) - \tilde{f}'(x_0)| \le \frac{M_3}{6}h^2 + \frac{\epsilon+\epsilon}{2h} = \frac{M_3}{6}h^2 + \frac{\epsilon}{h}$$</p>
                <p><strong>误差行为分析：</strong></p>
                <ul>
                <li>当步长 $h$ 减小时，<strong>截断误差</strong> ($\propto h^2$) 减小。</li>
                <li>当步长 $h$ 减小时，<strong>舍入误差</strong> ($\propto 1/h$) <strong>增大</strong>！</li>
                </ul>
                <p>这是一个致命的矛盾。我们不能像在数学理论中那样让 $h$ 任意趋于0。存在一个<strong>最优步长 $h_{opt}$</strong>，使得总误差最小。小于这个 $h$，舍入误差将占主导，结果会越来越差！这就是<strong>数值微分的不稳定性</strong>。它对输入数据的噪声（在此即为舍入误差）非常敏感。</p>
                <h4 id="42-%E4%BA%8C%E9%98%B6%E5%AF%BC%E6%95%B0%E8%BF%91%E4%BC%BC"><strong>4.2 二阶导数近似</strong></h4>
                <p>类似地，我们可以通过组合泰勒展开来推导二阶导数的公式 (Discussion 27)。
                $$f(x_0+h) = f(x_0) + f'(x_0)h + \frac{f''(x_0)}{2}h^2 + \frac{f'''(x_0)}{6}h^3 + O(h^4)$$
                $$f(x_0-h) = f(x_0) - f'(x_0)h + \frac{f''(x_0)}{2}h^2 - \frac{f'''(x_0)}{6}h^3 + O(h^4)$$
                两式相加：
                $$f(x_0+h) + f(x_0-h) = 2f(x_0) + f''(x_0)h^2 + O(h^4)$$
                整理得到：
                $$f''(x_0) = \frac{f(x_0+h) - 2f(x_0) + f(x_0-h)}{h^2} - \frac{h^2}{12}f^{(4)}(\xi)$$
                这是一个 $O(h^2)$ 精度的<strong>中心差分公式</strong>，用于近似二阶导数。它同样面临着 $1/h^2$ 形式的舍入误差放大问题，比一阶导数更不稳定。</p>
                <h3 id="%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86%E4%B8%80%E4%B8%AA%E7%A8%B3%E5%AE%9A%E7%9A%84%E8%BF%87%E7%A8%8B"><strong>第二部分：数值积分——一个“稳定”的过程</strong></h3>
                <h4 id="43-%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E6%8F%92%E5%80%BC%E5%9E%8B%E6%B1%82%E7%A7%AF"><strong>4.3 基本思想：插值型求积</strong></h4>
                <p><strong>核心思想：</strong>
                我们想计算 $I = \int_a^b f(x)dx$。</p>
                <ol>
                <li>
                <p>在 $[a,b]$ 上选择 $n+1$ 个节点 $x_0, \dots, x_n$。</p>
                </li>
                <li>
                <p>构造一个穿过这些点的插值多项式 $P_n(x)$。</p>
                </li>
                <li>
                <p>用 $P_n(x)$ 的积分来近似 $f(x)$ 的积分：</p>
                <p>
                $$
                \begin{aligned}
                I &= \int_a^b f(x)dx \approx \int_a^b P_n(x)dx = \int_a^b \sum_{k=0}^n f(x_k)L_k(x)dx \\
                &= \sum_{k=0}^n f(x_k) \underbrace{\int_a^b L_k(x)dx}_{A_k} = \sum_{k=0}^n A_k f(x_k)
                \end{aligned}
                $$
                </p>
                </li>
                </ol>
                <p>这个形式被称为<strong>插值型求积公式 (Interpolatory Quadrature)</strong>。$x_k$ 称为<strong>节点 (nodes)</strong>，$A_k$ 称为<strong>权 (weights) 或 Cotes 系数</strong>。
                数值积分的本质就是用一个<strong>带权和</strong>来近似积分值。</p>
                <p><strong>误差分析：</strong>
                $$
                \begin{aligned}
                Error &= \int_a^b f(x)dx - \int_a^b P_n(x)dx = \int_a^b (f(x)-P_n(x))dx = \int_a^b R_n(x)dx \\
                &= \int_a^b \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k) dx
                \end{aligned}
                $$</p>
                <p>与微分不同，积分是一个平均过程，它会“平滑”掉函数值的微小误差。因此，数值积分方法通常是<strong>非常稳定</strong>的。</p>
                <h4 id="431-newton-cotes-%E5%85%AC%E5%BC%8F"><strong>4.3.1 Newton-Cotes 公式</strong></h4>
                <p>这是一族最经典的求积公式，它们基于在 $[a,b]$ 区间上取<strong>等距节点</strong>。</p>
                <p><strong>1. 梯形法则 (Trapezoidal Rule, n=1):</strong>
                使用两个端点 $x_0=a, x_1=b$ 进行线性插值。
                $$A_0 = \int_a^b L_0(x)dx = \int_a^b \frac{x-b}{a-b}dx = \frac{b-a}{2}$$
                $$A_1 = \int_a^b L_1(x)dx = \int_a^b \frac{x-a}{b-a}dx = \frac{b-a}{2}$$
                <strong>公式：</strong> $\int_a^b f(x)dx \approx \frac{b-a}{2}[f(a)+f(b)]$
                <strong>误差：</strong> $E_T = -\frac{(b-a)^3}{12}f''(\xi) = O(h^3)$
                <strong>精度 (Degree of Precision):</strong> 一个求积公式的精度是指它能精确积分的最高次多项式的次数。梯形法则是对线性函数精确的，所以其<strong>精度为1</strong>。</p>
                <p><strong>2. 辛普森法则 (Simpson's Rule, n=2):</strong>
                使用三个点 $x_0=a, x_1=(a+b)/2, x_2=b$ 进行二次插值。
                <strong>公式：</strong> $\int_a^b f(x)dx \approx \frac{b-a}{6}\left[f(a) + 4f\left(\frac{a+b}{2}\right) + f(b)\right]$
                <strong>误差：</strong> $E_S = -\frac{(b-a)^5}{2880}f^{(4)}(\xi) = O(h^5)$
                <strong>精度：</strong> 令人惊讶的是，辛普森法则不仅对二次多项式精确，对<strong>三次多项式也精确</strong>！所以其<strong>精度为3</strong>。这种精度的“意外”提升是由于误差项中奇数阶导数项的对称性抵消造成的。</p>
                <p><strong>更高阶的Newton-Cotes公式</strong>（如Simpson's 3/8 Rule, Boole's Rule）可以类似推导，但它们在高阶时可能出现负权，导致数值不稳定，因此不常用。实用的做法是将低阶公式进行复合。</p>
                <h3 id="%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%9C%80%E4%BD%B3%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%80%BC%E8%BF%91%E4%B8%8E%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%9A%E9%A1%B9%E5%BC%8F"><strong>第三部分：最佳多项式逼近与切比雪夫多项式</strong></h3>
                <h4 id="831-minimax-%E9%80%BC%E8%BF%91%E9%97%AE%E9%A2%98"><strong>8.3.1 Minimax 逼近问题</strong></h4>
                <p>我们已经学习了最小二乗（L2）逼近。现在我们考虑一个更严格的逼近标准：<strong>最小化最大误差（L∞）</strong>。</p>
                <p><strong>Minimax 问题:</strong>
                给定函数 $f(x)$，在所有次数不超过 $n$ 的多项式 $\Pi_n$ 中，找到那个 $P_n^*(x)$，使得<strong>一致范数（或无穷范数）</strong> $||f - P_n||_\infty = \max_{x \in [a,b]} |f(x) - P_n(x)|$ 达到最小。</p>
                <p><strong>切比雪夫等振荡定理 (Chebyshev's Equioscillation Theorem):</strong>
                这个问题的解 $P_n^*(x)$ 存在且唯一，其充要条件是误差函数 $E(x)=f(x)-P_n^*(x)$ 在区间 $[a,b]$ 上至少有 <strong>$n+2$ 个点</strong>，在这些点上误差达到其最大值（或最小值），并且<strong>正负交替</strong>。
                这些点被称为<strong>切比雪夫交错点组 (Chebyshev Alternating Set)</strong>。</p>
                <h4 id="832-%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%9A%E9%A1%B9%E5%BC%8F"><strong>8.3.2 切比雪夫多项式</strong></h4>
                <p>如何找到这个最佳逼近多项式？直接构造非常困难。但切比雪夫找到了一个相关问题的巧妙解。</p>
                <p><strong>问题 (v 3.0):</strong> 在所有次数为 $n-1$ 的多项式中，找到 $P_{n-1}(x)$，使得 $||x^n - P_{n-1}(x)||_\infty$ 在 $[-1,1]$ 上最小。
                这等价于寻找一个<strong>首项系数为1 (monic) 的 $n$ 次多项式</strong>，使其在 $[-1,1]$ 上的无穷范数最小。</p>
                <p><strong>切比雪夫的洞察：</strong>
                考虑函数 $T_n(x) = \cos(n \arccos x)$。</p>
                <ul>
                <li>通过变量替换 $x=\cos\theta$，我们有 $T_n(\cos\theta) = \cos(n\theta)$。</li>
                <li>利用三角恒等式，可以证明 $T_n(x)$ 是一个关于 $x$ 的 $n$ 次多项式。
                $T_0(x)=1, T_1(x)=x, T_{n+1}(x)=2xT_n(x)-T_{n-1}(x)$。</li>
                <li>$T_n(x)$ 的首项系数是 $2^{n-1}$。</li>
                <li>在 $[-1,1]$ 区间内，$\cos(n\theta)$ 的值在 $+1$ 和 $-1$ 之间振荡。它在 $n+1$ 个点上达到其极值 $\pm 1$，并且正负交替！</li>
                </ul>
                <p>这完美地满足了等振荡定理的要求！
                因此，使得 $||x^n - P_{n-1}(x)||_\infty$ 最小的那个多项式正是<strong>缩放后的切比雪夫多项式</strong>：
                $$\tilde{T}_n(x) = \frac{1}{2^{n-1}} T_n(x)$$
                这个多项式的最小最大值为 $\frac{1}{2^{n-1}}$。</p>
                <h4 id="833-%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8"><strong>8.3.3 切比雪夫多项式的应用</strong></h4>
                <p><strong>1. 最佳插值节点的选择:</strong>
                回顾插值误差公式：$|f(x)-P_n(x)| = \left| \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{k=0}^n(x-x_k) \right|$。
                为了最小化误差上界，我们需要选择一组插值节点 $x_0, \dots, x_n$，使得节点多项式 $\prod(x-x_k)$ 的最大值最小。
                这个问题正是我们刚刚解决的：这个最佳的节点多项式就是 $\tilde{T}_{n+1}(x)$。
                因此，<strong>最佳的插值节点</strong>就是 **$n+1$ 次切比雪夫多项式 $T_{n+1}(x)$ 的根**。
                $$x_k = \cos\left(\frac{(2k+1)\pi}{2(n+1)}\right), \text{ for } k=0, \dots, n.$$
                这些根在区间 $[-1,1]$ 的两端更密集，中间更稀疏，正好可以抑制龙格现象。</p>
                <p><strong>2. 幂级数经济化 (Economization of Power Series):</strong>
                假设我们有一个高次多项式（例如，一个截断的泰勒级数）$P_n(x)$ 来逼近 $f(x)$。我们想用一个次数更低的 $P_{n-1}(x)$ 来代替它，同时希望损失的精度尽可能小。
                $P_n(x) - P_{n-1}(x) = Q_{n-1}(x)$
                $P_n(x) = a_n x^n + \dots$
                我们可以将 $x^n$ 用切比雪夫多项式表示：$x^n = \frac{1}{2^{n-1}}T_n(x) + (\text{lower degree terms})$。
                于是 $P_n(x) = a_n \left(\frac{1}{2^{n-1}}T_n(x) + \dots\right) + \dots$
                如果我们直接扔掉包含 $T_n(x)$ 的这一项，即令 $P_{n-1}(x) = P_n(x) - \frac{a_n}{2^{n-1}}T_n(x)$，那么我们引入的误差在 $[-1,1]$ 上的最大值仅为 $|\frac{a_n}{2^{n-1}}|$。
                这是一种非常高效的降低多项式次数的方法，其精度损失远小于直接截断泰勒级数的最高次项。</p>
                <h3 id="%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93"><strong>课程总结</strong></h3>
                <p><strong>本讲核心要点：</strong></p>
                <ol>
                <li><strong>数值微分</strong>通过逼近多项式的导数来估算函数导数，但它是一个<strong>不稳定</strong>的过程，因为舍入误差会随着步长 $h$ 的减小而被放大。中心差分格式 ($O(h^2)$) 优于前向/后向差分 ($O(h)$)。</li>
                <li><strong>数值积分</strong>通过对插值多项式积分来估算定积分，它是一个<strong>稳定</strong>的过程。<strong>梯形法则</strong>和<strong>辛普森法则</strong>是基于等距节点的Newton-Cotes公式中最简单和常用的两种。</li>
                <li><strong>最佳多项式逼近</strong>旨在最小化逼近的<strong>最大误差 (minimax)</strong>。其解由<strong>切比雪夫等振荡定理</strong>刻画。</li>
                <li><strong>切比雪夫多项式</strong>是minimax逼近理论的核心，它解决了首一多项式的最小范数问题，并为我们提供了<strong>最佳插值节点</strong>的选择方案，以及<strong>幂级数经济化</strong>的强大工具。</li>
                </ol>
            </article>
        </main>
    </div>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({
        startOnLoad: true
      });
    </script>
    <script src="../script.js"></script>
    <!-- The Modal -->
    <div id="about-me-modal" class="modal">
      <!-- Modal content -->
      <div class="modal-content">
        <span class="close-button">&times;</span>
        <h2>About Me</h2>
        <p>This is forliage, an undergraduate student of computer science and technology at Zhejiang University.</p>
        <p><strong>Motto:</strong> People always say that time heals all wounds, but I don't believe that. Time doen't heal the pain, it just makes us get used to pain. When you lose someone, you don't really forget them; you just learn how to live on without them.</p>
        <p><strong>Interests:</strong> Computer Graphics, Computer Version, Computer Animation, HPC, AIGC</p>
        <p><strong>Favorite Movie:</strong> The Shawshank Redemption, Dead Poets Society, Zootopia</p>
        <p><strong>Favorite Music:</strong> Blank Space, Sorega Daiji, Counting Stars, Whataya Want from Me</p>
        <p><strong>Contact Information:</strong>masterforliage@gmail.com</p>
        <hr>
        <h3>订阅我的博客</h3>
        <p>订阅功能正在建设中，敬请期待！</p>
      </div>
    </div>
    <script src="../modal.js"></script>
</body>
</html>